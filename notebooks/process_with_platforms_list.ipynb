{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "9f878586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import additional necessary libraries\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin, urlparse\n",
    "import time\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93546e4",
   "metadata": {},
   "source": [
    "Process tested with platforms list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "265608e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "platform_list = [\n",
    "    \"observation.org\",\n",
    "    \"seasearch.org.uk\",\n",
    "    \"natuurpunt.be\",\n",
    "    \"slu.se/artdatabanken\",\n",
    "    \"theroadlab.co.uk\",\n",
    "    \"exploreyourshore.ie\",\n",
    "    \"eyeonwater.org\",\n",
    "    \"iseahorse.org\",\n",
    "    \"redpromar.org\",\n",
    "    \"coastwards.org\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "bc0a7a18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "platform_url",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "78d14d66-34e5-45b3-bf45-f087c5ee911d",
       "rows": [
        [
         "0",
         "observation.org"
        ],
        [
         "1",
         "seasearch.org.uk"
        ],
        [
         "2",
         "natuurpunt.be"
        ],
        [
         "3",
         "slu.se/artdatabanken"
        ],
        [
         "4",
         "theroadlab.co.uk"
        ],
        [
         "5",
         "exploreyourshore.ie"
        ],
        [
         "6",
         "eyeonwater.org"
        ],
        [
         "7",
         "iseahorse.org"
        ],
        [
         "8",
         "redpromar.org"
        ],
        [
         "9",
         "coastwards.org"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>platform_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>observation.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>seasearch.org.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>natuurpunt.be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>slu.se/artdatabanken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>theroadlab.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>exploreyourshore.ie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>eyeonwater.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>iseahorse.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>redpromar.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>coastwards.org</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           platform_url\n",
       "0       observation.org\n",
       "1      seasearch.org.uk\n",
       "2         natuurpunt.be\n",
       "3  slu.se/artdatabanken\n",
       "4      theroadlab.co.uk\n",
       "5   exploreyourshore.ie\n",
       "6        eyeonwater.org\n",
       "7         iseahorse.org\n",
       "8         redpromar.org\n",
       "9        coastwards.org"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_platforms = pd.DataFrame(platform_list)\n",
    "df_platforms.columns = ['platform_url']\n",
    "df_platforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df329518",
   "metadata": {},
   "source": [
    "# active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "335af2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_website(url):\n",
    "    try:\n",
    "        # Ensure URL has protocol\n",
    "        if not url.startswith(('http://', 'https://')):\n",
    "            url = 'https://' + url\n",
    "        session = requests.Session()\n",
    "        session.headers.update({\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\",\n",
    "            \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n",
    "            \"Accept-Language\": \"en-US,en;q=0.5\",\n",
    "            \"Referer\": \"https://www.google.com/\"\n",
    "        })\n",
    "        response = session.get(url, timeout=5)\n",
    "        return f\"Status code: {response.status_code}\"\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return f\"Fallo: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b01310ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_platforms['active'] = df_platforms['platform_url'].apply(check_website)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "59924a3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "active",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "45e83a78-fc61-4909-8125-f33cf49db557",
       "rows": [
        [
         "0",
         "Status code: 200"
        ],
        [
         "1",
         "Status code: 200"
        ],
        [
         "2",
         "Status code: 200"
        ],
        [
         "3",
         "Status code: 200"
        ],
        [
         "4",
         "Status code: 200"
        ],
        [
         "5",
         "Status code: 200"
        ],
        [
         "6",
         "Status code: 200"
        ],
        [
         "7",
         "Status code: 200"
        ],
        [
         "8",
         "Status code: 200"
        ],
        [
         "9",
         "Fallo: HTTPSConnectionPool(host='coastwards.org', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7ff0c3ac4610>: Failed to establish a new connection: [Errno 111] Conexi√≥n rehusada'))"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 10
       }
      },
      "text/plain": [
       "0                                     Status code: 200\n",
       "1                                     Status code: 200\n",
       "2                                     Status code: 200\n",
       "3                                     Status code: 200\n",
       "4                                     Status code: 200\n",
       "5                                     Status code: 200\n",
       "6                                     Status code: 200\n",
       "7                                     Status code: 200\n",
       "8                                     Status code: 200\n",
       "9    Fallo: HTTPSConnectionPool(host='coastwards.or...\n",
       "Name: active, dtype: object"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_platforms['active'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ab1c68",
   "metadata": {},
   "source": [
    "# platform_about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "gidpstrpa1s",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_about_link(base_url):\n",
    "    \"\"\"\n",
    "    Extracts the 'About' link from a website.\n",
    "    Searches for common variations of 'About' links on the site.\n",
    "    \n",
    "    Args:\n",
    "        base_url (str): Base URL of the platform\n",
    "        \n",
    "    Returns:\n",
    "        str: URL of the About page if found, None if not\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Ensure URL has protocol\n",
    "        if not base_url.startswith(('http://', 'https://')):\n",
    "            base_url = 'https://' + base_url\n",
    "        \n",
    "        # Configure headers to avoid blocking\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "            'Accept-Language': 'en-US,en;q=0.5',\n",
    "            'Accept-Encoding': 'gzip, deflate',\n",
    "            'Connection': 'keep-alive',\n",
    "        }\n",
    "        \n",
    "        # Make HTTP request\n",
    "        response = requests.get(base_url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Parse HTML\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Possible 'About' link texts\n",
    "        about_texts = [\n",
    "            'about', 'about us', 'about this site', 'who we are', \n",
    "            'quienes somos', 'acerca de', 'sobre nosotros', 'over ons',\n",
    "            'chi siamo', 'wer sind wir', '√† propos', 'om oss'\n",
    "        ]\n",
    "        \n",
    "        # Search for links containing 'About' related texts\n",
    "        for link in soup.find_all('a', href=True):\n",
    "            link_text = link.get_text(strip=True).lower()\n",
    "            href = link.get('href')\n",
    "            \n",
    "            # Check if link text contains any variation of 'about'\n",
    "            if any(about_text in link_text for about_text in about_texts):\n",
    "                # Convert to absolute URL if relative\n",
    "                if href.startswith('/'):\n",
    "                    about_url = urljoin(base_url, href)\n",
    "                elif href.startswith('http'):\n",
    "                    about_url = href\n",
    "                else:\n",
    "                    about_url = urljoin(base_url, '/' + href)\n",
    "                \n",
    "                return about_url\n",
    "        \n",
    "        # If not found, search common 'about' page URLs\n",
    "        common_about_paths = ['/about', '/about-us', '/about.html', '/who-we-are', '/info']\n",
    "        for path in common_about_paths:\n",
    "            test_url = urljoin(base_url, path)\n",
    "            try:\n",
    "                test_response = requests.head(test_url, headers=headers, timeout=5)\n",
    "                if test_response.status_code == 200:\n",
    "                    return test_url\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "        return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error procesando {base_url}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "0e12b11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error procesando https://coastwards.org: HTTPSConnectionPool(host='coastwards.org', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7ff0c5511290>: Failed to establish a new connection: [Errno 111] Conexi√≥n rehusada'))\n"
     ]
    }
   ],
   "source": [
    "df_platforms['platform_about'] = df_platforms['platform_url'].apply(extract_about_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "4124156d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   platform_url    10 non-null     object\n",
      " 1   active          10 non-null     object\n",
      " 2   platform_about  7 non-null      object\n",
      "dtypes: object(3)\n",
      "memory usage: 372.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df_platforms.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "8e2a83b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "platform_url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "active",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "platform_about",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "80e936f9-8f8f-421d-8268-558a39e066e2",
       "rows": [
        [
         "0",
         "observation.org",
         "Status code: 200",
         "https://observation.org/about"
        ],
        [
         "1",
         "seasearch.org.uk",
         "Status code: 200",
         "https://www.seasearch.org.uk/about"
        ],
        [
         "2",
         "natuurpunt.be",
         "Status code: 200",
         "https://natuurpunt.be/dit-is-natuurpunt"
        ],
        [
         "3",
         "slu.se/artdatabanken",
         "Status code: 200",
         null
        ],
        [
         "4",
         "theroadlab.co.uk",
         "Status code: 200",
         "https://www.theroadlab.co.uk/about"
        ],
        [
         "5",
         "exploreyourshore.ie",
         "Status code: 200",
         "https://exploreyourshore.ie/about-explore-your-shore/"
        ],
        [
         "6",
         "eyeonwater.org",
         "Status code: 200",
         "https://eyeonwater.org/about-us"
        ],
        [
         "7",
         "iseahorse.org",
         "Status code: 200",
         "https://projectseahorse.org/about-us/"
        ],
        [
         "8",
         "redpromar.org",
         "Status code: 200",
         null
        ],
        [
         "9",
         "coastwards.org",
         "Fallo: HTTPSConnectionPool(host='coastwards.org', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7ff0c3ac4610>: Failed to establish a new connection: [Errno 111] Conexi√≥n rehusada'))",
         null
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>platform_url</th>\n",
       "      <th>active</th>\n",
       "      <th>platform_about</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>observation.org</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>https://observation.org/about</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>seasearch.org.uk</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>https://www.seasearch.org.uk/about</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>natuurpunt.be</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>https://natuurpunt.be/dit-is-natuurpunt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>slu.se/artdatabanken</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>theroadlab.co.uk</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>https://www.theroadlab.co.uk/about</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>exploreyourshore.ie</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>https://exploreyourshore.ie/about-explore-your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>eyeonwater.org</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>https://eyeonwater.org/about-us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>iseahorse.org</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>https://projectseahorse.org/about-us/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>redpromar.org</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>coastwards.org</td>\n",
       "      <td>Fallo: HTTPSConnectionPool(host='coastwards.or...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           platform_url                                             active  \\\n",
       "0       observation.org                                   Status code: 200   \n",
       "1      seasearch.org.uk                                   Status code: 200   \n",
       "2         natuurpunt.be                                   Status code: 200   \n",
       "3  slu.se/artdatabanken                                   Status code: 200   \n",
       "4      theroadlab.co.uk                                   Status code: 200   \n",
       "5   exploreyourshore.ie                                   Status code: 200   \n",
       "6        eyeonwater.org                                   Status code: 200   \n",
       "7         iseahorse.org                                   Status code: 200   \n",
       "8         redpromar.org                                   Status code: 200   \n",
       "9        coastwards.org  Fallo: HTTPSConnectionPool(host='coastwards.or...   \n",
       "\n",
       "                                      platform_about  \n",
       "0                      https://observation.org/about  \n",
       "1                 https://www.seasearch.org.uk/about  \n",
       "2            https://natuurpunt.be/dit-is-natuurpunt  \n",
       "3                                               None  \n",
       "4                 https://www.theroadlab.co.uk/about  \n",
       "5  https://exploreyourshore.ie/about-explore-your...  \n",
       "6                    https://eyeonwater.org/about-us  \n",
       "7              https://projectseahorse.org/about-us/  \n",
       "8                                               None  \n",
       "9                                               None  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_platforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61a0d02",
   "metadata": {},
   "source": [
    "# year_creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "4de4a808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year of creation of the domain: 2021\n"
     ]
    }
   ],
   "source": [
    "import whois\n",
    "\n",
    "def get_domain_creation_year(url):\n",
    "    # Ensure URL has protocol\n",
    "    if not url.startswith(('http://', 'https://')):\n",
    "        url = 'https://' + url\n",
    "    try:\n",
    "        domain = whois.whois(url)\n",
    "        creation_date = domain.creation_date\n",
    "        if isinstance(creation_date, list):  # Some WHOIS return multiple dates\n",
    "            creation_date = creation_date[0]\n",
    "        return creation_date.year\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "# Test function\n",
    "year = get_domain_creation_year(\"minka-sdg.org\")\n",
    "print(f\"Year of creation of the domain: {year}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "741c2220",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_platforms['year_creation'] = df_platforms['platform_url'].apply(get_domain_creation_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "ce2c378e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "year_creation",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "c10a4000-d216-4ebf-91bf-e8c6cbe480c3",
       "rows": [
        [
         "0",
         "2002.0"
        ],
        [
         "1",
         "1999.0"
        ],
        [
         "2",
         null
        ],
        [
         "3",
         "1989.0"
        ],
        [
         "4",
         "2022.0"
        ],
        [
         "5",
         "2019.0"
        ],
        [
         "6",
         "2015.0"
        ],
        [
         "7",
         "2012.0"
        ],
        [
         "8",
         "2020.0"
        ],
        [
         "9",
         "2016.0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 10
       }
      },
      "text/plain": [
       "0    2002.0\n",
       "1    1999.0\n",
       "2       NaN\n",
       "3    1989.0\n",
       "4    2022.0\n",
       "5    2019.0\n",
       "6    2015.0\n",
       "7    2012.0\n",
       "8    2020.0\n",
       "9    2016.0\n",
       "Name: year_creation, dtype: float64"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_platforms['year_creation']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ls8clu0vn8",
   "metadata": {},
   "source": [
    "# terms_use_link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ff794c",
   "metadata": {},
   "source": [
    "Domain slu.se is a very old universitary domain, but artdatabanken can be created later. The function get_domain_creation_year gives just the year when the main domain was registered. But we can't check anything else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "yb4fzi7wc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_terms_link(url):\n",
    "    \"\"\"\n",
    "    Extracts the link to a web page's terms of use/conditions.\n",
    "    Searches for common variations of terms links in multiple languages.\n",
    "\n",
    "    Args:\n",
    "        url (str): Platform URL\n",
    "\n",
    "    Returns:\n",
    "        str: URL of the terms page if found, None otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Ensure the URL has a protocol\n",
    "        if not url.startswith(('http://', 'https://')):\n",
    "            url = 'https://' + url\n",
    "        \n",
    "        # Configure headers to avoid blocking\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "            'Accept-Language': 'en-US,en;q=0.5',\n",
    "            'Accept-Encoding': 'gzip, deflate',\n",
    "            'Connection': 'keep-alive',\n",
    "        }\n",
    "        \n",
    "        # Make a request\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Parse HTML\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Possible term link texts (in multiple languages)\n",
    "        terms_texts = [\n",
    "            # English\n",
    "            'terms', 'terms of use', 'terms of service', 'terms and conditions', \n",
    "            'conditions of use', 'user terms', 'service terms', 'legal terms',\n",
    "            'terms & conditions', 'tos', 'terms of service agreement',\n",
    "            \n",
    "            # Spanish\n",
    "            't√©rminos', 't√©rminos de uso', 't√©rminos y condiciones', \n",
    "            'condiciones de uso', 't√©rminos del servicio', 'condiciones',\n",
    "            't√©rminos legales', 'condiciones legales',\n",
    "            \n",
    "            # French\n",
    "            'conditions', 'conditions d\\'utilisation', 'termes', \n",
    "            'conditions g√©n√©rales', 'cgu', 'mentions l√©gales',\n",
    "            \n",
    "            # German\n",
    "            'nutzungsbedingungen', 'gesch√§ftsbedingungen', 'bedingungen',\n",
    "            'agb', 'nutzungsbestimmungen',\n",
    "            \n",
    "            # Dutch\n",
    "            'gebruiksvoorwaarden', 'voorwaarden', 'algemene voorwaarden',\n",
    "            \n",
    "            # Italian\n",
    "            'termini', 'condizioni', 'termini di utilizzo', 'condizioni d\\'uso',\n",
    "            \n",
    "            # Other common patterns\n",
    "            'legal', 'legal notice', 'disclaimer'\n",
    "        ]\n",
    "        \n",
    "        # Search for links that contain texts related to terms\n",
    "        for link in soup.find_all('a', href=True):\n",
    "            link_text = link.get_text(strip=True).lower()\n",
    "            href = link.get('href')\n",
    "            \n",
    "            # Check if the link text contains any term variations\n",
    "            if any(term_text in link_text for term_text in terms_texts):\n",
    "                # Convert to absolute URL if relative\n",
    "                if href.startswith('/'):\n",
    "                    terms_url = urljoin(url, href)\n",
    "                elif href.startswith('http'):\n",
    "                    terms_url = href\n",
    "                else:\n",
    "                    terms_url = urljoin(url, '/' + href)\n",
    "                \n",
    "                return terms_url\n",
    "        \n",
    "        # If not found in links, search in footer or common areas\n",
    "        footer_elements = soup.find_all(['footer', 'div'], class_=re.compile(r'footer|legal|terms', re.I))\n",
    "        for footer in footer_elements:\n",
    "            for link in footer.find_all('a', href=True):\n",
    "                link_text = link.get_text(strip=True).lower()\n",
    "                href = link.get('href')\n",
    "                \n",
    "                if any(term_text in link_text for term_text in terms_texts):\n",
    "                    if href.startswith('/'):\n",
    "                        terms_url = urljoin(url, href)\n",
    "                    elif href.startswith('http'):\n",
    "                        terms_url = href\n",
    "                    else:\n",
    "                        terms_url = urljoin(url, '/' + href)\n",
    "                    \n",
    "                    return terms_url\n",
    "        \n",
    "        # If not found, search for common URLs of term pages\n",
    "        common_terms_paths = [\n",
    "            '/terms', '/terms-of-use', '/terms-of-service', '/terms-and-conditions',\n",
    "            '/tos', '/legal', '/conditions', '/user-terms', '/service-terms',\n",
    "            '/terms.html', '/terms.php', '/legal.html', '/conditions.html',\n",
    "            '/privacy-policy', '/legal-notice', '/disclaimer'\n",
    "        ]\n",
    "        \n",
    "        for path in common_terms_paths:\n",
    "            test_url = urljoin(url, path)\n",
    "            try:\n",
    "                test_response = requests.head(test_url, headers=headers, timeout=5)\n",
    "                if test_response.status_code == 200:\n",
    "                    return test_url\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "        return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing terms in {url}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "834f0f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing terms in https://coastwards.org: HTTPSConnectionPool(host='coastwards.org', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7ff0c45ad790>: Failed to establish a new connection: [Errno 111] Conexi√≥n rehusada'))\n"
     ]
    }
   ],
   "source": [
    "df_platforms['terms_link'] = df_platforms['platform_url'].apply(extract_terms_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "5a2e33a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   platform_url    10 non-null     object \n",
      " 1   active          10 non-null     object \n",
      " 2   platform_about  7 non-null      object \n",
      " 3   year_creation   9 non-null      float64\n",
      " 4   terms_link      7 non-null      object \n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 532.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df_platforms.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cda2588",
   "metadata": {},
   "source": [
    "# privacy_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "4sut8r1kdil",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_privacy_policy_link(url):\n",
    "    \"\"\"\n",
    "    Extracts the privacy policy link from a web page.\n",
    "    Finds common variations of privacy links in multiple languages.\n",
    "\n",
    "    Args:\n",
    "        url (str): Platform URL\n",
    "\n",
    "    Returns:\n",
    "        str: URL of the privacy policy page if found, None otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Ensure the URL has a protocol\n",
    "        if not url.startswith(('http://', 'https://')):\n",
    "            url = 'https://' + url\n",
    "        \n",
    "        # Configure headers to avoid blocking\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "            'Accept-Language': 'en-US,en;q=0.5',\n",
    "            'Accept-Encoding': 'gzip, deflate',\n",
    "            'Connection': 'keep-alive',\n",
    "        }\n",
    "        \n",
    "        # Making request\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Parsing HTML\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Possible privacy link texts (in multiple languages)\n",
    "        privacy_texts = [\n",
    "            # English\n",
    "            'privacy', 'privacy policy', 'privacy notice', 'privacy statement',\n",
    "            'data protection', 'data policy', 'privacy terms', 'privacy agreement',\n",
    "            'data privacy', 'privacy & cookies', 'cookie policy',\n",
    "            \n",
    "            # Spanish\n",
    "            'privacidad', 'pol√≠tica de privacidad', 'aviso de privacidad',\n",
    "            'pol√≠tica de datos', 'protecci√≥n de datos', 't√©rminos de privacidad',\n",
    "            'pol√≠tica de cookies', 'aviso legal', 'protecci√≥n de la privacidad',\n",
    "            \n",
    "            # French\n",
    "            'confidentialit√©', 'politique de confidentialit√©', \n",
    "            'protection des donn√©es', 'vie priv√©e', 'donn√©es personnelles',\n",
    "            'politique de cookies', 'rgpd', 'gdpr',\n",
    "            \n",
    "            # German\n",
    "            'datenschutz', 'datenschutzerkl√§rung', 'datenschutzrichtlinie',\n",
    "            'datenschutzbestimmungen', 'privatsph√§re', 'dsgvo',\n",
    "            \n",
    "            # Dutch\n",
    "            'privacy', 'privacybeleid', 'gegevensbescherming', 'avg',\n",
    "            'privacyverklaring', 'cookiebeleid',\n",
    "            \n",
    "            # Italian\n",
    "            'privacy', 'politica privacy', 'protezione dati', 'riservatezza',\n",
    "            'gdpr', 'informativa privacy', 'politica dei cookie',\n",
    "            \n",
    "            # Other patterns\n",
    "            'gdpr', 'rgpd', 'cookies', 'cookie notice', 'data handling'\n",
    "        ]\n",
    "        \n",
    "        # Search for links that contain privacy-related texts\n",
    "        for link in soup.find_all('a', href=True):\n",
    "            link_text = link.get_text(strip=True).lower()\n",
    "            href = link.get('href')\n",
    "            \n",
    "            # Check if the link text contains any privacy variations\n",
    "            if any(privacy_text in link_text for privacy_text in privacy_texts):\n",
    "                # Convert to absolute URL if relative\n",
    "                if href.startswith('/'):\n",
    "                    privacy_url = urljoin(url, href)\n",
    "                elif href.startswith('http'):\n",
    "                    privacy_url = href\n",
    "                else:\n",
    "                    privacy_url = urljoin(url, '/' + href)\n",
    "                \n",
    "                return privacy_url\n",
    "        \n",
    "        # If not found in main links, search in footer or common areas\n",
    "        footer_elements = soup.find_all(['footer', 'div'], class_=re.compile(r'footer|legal|privacy|cookie', re.I))\n",
    "        for footer in footer_elements:\n",
    "            for link in footer.find_all('a', href=True):\n",
    "                link_text = link.get_text(strip=True).lower()\n",
    "                href = link.get('href')\n",
    "                \n",
    "                if any(privacy_text in link_text for privacy_text in privacy_texts):\n",
    "                    if href.startswith('/'):\n",
    "                        privacy_url = urljoin(url, href)\n",
    "                    elif href.startswith('http'):\n",
    "                        privacy_url = href\n",
    "                    else:\n",
    "                        privacy_url = urljoin(url, '/' + href)\n",
    "                    \n",
    "                    return privacy_url\n",
    "        \n",
    "        # If not found, search for common privacy page URLs\n",
    "        common_privacy_paths = [\n",
    "            '/privacy', '/privacy-policy', '/privacy-notice', '/privacy-statement',\n",
    "            '/data-protection', '/data-policy', '/cookies', '/cookie-policy',\n",
    "            '/privacy.html', '/privacy.php', '/datenschutz', '/confidentialite',\n",
    "            '/privacidad', '/gdpr', '/data-privacy', '/cookie-notice'\n",
    "        ]\n",
    "        \n",
    "        for path in common_privacy_paths:\n",
    "            test_url = urljoin(url, path)\n",
    "            try:\n",
    "                test_response = requests.head(test_url, headers=headers, timeout=5)\n",
    "                if test_response.status_code == 200:\n",
    "                    return test_url\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "        return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error procesando privacidad en {url}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "9891ef5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error procesando privacidad en https://coastwards.org: HTTPSConnectionPool(host='coastwards.org', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7ff0c3af0050>: Failed to establish a new connection: [Errno 111] Conexi√≥n rehusada'))\n"
     ]
    }
   ],
   "source": [
    "df_platforms['privacy_link'] = df_platforms['platform_url'].apply(extract_privacy_policy_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "294d0251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   platform_url    10 non-null     object \n",
      " 1   active          10 non-null     object \n",
      " 2   platform_about  7 non-null      object \n",
      " 3   year_creation   9 non-null      float64\n",
      " 4   terms_link      7 non-null      object \n",
      " 5   privacy_link    7 non-null      object \n",
      "dtypes: float64(1), object(5)\n",
      "memory usage: 612.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df_platforms.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "2a7679ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "platform_url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "active",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "platform_about",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "year_creation",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "terms_link",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "privacy_link",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "627ee158-17dd-4176-be21-6ccb956ae606",
       "rows": [
        [
         "0",
         "observation.org",
         "Status code: 200",
         "https://observation.org/about",
         "2002.0",
         "https://observation.org/terms",
         "https://observation.org/privacy"
        ],
        [
         "1",
         "seasearch.org.uk",
         "Status code: 200",
         "https://www.seasearch.org.uk/about",
         "1999.0",
         "https://www.seasearch.org.uk/website-terms-conditions",
         "https://www.seasearch.org.uk/privacy"
        ],
        [
         "2",
         "natuurpunt.be",
         "Status code: 200",
         "https://natuurpunt.be/dit-is-natuurpunt",
         null,
         "https://natuurpunt.be/algemene-voorwaarden-en-privacy",
         "https://natuurpunt.be/algemene-voorwaarden-en-privacy"
        ],
        [
         "3",
         "slu.se/artdatabanken",
         "Status code: 200",
         null,
         "1989.0",
         null,
         null
        ],
        [
         "4",
         "theroadlab.co.uk",
         "Status code: 200",
         "https://www.theroadlab.co.uk/about",
         "2022.0",
         null,
         null
        ],
        [
         "5",
         "exploreyourshore.ie",
         "Status code: 200",
         "https://exploreyourshore.ie/about-explore-your-shore/",
         "2019.0",
         "https://exploreyourshore.ie/legals/",
         "https://exploreyourshore.ie/cookie-policy/"
        ],
        [
         "6",
         "eyeonwater.org",
         "Status code: 200",
         "https://eyeonwater.org/about-us",
         "2015.0",
         "https://eyeonwater.org/privacy-policy",
         "https://eyeonwater.org/privacy-policy"
        ],
        [
         "7",
         "iseahorse.org",
         "Status code: 200",
         "https://projectseahorse.org/about-us/",
         "2012.0",
         "https://projectseahorse.org/regulating-trade/controlling-legal-trade/",
         "https://projectseahorse.org/privacy-statement-ca/"
        ],
        [
         "8",
         "redpromar.org",
         "Status code: 200",
         null,
         "2020.0",
         "https://redpromar.org/sightings",
         "https://redpromar.org/legal-notice"
        ],
        [
         "9",
         "coastwards.org",
         "Fallo: HTTPSConnectionPool(host='coastwards.org', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7ff0c3ac4610>: Failed to establish a new connection: [Errno 111] Conexi√≥n rehusada'))",
         null,
         "2016.0",
         null,
         null
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>platform_url</th>\n",
       "      <th>active</th>\n",
       "      <th>platform_about</th>\n",
       "      <th>year_creation</th>\n",
       "      <th>terms_link</th>\n",
       "      <th>privacy_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>observation.org</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>https://observation.org/about</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>https://observation.org/terms</td>\n",
       "      <td>https://observation.org/privacy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>seasearch.org.uk</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>https://www.seasearch.org.uk/about</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>https://www.seasearch.org.uk/website-terms-con...</td>\n",
       "      <td>https://www.seasearch.org.uk/privacy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>natuurpunt.be</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>https://natuurpunt.be/dit-is-natuurpunt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://natuurpunt.be/algemene-voorwaarden-en-...</td>\n",
       "      <td>https://natuurpunt.be/algemene-voorwaarden-en-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>slu.se/artdatabanken</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>None</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>theroadlab.co.uk</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>https://www.theroadlab.co.uk/about</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>exploreyourshore.ie</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>https://exploreyourshore.ie/about-explore-your...</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>https://exploreyourshore.ie/legals/</td>\n",
       "      <td>https://exploreyourshore.ie/cookie-policy/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>eyeonwater.org</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>https://eyeonwater.org/about-us</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>https://eyeonwater.org/privacy-policy</td>\n",
       "      <td>https://eyeonwater.org/privacy-policy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>iseahorse.org</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>https://projectseahorse.org/about-us/</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>https://projectseahorse.org/regulating-trade/c...</td>\n",
       "      <td>https://projectseahorse.org/privacy-statement-ca/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>redpromar.org</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>None</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>https://redpromar.org/sightings</td>\n",
       "      <td>https://redpromar.org/legal-notice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>coastwards.org</td>\n",
       "      <td>Fallo: HTTPSConnectionPool(host='coastwards.or...</td>\n",
       "      <td>None</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           platform_url                                             active  \\\n",
       "0       observation.org                                   Status code: 200   \n",
       "1      seasearch.org.uk                                   Status code: 200   \n",
       "2         natuurpunt.be                                   Status code: 200   \n",
       "3  slu.se/artdatabanken                                   Status code: 200   \n",
       "4      theroadlab.co.uk                                   Status code: 200   \n",
       "5   exploreyourshore.ie                                   Status code: 200   \n",
       "6        eyeonwater.org                                   Status code: 200   \n",
       "7         iseahorse.org                                   Status code: 200   \n",
       "8         redpromar.org                                   Status code: 200   \n",
       "9        coastwards.org  Fallo: HTTPSConnectionPool(host='coastwards.or...   \n",
       "\n",
       "                                      platform_about  year_creation  \\\n",
       "0                      https://observation.org/about         2002.0   \n",
       "1                 https://www.seasearch.org.uk/about         1999.0   \n",
       "2            https://natuurpunt.be/dit-is-natuurpunt            NaN   \n",
       "3                                               None         1989.0   \n",
       "4                 https://www.theroadlab.co.uk/about         2022.0   \n",
       "5  https://exploreyourshore.ie/about-explore-your...         2019.0   \n",
       "6                    https://eyeonwater.org/about-us         2015.0   \n",
       "7              https://projectseahorse.org/about-us/         2012.0   \n",
       "8                                               None         2020.0   \n",
       "9                                               None         2016.0   \n",
       "\n",
       "                                          terms_link  \\\n",
       "0                      https://observation.org/terms   \n",
       "1  https://www.seasearch.org.uk/website-terms-con...   \n",
       "2  https://natuurpunt.be/algemene-voorwaarden-en-...   \n",
       "3                                               None   \n",
       "4                                               None   \n",
       "5                https://exploreyourshore.ie/legals/   \n",
       "6              https://eyeonwater.org/privacy-policy   \n",
       "7  https://projectseahorse.org/regulating-trade/c...   \n",
       "8                    https://redpromar.org/sightings   \n",
       "9                                               None   \n",
       "\n",
       "                                        privacy_link  \n",
       "0                    https://observation.org/privacy  \n",
       "1               https://www.seasearch.org.uk/privacy  \n",
       "2  https://natuurpunt.be/algemene-voorwaarden-en-...  \n",
       "3                                               None  \n",
       "4                                               None  \n",
       "5         https://exploreyourshore.ie/cookie-policy/  \n",
       "6              https://eyeonwater.org/privacy-policy  \n",
       "7  https://projectseahorse.org/privacy-statement-ca/  \n",
       "8                 https://redpromar.org/legal-notice  \n",
       "9                                               None  "
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_platforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd1cb2b",
   "metadata": {},
   "source": [
    "# code_repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "wwxeu58km5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_code_repository_link(url):\n",
    "    \"\"\"\n",
    "    Extracts the link to a web platform's code repository.\n",
    "    Searches for links to GitHub, GitLab, Bitbucket, and other code repositories.\n",
    "\n",
    "    Args:\n",
    "        url (str): Platform URL\n",
    "\n",
    "    Returns:\n",
    "        str: Code repository URL if found, None otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not url.startswith(('http://', 'https://')):\n",
    "            url = 'https://' + url\n",
    "        \n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "            'Accept-Language': 'en-US,en;q=0.5',\n",
    "            'Accept-Encoding': 'gzip, deflate',\n",
    "            'Connection': 'keep-alive',\n",
    "        }\n",
    "        \n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Known code repository domains\n",
    "        repo_domains = [\n",
    "            'github.com', 'gitlab.com', 'bitbucket.org', 'sourceforge.net',\n",
    "            'codeberg.org', 'git.sr.ht', 'gitea.com', 'gitee.com'\n",
    "        ]\n",
    "        \n",
    "        # HIGH PRIORITY: Find direct links to known repositories\n",
    "        for link in soup.find_all('a', href=True):\n",
    "            href = link.get('href')\n",
    "            \n",
    "            # Check if the link points to a known repository\n",
    "            for domain in repo_domains:\n",
    "                if domain in href:\n",
    "                    # Verify that it is not just the main domain and that it is a valid repo\n",
    "                    if href.count('/') >= 2 and not href.endswith(domain):\n",
    "                        # Check that it does not end in extensions that are not repos\n",
    "                        if not any(ext in href.lower() for ext in ['.png', '.jpg', '.gif', '.svg', '.css', '.js']):\n",
    "                            return href\n",
    "        \n",
    "        # Search for very specific texts in source code\n",
    "        specific_repo_texts = [\n",
    "            'source code', 'github', 'gitlab', 'view source', 'download source',\n",
    "            'fork on github', 'clone', 'git repository', 'c√≥digo fuente'\n",
    "        ]\n",
    "        \n",
    "        # Search for links with VERY specific text from repositories\n",
    "        for link in soup.find_all('a', href=True):\n",
    "            link_text = link.get_text(strip=True).lower()\n",
    "            href = link.get('href')\n",
    "            \n",
    "            # Only search for very specific texts that point to known domains\n",
    "            if any(specific_text in link_text for specific_text in specific_repo_texts):\n",
    "                for domain in repo_domains:\n",
    "                    if domain in href:\n",
    "                        return href\n",
    "        \n",
    "        # Search developer/footer areas with strict criteria\n",
    "        developer_areas = soup.find_all(['footer', 'div'], \n",
    "                                      class_=re.compile(r'developer|code|source|footer', re.I))\n",
    "        \n",
    "        for area in developer_areas:\n",
    "            for link in area.find_all('a', href=True):\n",
    "                href = link.get('href')\n",
    "                link_text = link.get_text(strip=True).lower()\n",
    "                \n",
    "                # Only search known domains with very specific text\n",
    "                for domain in repo_domains:\n",
    "                    if domain in href and any(text in link_text for text in specific_repo_texts):\n",
    "                        return href\n",
    "        \n",
    "        # Search in meta tags (known domains only)\n",
    "        meta_tags = soup.find_all('meta')\n",
    "        for meta in meta_tags:\n",
    "            content = meta.get('content', '')\n",
    "            for domain in repo_domains:\n",
    "                if domain in content and content.count('/') >= 2:\n",
    "                    return content\n",
    "        \n",
    "        # 5. Search GitHub badges (very specific)\n",
    "        for img in soup.find_all('img'):\n",
    "            src = img.get('src', '')\n",
    "            if 'shields.io' in src and 'github' in src:\n",
    "                parent_link = img.find_parent('a')\n",
    "                if parent_link and parent_link.get('href'):\n",
    "                    href = parent_link.get('href')\n",
    "                    if 'github.com' in href:\n",
    "                        return href\n",
    "                \n",
    "        return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing repository in {url}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "h2xfzlbcg7r",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing repository in https://coastwards.org: HTTPSConnectionPool(host='coastwards.org', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7ff0c45ae590>: Failed to establish a new connection: [Errno 111] Conexi√≥n rehusada'))\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "platform_url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "active",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "platform_about",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "year_creation",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "terms_link",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "privacy_link",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "code_repository",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "10288fdf-552f-4a80-86b8-0f630a70c86e",
       "rows": [
        [
         "0",
         "observation.org",
         "Status code: 200",
         "https://observation.org/about",
         "2002.0",
         "https://observation.org/terms",
         "https://observation.org/privacy",
         "https://github.com/TecharoHQ/anubis"
        ],
        [
         "1",
         "seasearch.org.uk",
         "Status code: 200",
         "https://www.seasearch.org.uk/about",
         "1999.0",
         "https://www.seasearch.org.uk/website-terms-conditions",
         "https://www.seasearch.org.uk/privacy",
         null
        ],
        [
         "2",
         "natuurpunt.be",
         "Status code: 200",
         "https://natuurpunt.be/dit-is-natuurpunt",
         null,
         "https://natuurpunt.be/algemene-voorwaarden-en-privacy",
         "https://natuurpunt.be/algemene-voorwaarden-en-privacy",
         null
        ],
        [
         "3",
         "slu.se/artdatabanken",
         "Status code: 200",
         null,
         "1989.0",
         null,
         null,
         null
        ],
        [
         "4",
         "theroadlab.co.uk",
         "Status code: 200",
         "https://www.theroadlab.co.uk/about",
         "2022.0",
         null,
         null,
         null
        ],
        [
         "5",
         "exploreyourshore.ie",
         "Status code: 200",
         "https://exploreyourshore.ie/about-explore-your-shore/",
         "2019.0",
         "https://exploreyourshore.ie/legals/",
         "https://exploreyourshore.ie/cookie-policy/",
         null
        ],
        [
         "6",
         "eyeonwater.org",
         "Status code: 200",
         "https://eyeonwater.org/about-us",
         "2015.0",
         "https://eyeonwater.org/privacy-policy",
         "https://eyeonwater.org/privacy-policy",
         null
        ],
        [
         "7",
         "iseahorse.org",
         "Status code: 200",
         "https://projectseahorse.org/about-us/",
         "2012.0",
         "https://projectseahorse.org/regulating-trade/controlling-legal-trade/",
         "https://projectseahorse.org/privacy-statement-ca/",
         null
        ],
        [
         "8",
         "redpromar.org",
         "Status code: 200",
         null,
         "2020.0",
         "https://redpromar.org/sightings",
         "https://redpromar.org/legal-notice",
         null
        ],
        [
         "9",
         "coastwards.org",
         "Fallo: HTTPSConnectionPool(host='coastwards.org', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7ff0c3ac4610>: Failed to establish a new connection: [Errno 111] Conexi√≥n rehusada'))",
         null,
         "2016.0",
         null,
         null,
         null
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>platform_url</th>\n",
       "      <th>active</th>\n",
       "      <th>platform_about</th>\n",
       "      <th>year_creation</th>\n",
       "      <th>terms_link</th>\n",
       "      <th>privacy_link</th>\n",
       "      <th>code_repository</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>observation.org</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>https://observation.org/about</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>https://observation.org/terms</td>\n",
       "      <td>https://observation.org/privacy</td>\n",
       "      <td>https://github.com/TecharoHQ/anubis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>seasearch.org.uk</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>https://www.seasearch.org.uk/about</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>https://www.seasearch.org.uk/website-terms-con...</td>\n",
       "      <td>https://www.seasearch.org.uk/privacy</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>natuurpunt.be</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>https://natuurpunt.be/dit-is-natuurpunt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://natuurpunt.be/algemene-voorwaarden-en-...</td>\n",
       "      <td>https://natuurpunt.be/algemene-voorwaarden-en-...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>slu.se/artdatabanken</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>None</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>theroadlab.co.uk</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>https://www.theroadlab.co.uk/about</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>exploreyourshore.ie</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>https://exploreyourshore.ie/about-explore-your...</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>https://exploreyourshore.ie/legals/</td>\n",
       "      <td>https://exploreyourshore.ie/cookie-policy/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>eyeonwater.org</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>https://eyeonwater.org/about-us</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>https://eyeonwater.org/privacy-policy</td>\n",
       "      <td>https://eyeonwater.org/privacy-policy</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>iseahorse.org</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>https://projectseahorse.org/about-us/</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>https://projectseahorse.org/regulating-trade/c...</td>\n",
       "      <td>https://projectseahorse.org/privacy-statement-ca/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>redpromar.org</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>None</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>https://redpromar.org/sightings</td>\n",
       "      <td>https://redpromar.org/legal-notice</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>coastwards.org</td>\n",
       "      <td>Fallo: HTTPSConnectionPool(host='coastwards.or...</td>\n",
       "      <td>None</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           platform_url                                             active  \\\n",
       "0       observation.org                                   Status code: 200   \n",
       "1      seasearch.org.uk                                   Status code: 200   \n",
       "2         natuurpunt.be                                   Status code: 200   \n",
       "3  slu.se/artdatabanken                                   Status code: 200   \n",
       "4      theroadlab.co.uk                                   Status code: 200   \n",
       "5   exploreyourshore.ie                                   Status code: 200   \n",
       "6        eyeonwater.org                                   Status code: 200   \n",
       "7         iseahorse.org                                   Status code: 200   \n",
       "8         redpromar.org                                   Status code: 200   \n",
       "9        coastwards.org  Fallo: HTTPSConnectionPool(host='coastwards.or...   \n",
       "\n",
       "                                      platform_about  year_creation  \\\n",
       "0                      https://observation.org/about         2002.0   \n",
       "1                 https://www.seasearch.org.uk/about         1999.0   \n",
       "2            https://natuurpunt.be/dit-is-natuurpunt            NaN   \n",
       "3                                               None         1989.0   \n",
       "4                 https://www.theroadlab.co.uk/about         2022.0   \n",
       "5  https://exploreyourshore.ie/about-explore-your...         2019.0   \n",
       "6                    https://eyeonwater.org/about-us         2015.0   \n",
       "7              https://projectseahorse.org/about-us/         2012.0   \n",
       "8                                               None         2020.0   \n",
       "9                                               None         2016.0   \n",
       "\n",
       "                                          terms_link  \\\n",
       "0                      https://observation.org/terms   \n",
       "1  https://www.seasearch.org.uk/website-terms-con...   \n",
       "2  https://natuurpunt.be/algemene-voorwaarden-en-...   \n",
       "3                                               None   \n",
       "4                                               None   \n",
       "5                https://exploreyourshore.ie/legals/   \n",
       "6              https://eyeonwater.org/privacy-policy   \n",
       "7  https://projectseahorse.org/regulating-trade/c...   \n",
       "8                    https://redpromar.org/sightings   \n",
       "9                                               None   \n",
       "\n",
       "                                        privacy_link  \\\n",
       "0                    https://observation.org/privacy   \n",
       "1               https://www.seasearch.org.uk/privacy   \n",
       "2  https://natuurpunt.be/algemene-voorwaarden-en-...   \n",
       "3                                               None   \n",
       "4                                               None   \n",
       "5         https://exploreyourshore.ie/cookie-policy/   \n",
       "6              https://eyeonwater.org/privacy-policy   \n",
       "7  https://projectseahorse.org/privacy-statement-ca/   \n",
       "8                 https://redpromar.org/legal-notice   \n",
       "9                                               None   \n",
       "\n",
       "                       code_repository  \n",
       "0  https://github.com/TecharoHQ/anubis  \n",
       "1                                 None  \n",
       "2                                 None  \n",
       "3                                 None  \n",
       "4                                 None  \n",
       "5                                 None  \n",
       "6                                 None  \n",
       "7                                 None  \n",
       "8                                 None  \n",
       "9                                 None  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_platforms['code_repository'] = df_platforms['platform_url'].apply(extract_code_repository_link)\n",
    "\n",
    "df_platforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "b52ad995",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_platforms.to_csv(\"../data/df_platforms.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab18835",
   "metadata": {},
   "source": [
    "# language_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "d2dd351e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['programming_language2'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[172]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdf_platforms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mprogramming_language2\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/RIECS_CS_infrastructures/.venv/lib/python3.11/site-packages/pandas/core/frame.py:5588\u001b[39m, in \u001b[36mDataFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   5440\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdrop\u001b[39m(\n\u001b[32m   5441\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   5442\u001b[39m     labels: IndexLabel | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5449\u001b[39m     errors: IgnoreRaise = \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   5450\u001b[39m ) -> DataFrame | \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5451\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   5452\u001b[39m \u001b[33;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[32m   5453\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   5586\u001b[39m \u001b[33;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[32m   5587\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5588\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5589\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5590\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5591\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5592\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5593\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5594\u001b[39m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5595\u001b[39m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5596\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/RIECS_CS_infrastructures/.venv/lib/python3.11/site-packages/pandas/core/generic.py:4807\u001b[39m, in \u001b[36mNDFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   4805\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes.items():\n\u001b[32m   4806\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4807\u001b[39m         obj = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4809\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[32m   4810\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_inplace(obj)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/RIECS_CS_infrastructures/.venv/lib/python3.11/site-packages/pandas/core/generic.py:4849\u001b[39m, in \u001b[36mNDFrame._drop_axis\u001b[39m\u001b[34m(self, labels, axis, level, errors, only_slice)\u001b[39m\n\u001b[32m   4847\u001b[39m         new_axis = axis.drop(labels, level=level, errors=errors)\n\u001b[32m   4848\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4849\u001b[39m         new_axis = \u001b[43maxis\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4850\u001b[39m     indexer = axis.get_indexer(new_axis)\n\u001b[32m   4852\u001b[39m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[32m   4853\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/RIECS_CS_infrastructures/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:7136\u001b[39m, in \u001b[36mIndex.drop\u001b[39m\u001b[34m(self, labels, errors)\u001b[39m\n\u001b[32m   7134\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mask.any():\n\u001b[32m   7135\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors != \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m7136\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask].tolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found in axis\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   7137\u001b[39m     indexer = indexer[~mask]\n\u001b[32m   7138\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.delete(indexer)\n",
      "\u001b[31mKeyError\u001b[39m: \"['programming_language2'] not found in axis\""
     ]
    }
   ],
   "source": [
    "df_platforms.drop(columns=['programming_language2'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb078ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_website_tech(url, timeout=10):\n",
    "    \"\"\"\n",
    "    Analyzes a URL to detect web technologies used    \n",
    "    \"\"\"\n",
    "    result = {\n",
    "        'url': url,\n",
    "        'technologies': [],\n",
    "        'language': None,\n",
    "        'framework': None,\n",
    "        'server': None,\n",
    "        'headers': {},\n",
    "        'status_code': None,\n",
    "        'error': None\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Asegurar que la URL tenga protocolo\n",
    "        if not url.startswith(('http://', 'https://')):\n",
    "            url = 'https://' + url\n",
    "            \n",
    "        # Make HTTP request\n",
    "        response = requests.get(url, timeout=timeout, allow_redirects=True)\n",
    "        result['status_code'] = response.status_code\n",
    "        \n",
    "        # Analyze headers\n",
    "        headers = response.headers\n",
    "        result['headers'] = dict(headers)\n",
    "        \n",
    "        # Get HTML content\n",
    "        html_content = response.text.lower()\n",
    "        \n",
    "        # Detect technologies by headers\n",
    "        tech_info = detect_tech_from_headers(headers)\n",
    "        result.update(tech_info)\n",
    "        \n",
    "        # Detect technologies by HTML content\n",
    "        html_tech = detect_tech_from_html(html_content)\n",
    "        result['technologies'].extend(html_tech)\n",
    "        \n",
    "        # Detect by URL patterns\n",
    "        url_tech = detect_tech_from_url(url)\n",
    "        result['technologies'].extend(url_tech)\n",
    "        \n",
    "        # Determine primary language\n",
    "        result['language'] = determine_primary_language(result)\n",
    "        \n",
    "        # Drop duplicates\n",
    "        result['technologies'] = list(set(result['technologies']))\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        result['error'] = str(e)\n",
    "    except Exception as e:\n",
    "        result['error'] = f\"Unexpected error: {str(e)}\"\n",
    "    \n",
    "    return result\n",
    "\n",
    "def detect_tech_from_headers(headers):\n",
    "    \"\"\"Detects technologies based on HTTP headers\"\"\"\n",
    "    tech_info = {\n",
    "        'technologies': [],\n",
    "        'language': None,\n",
    "        'framework': None,\n",
    "        'server': None\n",
    "    }\n",
    "    \n",
    "    # Convert headers to lowercase for search\n",
    "    headers_lower = {k.lower(): v for k, v in headers.items()}\n",
    "    \n",
    "    # Detect web server\n",
    "    if 'server' in headers_lower:\n",
    "        server = headers_lower['server']\n",
    "        tech_info['server'] = server\n",
    "        \n",
    "        if 'apache' in server.lower():\n",
    "            tech_info['technologies'].append('Apache')\n",
    "        if 'nginx' in server.lower():\n",
    "            tech_info['technologies'].append('Nginx')\n",
    "        if 'iis' in server.lower():\n",
    "            tech_info['technologies'].append('IIS')\n",
    "    \n",
    "    # Detect language by specific headers\n",
    "    if 'x-powered-by' in headers_lower:\n",
    "        powered_by = headers_lower['x-powered-by'].lower()\n",
    "        \n",
    "        if 'php' in powered_by:\n",
    "            tech_info['language'] = 'PHP'\n",
    "            tech_info['technologies'].append('PHP')\n",
    "        elif 'asp.net' in powered_by:\n",
    "            tech_info['language'] = 'ASP.NET'\n",
    "            tech_info['technologies'].append('ASP.NET')\n",
    "        elif 'express' in powered_by:\n",
    "            tech_info['language'] = 'Node.js'\n",
    "            tech_info['technologies'].append('Node.js')\n",
    "            tech_info['technologies'].append('Express')\n",
    "    \n",
    "    # Detect Ruby on Rails\n",
    "    if 'x-runtime' in headers_lower:\n",
    "        tech_info['language'] = 'Ruby'\n",
    "        tech_info['framework'] = 'Ruby on Rails'\n",
    "        tech_info['technologies'].append('Ruby on Rails')\n",
    "    \n",
    "    # Detect by cookies\n",
    "    if 'set-cookie' in headers_lower:\n",
    "        cookies = headers_lower['set-cookie'].lower()\n",
    "        \n",
    "        if 'phpsessid' in cookies:\n",
    "            tech_info['language'] = 'PHP'\n",
    "            tech_info['technologies'].append('PHP')\n",
    "        elif 'jsessionid' in cookies:\n",
    "            tech_info['language'] = 'Java'\n",
    "            tech_info['technologies'].append('Java')\n",
    "        elif '_session_id' in cookies and 'rails' in cookies:\n",
    "            tech_info['language'] = 'Ruby'\n",
    "            tech_info['technologies'].append('Ruby on Rails')\n",
    "    \n",
    "    # Detect CloudFlare\n",
    "    if 'cf-ray' in headers_lower:\n",
    "        tech_info['technologies'].append('CloudFlare')\n",
    "    \n",
    "    return tech_info\n",
    "\n",
    "def detect_tech_from_html(html_content):\n",
    "    \"\"\"Detects technologies by analyzing HTML content\"\"\"\n",
    "    technologies = []\n",
    "    \n",
    "    # WordPress\n",
    "    if any(indicator in html_content for indicator in [\n",
    "        'wp-content', 'wp-includes', 'wordpress', '/wp-json/'\n",
    "    ]):\n",
    "        technologies.append('WordPress')\n",
    "    \n",
    "    # Drupal\n",
    "    if any(indicator in html_content for indicator in [\n",
    "        'drupal', 'sites/default/files', 'misc/drupal.js'\n",
    "    ]):\n",
    "        technologies.append('Drupal')\n",
    "    \n",
    "    # Joomla\n",
    "    if any(indicator in html_content for indicator in [\n",
    "        'joomla', 'option=com_', 'joomla.org'\n",
    "    ]):\n",
    "        technologies.append('Joomla')\n",
    "    \n",
    "    # React\n",
    "    if any(indicator in html_content for indicator in [\n",
    "        'react', 'data-reactroot', '__react', 'react-dom'\n",
    "    ]):\n",
    "        technologies.append('React')\n",
    "    \n",
    "    # Vue.js\n",
    "    if any(indicator in html_content for indicator in [\n",
    "        'vue.js', 'vue.min.js', 'v-if=', 'v-for='\n",
    "    ]):\n",
    "        technologies.append('Vue.js')\n",
    "    \n",
    "    # Angular\n",
    "    if any(indicator in html_content for indicator in [\n",
    "        'angular', 'ng-app', 'ng-controller', 'angular.min.js'\n",
    "    ]):\n",
    "        technologies.append('Angular')\n",
    "    \n",
    "    # jQuery\n",
    "    if any(indicator in html_content for indicator in [\n",
    "        'jquery', 'jquery.min.js', '$.fn.jquery'\n",
    "    ]):\n",
    "        technologies.append('jQuery')\n",
    "    \n",
    "    # Bootstrap\n",
    "    if any(indicator in html_content for indicator in [\n",
    "        'bootstrap', 'bootstrap.min.css', 'bootstrap.css'\n",
    "    ]):\n",
    "        technologies.append('Bootstrap')\n",
    "    \n",
    "    # Django (Python)\n",
    "    if any(indicator in html_content for indicator in [\n",
    "        'csrfmiddlewaretoken', 'django', '__admin_media_prefix__'\n",
    "    ]):\n",
    "        technologies.append('Django')\n",
    "    \n",
    "    # Laravel (PHP)\n",
    "    if any(indicator in html_content for indicator in [\n",
    "        'laravel_session', 'laravel', 'csrf-token'\n",
    "    ]):\n",
    "        technologies.append('Laravel')\n",
    "    \n",
    "    # Ruby on Rails\n",
    "    if any(indicator in html_content for indicator in [\n",
    "        'csrf-param', 'csrf-token', 'rails', 'data-method='\n",
    "    ]):\n",
    "        technologies.append('Ruby on Rails')\n",
    "    \n",
    "    # Google Analytics\n",
    "    if any(indicator in html_content for indicator in [\n",
    "        'google-analytics', 'gtag(', 'ga('\n",
    "    ]):\n",
    "        technologies.append('Google Analytics')\n",
    "    \n",
    "    return technologies\n",
    "\n",
    "def detect_tech_from_url(url):\n",
    "    \"\"\"Detects technologies based on URL patterns\"\"\"\n",
    "    technologies = []\n",
    "    \n",
    "    # Analyze file extensions\n",
    "    if '.php' in url:\n",
    "        technologies.append('PHP')\n",
    "    elif '.asp' in url or '.aspx' in url:\n",
    "        technologies.append('ASP.NET')\n",
    "    elif '.jsp' in url:\n",
    "        technologies.append('Java')\n",
    "    elif '.py' in url:\n",
    "        technologies.append('Python')\n",
    "    elif '.rb' in url:\n",
    "        technologies.append('Ruby')\n",
    "    elif '.cfm' in url:\n",
    "        technologies.append('ColdFusion')\n",
    "    \n",
    "    # WordPress specific patterns\n",
    "    if any(pattern in url for pattern in ['/wp-content/', '/wp-admin/', '/wp-includes/']):\n",
    "        technologies.append('WordPress')\n",
    "    \n",
    "    # Drupal patterns\n",
    "    if any(pattern in url for pattern in ['/node/', '/admin/config/']):\n",
    "        technologies.append('Drupal')\n",
    "    \n",
    "    return technologies\n",
    "\n",
    "def determine_primary_language(result):\n",
    "    \"\"\"Determine the primary language based on all the information\"\"\"\n",
    "    technologies = result['technologies']\n",
    "    \n",
    "    # Prioridad por frameworks espec√≠ficos\n",
    "    if 'Ruby on Rails' in technologies:\n",
    "        return 'Ruby'\n",
    "    elif 'Django' in technologies:\n",
    "        return 'Python'\n",
    "    elif 'Laravel' in technologies:\n",
    "        return 'PHP'\n",
    "    elif 'ASP.NET' in technologies:\n",
    "        return 'ASP.NET'\n",
    "    elif 'PHP' in technologies or 'WordPress' in technologies:\n",
    "        return 'PHP'\n",
    "    elif 'Java' in technologies:\n",
    "        return 'Java'\n",
    "    elif 'Node.js' in technologies:\n",
    "        return 'JavaScript (Node.js)'\n",
    "    elif any(js_tech in technologies for js_tech in ['React', 'Vue.js', 'Angular']):\n",
    "        return 'JavaScript'\n",
    "    elif result['language'] is not None:\n",
    "        return result['language']\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c93012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n que retorna solo el lenguaje\n",
    "def get_language(url):\n",
    "    try:\n",
    "        result = analyze_website_tech(url)\n",
    "        return result['language']\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "df_platforms['programming_language'] = df_platforms['platform_url'].apply(get_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0e9750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "programming_language",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "fe1ae71b-dda3-4dfe-83b7-045ba1ae6834",
       "rows": [
        [
         "0",
         "Python"
        ],
        [
         "1",
         "Ruby"
        ],
        [
         "2",
         null
        ],
        [
         "3",
         "ASP.NET"
        ],
        [
         "4",
         "JavaScript"
        ],
        [
         "5",
         "PHP"
        ],
        [
         "6",
         null
        ],
        [
         "7",
         "PHP"
        ],
        [
         "8",
         "Ruby"
        ],
        [
         "9",
         null
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 10
       }
      },
      "text/plain": [
       "0        Python\n",
       "1          Ruby\n",
       "2          None\n",
       "3       ASP.NET\n",
       "4    JavaScript\n",
       "5           PHP\n",
       "6          None\n",
       "7           PHP\n",
       "8          Ruby\n",
       "9          None\n",
       "Name: programming_language, dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_platforms.programming_language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adab0bc4",
   "metadata": {},
   "source": [
    "**NOTE:**\n",
    "* **PHP**: frameworks like Laravel, Symfony, CodeIgniter... and CMS like WordPress, Drupal, Joomla...\n",
    "* **JavaScript**: frontends like React, Vue.js, Angular, jQuery... and backends like Node.js or Express.js."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc889e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_platforms.to_csv(\"../data/df_platforms.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7418ca1",
   "metadata": {},
   "source": [
    "# governance_explicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2759c533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "platform_url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "active",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "platform_about",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "year_creation",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "terms_link",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "privacy_link",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "code_repository",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "programming_language",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "2a4842e7-e87e-4bfb-a41e-6228111df7b7",
       "rows": [
        [
         "0",
         "observation.org",
         "Status code: 200",
         "https://observation.org/about",
         "2002",
         "https://observation.org/terms",
         "https://observation.org/privacy",
         "https://github.com/TecharoHQ/anubis",
         "Python"
        ],
        [
         "1",
         "seasearch.org.uk",
         "Status code: 200",
         "https://www.seasearch.org.uk/about",
         "1999",
         "https://www.seasearch.org.uk/website-terms-conditions",
         "https://www.seasearch.org.uk/privacy",
         null,
         "Ruby"
        ],
        [
         "2",
         "natuurpunt.be",
         "Status code: 200",
         "https://natuurpunt.be/dit-is-natuurpunt",
         "2001",
         "https://natuurpunt.be/algemene-voorwaarden-en-privacy",
         "https://natuurpunt.be/algemene-voorwaarden-en-privacy",
         null,
         null
        ],
        [
         "3",
         "slu.se/artdatabanken",
         "Status code: 200",
         null,
         "1989",
         null,
         null,
         null,
         "ASP.NET"
        ],
        [
         "4",
         "theroadlab.co.uk",
         "Status code: 200",
         "https://www.theroadlab.co.uk/about",
         "2022",
         null,
         null,
         null,
         "JavaScript"
        ],
        [
         "5",
         "exploreyourshore.ie",
         "Status code: 200",
         "https://exploreyourshore.ie/about-explore-your-shore/",
         "2019",
         "https://exploreyourshore.ie/legals/",
         "https://exploreyourshore.ie/cookie-policy/",
         null,
         "PHP"
        ],
        [
         "6",
         "eyeonwater.org",
         "Status code: 200",
         "https://eyeonwater.org/about-us",
         "2015",
         "https://eyeonwater.org/privacy-policy",
         "https://eyeonwater.org/privacy-policy",
         null,
         null
        ],
        [
         "7",
         "iseahorse.org",
         "Status code: 200",
         "https://projectseahorse.org/about-us/",
         "2012",
         "https://projectseahorse.org/regulating-trade/controlling-legal-trade/",
         "https://projectseahorse.org/privacy-statement-ca/",
         null,
         "PHP"
        ],
        [
         "8",
         "redpromar.org",
         "Status code: 200",
         null,
         "2020",
         "https://redpromar.org/sightings",
         "https://redpromar.org/legal-notice",
         null,
         "Ruby"
        ],
        [
         "9",
         "coastwards.org",
         "Fallo: HTTPSConnectionPool(host='coastwards.org', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fbae1b96e10>: Failed to establish a new connection: [Errno 111] Connection refused'))",
         null,
         "2016",
         null,
         null,
         null,
         null
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>platform_url</th>\n",
       "      <th>active</th>\n",
       "      <th>platform_about</th>\n",
       "      <th>year_creation</th>\n",
       "      <th>terms_link</th>\n",
       "      <th>privacy_link</th>\n",
       "      <th>code_repository</th>\n",
       "      <th>programming_language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>observation.org</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>https://observation.org/about</td>\n",
       "      <td>2002</td>\n",
       "      <td>https://observation.org/terms</td>\n",
       "      <td>https://observation.org/privacy</td>\n",
       "      <td>https://github.com/TecharoHQ/anubis</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>seasearch.org.uk</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>https://www.seasearch.org.uk/about</td>\n",
       "      <td>1999</td>\n",
       "      <td>https://www.seasearch.org.uk/website-terms-con...</td>\n",
       "      <td>https://www.seasearch.org.uk/privacy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ruby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>natuurpunt.be</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>https://natuurpunt.be/dit-is-natuurpunt</td>\n",
       "      <td>2001</td>\n",
       "      <td>https://natuurpunt.be/algemene-voorwaarden-en-...</td>\n",
       "      <td>https://natuurpunt.be/algemene-voorwaarden-en-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>slu.se/artdatabanken</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1989</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ASP.NET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>theroadlab.co.uk</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>https://www.theroadlab.co.uk/about</td>\n",
       "      <td>2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>exploreyourshore.ie</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>https://exploreyourshore.ie/about-explore-your...</td>\n",
       "      <td>2019</td>\n",
       "      <td>https://exploreyourshore.ie/legals/</td>\n",
       "      <td>https://exploreyourshore.ie/cookie-policy/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PHP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>eyeonwater.org</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>https://eyeonwater.org/about-us</td>\n",
       "      <td>2015</td>\n",
       "      <td>https://eyeonwater.org/privacy-policy</td>\n",
       "      <td>https://eyeonwater.org/privacy-policy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>iseahorse.org</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>https://projectseahorse.org/about-us/</td>\n",
       "      <td>2012</td>\n",
       "      <td>https://projectseahorse.org/regulating-trade/c...</td>\n",
       "      <td>https://projectseahorse.org/privacy-statement-ca/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PHP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>redpromar.org</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "      <td>https://redpromar.org/sightings</td>\n",
       "      <td>https://redpromar.org/legal-notice</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ruby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>coastwards.org</td>\n",
       "      <td>Fallo: HTTPSConnectionPool(host='coastwards.or...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           platform_url                                             active  \\\n",
       "0       observation.org                                   Status code: 200   \n",
       "1      seasearch.org.uk                                   Status code: 200   \n",
       "2         natuurpunt.be                                   Status code: 200   \n",
       "3  slu.se/artdatabanken                                   Status code: 200   \n",
       "4      theroadlab.co.uk                                   Status code: 200   \n",
       "5   exploreyourshore.ie                                   Status code: 200   \n",
       "6        eyeonwater.org                                   Status code: 200   \n",
       "7         iseahorse.org                                   Status code: 200   \n",
       "8         redpromar.org                                   Status code: 200   \n",
       "9        coastwards.org  Fallo: HTTPSConnectionPool(host='coastwards.or...   \n",
       "\n",
       "                                      platform_about  year_creation  \\\n",
       "0                      https://observation.org/about           2002   \n",
       "1                 https://www.seasearch.org.uk/about           1999   \n",
       "2            https://natuurpunt.be/dit-is-natuurpunt           2001   \n",
       "3                                                NaN           1989   \n",
       "4                 https://www.theroadlab.co.uk/about           2022   \n",
       "5  https://exploreyourshore.ie/about-explore-your...           2019   \n",
       "6                    https://eyeonwater.org/about-us           2015   \n",
       "7              https://projectseahorse.org/about-us/           2012   \n",
       "8                                                NaN           2020   \n",
       "9                                                NaN           2016   \n",
       "\n",
       "                                          terms_link  \\\n",
       "0                      https://observation.org/terms   \n",
       "1  https://www.seasearch.org.uk/website-terms-con...   \n",
       "2  https://natuurpunt.be/algemene-voorwaarden-en-...   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "5                https://exploreyourshore.ie/legals/   \n",
       "6              https://eyeonwater.org/privacy-policy   \n",
       "7  https://projectseahorse.org/regulating-trade/c...   \n",
       "8                    https://redpromar.org/sightings   \n",
       "9                                                NaN   \n",
       "\n",
       "                                        privacy_link  \\\n",
       "0                    https://observation.org/privacy   \n",
       "1               https://www.seasearch.org.uk/privacy   \n",
       "2  https://natuurpunt.be/algemene-voorwaarden-en-...   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "5         https://exploreyourshore.ie/cookie-policy/   \n",
       "6              https://eyeonwater.org/privacy-policy   \n",
       "7  https://projectseahorse.org/privacy-statement-ca/   \n",
       "8                 https://redpromar.org/legal-notice   \n",
       "9                                                NaN   \n",
       "\n",
       "                       code_repository programming_language  \n",
       "0  https://github.com/TecharoHQ/anubis               Python  \n",
       "1                                  NaN                 Ruby  \n",
       "2                                  NaN                  NaN  \n",
       "3                                  NaN              ASP.NET  \n",
       "4                                  NaN           JavaScript  \n",
       "5                                  NaN                  PHP  \n",
       "6                                  NaN                  NaN  \n",
       "7                                  NaN                  PHP  \n",
       "8                                  NaN                 Ruby  \n",
       "9                                  NaN                  NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_platforms = pd.read_csv(\"../data/df_platforms.csv\")\n",
    "df_platforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "g43a9gmr995",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_governance_policy_link(url):\n",
    "    \"\"\"\n",
    "    Extracts the link to data governance policies from a web platform.\n",
    "    Searches for terms related to data governance, data management, \n",
    "    scientific data policies and data management frameworks.\n",
    "    \n",
    "    Args:\n",
    "        url (str): Platform URL\n",
    "        \n",
    "    Returns:\n",
    "        str: URL of the data governance page if found, None otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Ensure URL has protocol\n",
    "        if not url.startswith(('http://', 'https://')):\n",
    "            url = 'https://' + url\n",
    "        \n",
    "        # Configure headers to avoid blocking\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "            'Accept-Language': 'en-US,en;q=0.5',\n",
    "            'Accept-Encoding': 'gzip, deflate',\n",
    "            'Connection': 'keep-alive',\n",
    "        }\n",
    "        \n",
    "        # Make HTTP request\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Parse HTML\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Terms related to data governance (multiple languages)\n",
    "        governance_texts = [\n",
    "            # English - Data governance\n",
    "            'data governance', 'data policy', 'data management', 'data stewardship',\n",
    "            'data standards', 'data quality', 'data principles', 'data framework',\n",
    "            'scientific data policy', 'research data policy', 'data sharing policy',\n",
    "            'data use policy', 'data access policy', 'data ethics', 'data guidelines',\n",
    "            'information governance', 'data management plan', 'fair data', 'open data policy',\n",
    "            \n",
    "            # English - Scientific specific terms\n",
    "            'research guidelines', 'scientific standards', 'data citation', 'metadata standards',\n",
    "            'data repository policy', 'data licensing', 'data attribution', 'data provenance',\n",
    "            'scientific integrity', 'research ethics', 'data transparency', 'reproducible research',\n",
    "            \n",
    "            # Spanish - Data governance\n",
    "            'gobernanza de datos', 'pol√≠tica de datos', 'gesti√≥n de datos', 'administraci√≥n de datos',\n",
    "            'est√°ndares de datos', 'calidad de datos', 'principios de datos', 'marco de datos',\n",
    "            'pol√≠tica cient√≠fica de datos', 'pol√≠tica de investigaci√≥n', 'pol√≠tica de intercambio',\n",
    "            '√©tica de datos', 'directrices de datos', 'gobernanza de informaci√≥n',\n",
    "            \n",
    "            # French\n",
    "            'gouvernance des donn√©es', 'politique des donn√©es', 'gestion des donn√©es',\n",
    "            '√©thique des donn√©es', 'donn√©es ouvertes', 'int√©grit√© scientifique',\n",
    "            \n",
    "            # German\n",
    "            'datenverwaltung', 'datenrichtlinien', 'datenethik', 'forschungsrichtlinien',\n",
    "            \n",
    "            # Dutch\n",
    "            'data governance', 'gegevensbeheer', 'onderzoeksrichtlijnen',\n",
    "            \n",
    "            # Universal technical terms\n",
    "            'fair principles', 'dmp', 'orcid', 'doi policy', 'creative commons',\n",
    "            'research data management', 'rdm', 'data management framework'\n",
    "        ]\n",
    "        \n",
    "        found_links = []\n",
    "        \n",
    "        # Search for direct links with governance-related text\n",
    "        for link in soup.find_all('a', href=True):\n",
    "            link_text = link.get_text(strip=True).lower()\n",
    "            href = link.get('href')\n",
    "            \n",
    "            # Check if text contains governance terms\n",
    "            for governance_text in governance_texts:\n",
    "                if governance_text in link_text:\n",
    "                    # Convert to absolute URL if relative\n",
    "                    if href.startswith('/'):\n",
    "                        governance_url = urljoin(url, href)\n",
    "                    elif href.startswith('http'):\n",
    "                        governance_url = href\n",
    "                    else:\n",
    "                        governance_url = urljoin(url, '/' + href)\n",
    "                    \n",
    "                    found_links.append((governance_url, governance_text, link_text))\n",
    "        \n",
    "        # Search in specific sections (footer, navigation, menus)\n",
    "        specific_areas = soup.find_all(['footer', 'nav', 'div'], \n",
    "                                     class_=re.compile(r'footer|nav|menu|policy|legal|research|science|data', re.I))\n",
    "        \n",
    "        for area in specific_areas:\n",
    "            for link in area.find_all('a', href=True):\n",
    "                link_text = link.get_text(strip=True).lower()\n",
    "                href = link.get('href')\n",
    "                \n",
    "                for governance_text in governance_texts:\n",
    "                    if governance_text in link_text:\n",
    "                        if href.startswith('/'):\n",
    "                            governance_url = urljoin(url, href)\n",
    "                        elif href.startswith('http'):\n",
    "                            governance_url = href\n",
    "                        else:\n",
    "                            governance_url = urljoin(url, '/' + href)\n",
    "                        \n",
    "                        found_links.append((governance_url, governance_text, link_text))\n",
    "        \n",
    "        # Search common governance policy URLs\n",
    "        common_governance_paths = [\n",
    "            '/data-governance', '/data-policy', '/data-management', '/research-policy',\n",
    "            '/scientific-policy', '/data-standards', '/data-guidelines', '/research-guidelines',\n",
    "            '/fair-data', '/open-data', '/data-ethics', '/research-ethics', '/data-use-policy',\n",
    "            '/data-sharing', '/data-access', '/scientific-standards', '/research-integrity',\n",
    "            '/data-management-plan', '/rdm', '/metadata-policy', '/data-citation',\n",
    "            '/governance.html', '/policy.html', '/guidelines.html', '/standards.html'\n",
    "        ]\n",
    "        \n",
    "        for path in common_governance_paths:\n",
    "            test_url = urljoin(url, path)\n",
    "            try:\n",
    "                test_response = requests.head(test_url, headers=headers, timeout=5)\n",
    "                if test_response.status_code == 200:\n",
    "                    found_links.append((test_url, 'common_path', path))\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        # Filter and prioritize results\n",
    "        if found_links:\n",
    "            # Prioritize by term relevance\n",
    "            priority_terms = ['data governance', 'data policy', 'research policy', 'scientific policy']\n",
    "            \n",
    "            # First search for high priority terms\n",
    "            for link_url, term, text in found_links:\n",
    "                if any(priority_term in term for priority_term in priority_terms):\n",
    "                    return link_url\n",
    "            \n",
    "            # If no high priority terms, return first found\n",
    "            return found_links[0][0]\n",
    "        \n",
    "        return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing data governance in {url}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e65c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing data governance in https://coastwards.org: HTTPSConnectionPool(host='coastwards.org', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7ff0c6cfa7d0>: Failed to establish a new connection: [Errno 111] Conexi√≥n rehusada'))\n"
     ]
    }
   ],
   "source": [
    "df_platforms['governance_explicit'] = df_platforms['platform_url'].apply(extract_data_governance_policy_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934b06f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "platform_url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "governance_explicit",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "e2afd84e-76fc-4392-a0fc-2746afe52026",
       "rows": [
        [
         "0",
         "observation.org",
         "https://observation.org/data-governance"
        ],
        [
         "1",
         "seasearch.org.uk",
         null
        ],
        [
         "2",
         "natuurpunt.be",
         null
        ],
        [
         "3",
         "slu.se/artdatabanken",
         null
        ],
        [
         "4",
         "theroadlab.co.uk",
         null
        ],
        [
         "5",
         "exploreyourshore.ie",
         null
        ],
        [
         "6",
         "eyeonwater.org",
         null
        ],
        [
         "7",
         "iseahorse.org",
         null
        ],
        [
         "8",
         "redpromar.org",
         null
        ],
        [
         "9",
         "coastwards.org",
         null
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>platform_url</th>\n",
       "      <th>governance_explicit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>observation.org</td>\n",
       "      <td>https://observation.org/data-governance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>seasearch.org.uk</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>natuurpunt.be</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>slu.se/artdatabanken</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>theroadlab.co.uk</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>exploreyourshore.ie</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>eyeonwater.org</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>iseahorse.org</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>redpromar.org</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>coastwards.org</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           platform_url                      governance_explicit\n",
       "0       observation.org  https://observation.org/data-governance\n",
       "1      seasearch.org.uk                                     None\n",
       "2         natuurpunt.be                                     None\n",
       "3  slu.se/artdatabanken                                     None\n",
       "4      theroadlab.co.uk                                     None\n",
       "5   exploreyourshore.ie                                     None\n",
       "6        eyeonwater.org                                     None\n",
       "7         iseahorse.org                                     None\n",
       "8         redpromar.org                                     None\n",
       "9        coastwards.org                                     None"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_platforms[['platform_url', 'governance_explicit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74311b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_platforms.to_csv(\"../data/df_platforms.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9krgv42q3cu",
   "metadata": {},
   "source": [
    "# api_availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wlkv6y7h58k",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_api_url(url):\n",
    "    \"\"\"\n",
    "    Extracts the API URL or documentation URL from a platform.\n",
    "    Searches for API documentation, endpoints, and common API indicators.\n",
    "    \n",
    "    Args:\n",
    "        url (str): Platform URL\n",
    "        \n",
    "    Returns:\n",
    "        str: URL to API documentation/endpoint if found, None otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Ensure URL has protocol\n",
    "        if not url.startswith(('http://', 'https://')):\n",
    "            url = 'https://' + url\n",
    "        \n",
    "        # Configure headers to avoid blocking\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "            'Accept-Language': 'en-US,en;q=0.5',\n",
    "            'Accept-Encoding': 'gzip, deflate',\n",
    "            'Connection': 'keep-alive',\n",
    "        }\n",
    "        \n",
    "        # Make HTTP request\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Parse HTML\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # API-related terms to search for\n",
    "        api_terms = [\n",
    "            # High priority terms\n",
    "            'api documentation', 'api docs', 'api reference', 'api guide',\n",
    "            'developer documentation', 'developers', 'rest api',\n",
    "            \n",
    "            # Medium priority terms\n",
    "            'api', 'web api', 'json api', 'restful api', 'graphql',\n",
    "            'api endpoint', 'api access', 'api integration', 'sdk',\n",
    "            \n",
    "            # Spanish\n",
    "            'documentaci√≥n api', 'gu√≠a api', 'desarrolladores',\n",
    "            \n",
    "            # French\n",
    "            'documentation api', 'guide api', 'd√©veloppeurs',\n",
    "            \n",
    "            # German\n",
    "            'api dokumentation', 'entwickler',\n",
    "            \n",
    "            # Dutch\n",
    "            'api documentatie', 'ontwikkelaars'\n",
    "        ]\n",
    "        \n",
    "        found_api_links = []\n",
    "        \n",
    "        # 1. Search for direct API links in navigation and content\n",
    "        for link in soup.find_all('a', href=True):\n",
    "            link_text = link.get_text(strip=True).lower()\n",
    "            href = link.get('href')\n",
    "            \n",
    "            # Check if link text contains API terms\n",
    "            for api_term in api_terms:\n",
    "                if api_term in link_text:\n",
    "                    # Convert to absolute URL if relative\n",
    "                    if href.startswith('/'):\n",
    "                        api_url = urljoin(url, href)\n",
    "                    elif href.startswith('http'):\n",
    "                        api_url = href\n",
    "                    else:\n",
    "                        api_url = urljoin(url, '/' + href)\n",
    "                    \n",
    "                    # Add priority score based on term importance\n",
    "                    priority = 3 if api_term in ['api documentation', 'api docs', 'developers', 'api reference'] else 2\n",
    "                    found_api_links.append((api_url, api_term, link_text, priority))\n",
    "        \n",
    "        # 2. Check common API endpoint paths\n",
    "        common_api_paths = [\n",
    "            # High priority paths\n",
    "            '/api/docs', '/api-docs', '/docs/api', '/documentation/api',\n",
    "            '/developers', '/developer',\n",
    "            \n",
    "            # Medium priority paths\n",
    "            '/api', '/api/v1', '/api/v2', '/swagger', '/docs',\n",
    "            '/documentation', '/rest', '/restapi', '/graphql',\n",
    "            \n",
    "            # Lower priority paths\n",
    "            '/api.html', '/api.php', '/help/api', '/support/api',\n",
    "            '/reference/api'\n",
    "        ]\n",
    "        \n",
    "        for i, path in enumerate(common_api_paths):\n",
    "            test_url = urljoin(url, path)\n",
    "            try:\n",
    "                test_response = requests.head(test_url, headers=headers, timeout=5)\n",
    "                if test_response.status_code == 200:\n",
    "                    # Higher priority for paths at the beginning of the list\n",
    "                    priority = 3 if i < 5 else (2 if i < 10 else 1)\n",
    "                    found_api_links.append((test_url, 'common_path', path, priority))\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        # 3. Sort by priority and return the best match\n",
    "        if found_api_links:\n",
    "            # Sort by priority (highest first) and then by term quality\n",
    "            found_api_links.sort(key=lambda x: (-x[3], x[1] != 'common_path'))\n",
    "            return found_api_links[0][0]\n",
    "        \n",
    "        return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting API URL from {url}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7w9xrqz6xcl",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting API URL from https://coastwards.org: HTTPSConnectionPool(host='coastwards.org', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7ff0c6da2590>: Failed to establish a new connection: [Errno 111] Conexi√≥n rehusada'))\n"
     ]
    }
   ],
   "source": [
    "# Apply the API extraction function to all platforms\n",
    "df_platforms['api'] = df_platforms['platform_url'].apply(extract_api_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a119c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "platform_url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "active",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "platform_about",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "year_creation",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "terms_link",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "privacy_link",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "code_repository",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "programming_language",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "governance_explicit",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "api",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "a4b0aa6d-34ae-4e28-8533-caddfdd8f4de",
       "rows": [
        [
         "0",
         "observation.org",
         "Status code: 200",
         "https://observation.org/about",
         "2002",
         "https://observation.org/terms",
         "https://observation.org/privacy",
         "https://github.com/TecharoHQ/anubis",
         "Python",
         "https://observation.org/data-governance",
         "https://observation.org/api-docs"
        ],
        [
         "1",
         "seasearch.org.uk",
         "Status code: 200",
         "https://www.seasearch.org.uk/about",
         "1999",
         "https://www.seasearch.org.uk/website-terms-conditions",
         "https://www.seasearch.org.uk/privacy",
         null,
         "Ruby",
         null,
         null
        ],
        [
         "2",
         "natuurpunt.be",
         "Status code: 200",
         "https://natuurpunt.be/dit-is-natuurpunt",
         "2001",
         "https://natuurpunt.be/algemene-voorwaarden-en-privacy",
         "https://natuurpunt.be/algemene-voorwaarden-en-privacy",
         null,
         null,
         null,
         null
        ],
        [
         "3",
         "slu.se/artdatabanken",
         "Status code: 200",
         null,
         "1989",
         null,
         null,
         null,
         "ASP.NET",
         null,
         null
        ],
        [
         "4",
         "theroadlab.co.uk",
         "Status code: 200",
         "https://www.theroadlab.co.uk/about",
         "2022",
         null,
         null,
         null,
         "JavaScript",
         null,
         null
        ],
        [
         "5",
         "exploreyourshore.ie",
         "Status code: 200",
         "https://exploreyourshore.ie/about-explore-your-shore/",
         "2019",
         "https://exploreyourshore.ie/legals/",
         "https://exploreyourshore.ie/cookie-policy/",
         null,
         "PHP",
         null,
         null
        ],
        [
         "6",
         "eyeonwater.org",
         "Status code: 200",
         "https://eyeonwater.org/about-us",
         "2015",
         "https://eyeonwater.org/privacy-policy",
         "https://eyeonwater.org/privacy-policy",
         null,
         null,
         null,
         null
        ],
        [
         "7",
         "iseahorse.org",
         "Status code: 200",
         "https://projectseahorse.org/about-us/",
         "2012",
         "https://projectseahorse.org/regulating-trade/controlling-legal-trade/",
         "https://projectseahorse.org/privacy-statement-ca/",
         null,
         "PHP",
         null,
         null
        ],
        [
         "8",
         "redpromar.org",
         "Status code: 200",
         null,
         "2020",
         "https://redpromar.org/sightings",
         "https://redpromar.org/legal-notice",
         null,
         "Ruby",
         null,
         "https://redpromar.org/api/v1"
        ],
        [
         "9",
         "coastwards.org",
         "Fallo: HTTPSConnectionPool(host='coastwards.org', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fbae1b96e10>: Failed to establish a new connection: [Errno 111] Connection refused'))",
         null,
         "2016",
         null,
         null,
         null,
         null,
         null,
         null
        ]
       ],
       "shape": {
        "columns": 10,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>platform_url</th>\n",
       "      <th>active</th>\n",
       "      <th>platform_about</th>\n",
       "      <th>year_creation</th>\n",
       "      <th>terms_link</th>\n",
       "      <th>privacy_link</th>\n",
       "      <th>code_repository</th>\n",
       "      <th>programming_language</th>\n",
       "      <th>governance_explicit</th>\n",
       "      <th>api</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>observation.org</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>https://observation.org/about</td>\n",
       "      <td>2002</td>\n",
       "      <td>https://observation.org/terms</td>\n",
       "      <td>https://observation.org/privacy</td>\n",
       "      <td>https://github.com/TecharoHQ/anubis</td>\n",
       "      <td>Python</td>\n",
       "      <td>https://observation.org/data-governance</td>\n",
       "      <td>https://observation.org/api-docs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>seasearch.org.uk</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>https://www.seasearch.org.uk/about</td>\n",
       "      <td>1999</td>\n",
       "      <td>https://www.seasearch.org.uk/website-terms-con...</td>\n",
       "      <td>https://www.seasearch.org.uk/privacy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ruby</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>natuurpunt.be</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>https://natuurpunt.be/dit-is-natuurpunt</td>\n",
       "      <td>2001</td>\n",
       "      <td>https://natuurpunt.be/algemene-voorwaarden-en-...</td>\n",
       "      <td>https://natuurpunt.be/algemene-voorwaarden-en-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>slu.se/artdatabanken</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1989</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ASP.NET</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>theroadlab.co.uk</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>https://www.theroadlab.co.uk/about</td>\n",
       "      <td>2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>exploreyourshore.ie</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>https://exploreyourshore.ie/about-explore-your...</td>\n",
       "      <td>2019</td>\n",
       "      <td>https://exploreyourshore.ie/legals/</td>\n",
       "      <td>https://exploreyourshore.ie/cookie-policy/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PHP</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>eyeonwater.org</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>https://eyeonwater.org/about-us</td>\n",
       "      <td>2015</td>\n",
       "      <td>https://eyeonwater.org/privacy-policy</td>\n",
       "      <td>https://eyeonwater.org/privacy-policy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>iseahorse.org</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>https://projectseahorse.org/about-us/</td>\n",
       "      <td>2012</td>\n",
       "      <td>https://projectseahorse.org/regulating-trade/c...</td>\n",
       "      <td>https://projectseahorse.org/privacy-statement-ca/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PHP</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>redpromar.org</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "      <td>https://redpromar.org/sightings</td>\n",
       "      <td>https://redpromar.org/legal-notice</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ruby</td>\n",
       "      <td>None</td>\n",
       "      <td>https://redpromar.org/api/v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>coastwards.org</td>\n",
       "      <td>Fallo: HTTPSConnectionPool(host='coastwards.or...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           platform_url                                             active  \\\n",
       "0       observation.org                                   Status code: 200   \n",
       "1      seasearch.org.uk                                   Status code: 200   \n",
       "2         natuurpunt.be                                   Status code: 200   \n",
       "3  slu.se/artdatabanken                                   Status code: 200   \n",
       "4      theroadlab.co.uk                                   Status code: 200   \n",
       "5   exploreyourshore.ie                                   Status code: 200   \n",
       "6        eyeonwater.org                                   Status code: 200   \n",
       "7         iseahorse.org                                   Status code: 200   \n",
       "8         redpromar.org                                   Status code: 200   \n",
       "9        coastwards.org  Fallo: HTTPSConnectionPool(host='coastwards.or...   \n",
       "\n",
       "                                      platform_about  year_creation  \\\n",
       "0                      https://observation.org/about           2002   \n",
       "1                 https://www.seasearch.org.uk/about           1999   \n",
       "2            https://natuurpunt.be/dit-is-natuurpunt           2001   \n",
       "3                                                NaN           1989   \n",
       "4                 https://www.theroadlab.co.uk/about           2022   \n",
       "5  https://exploreyourshore.ie/about-explore-your...           2019   \n",
       "6                    https://eyeonwater.org/about-us           2015   \n",
       "7              https://projectseahorse.org/about-us/           2012   \n",
       "8                                                NaN           2020   \n",
       "9                                                NaN           2016   \n",
       "\n",
       "                                          terms_link  \\\n",
       "0                      https://observation.org/terms   \n",
       "1  https://www.seasearch.org.uk/website-terms-con...   \n",
       "2  https://natuurpunt.be/algemene-voorwaarden-en-...   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "5                https://exploreyourshore.ie/legals/   \n",
       "6              https://eyeonwater.org/privacy-policy   \n",
       "7  https://projectseahorse.org/regulating-trade/c...   \n",
       "8                    https://redpromar.org/sightings   \n",
       "9                                                NaN   \n",
       "\n",
       "                                        privacy_link  \\\n",
       "0                    https://observation.org/privacy   \n",
       "1               https://www.seasearch.org.uk/privacy   \n",
       "2  https://natuurpunt.be/algemene-voorwaarden-en-...   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "5         https://exploreyourshore.ie/cookie-policy/   \n",
       "6              https://eyeonwater.org/privacy-policy   \n",
       "7  https://projectseahorse.org/privacy-statement-ca/   \n",
       "8                 https://redpromar.org/legal-notice   \n",
       "9                                                NaN   \n",
       "\n",
       "                       code_repository programming_language  \\\n",
       "0  https://github.com/TecharoHQ/anubis               Python   \n",
       "1                                  NaN                 Ruby   \n",
       "2                                  NaN                  NaN   \n",
       "3                                  NaN              ASP.NET   \n",
       "4                                  NaN           JavaScript   \n",
       "5                                  NaN                  PHP   \n",
       "6                                  NaN                  NaN   \n",
       "7                                  NaN                  PHP   \n",
       "8                                  NaN                 Ruby   \n",
       "9                                  NaN                  NaN   \n",
       "\n",
       "                       governance_explicit                               api  \n",
       "0  https://observation.org/data-governance  https://observation.org/api-docs  \n",
       "1                                     None                              None  \n",
       "2                                     None                              None  \n",
       "3                                     None                              None  \n",
       "4                                     None                              None  \n",
       "5                                     None                              None  \n",
       "6                                     None                              None  \n",
       "7                                     None                              None  \n",
       "8                                     None      https://redpromar.org/api/v1  \n",
       "9                                     None                              None  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_platforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d20cd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_platforms.to_csv(\"../data/df_platforms.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa32cca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from urllib.parse import parse_qs, unquote, urlparse\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def duckduckgo_search(query):\n",
    "    search = f\"{query} api\"\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    search_url = f\"https://lite.duckduckgo.com/lite/?q={search.replace(' ', '+')}\"\n",
    "\n",
    "    response = requests.get(search_url, headers=headers, timeout=10)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # Buscar el primer enlace resultante\n",
    "    first_link = soup.find(\"a\", class_=\"result-link\")\n",
    "    if first_link and \"href\" in first_link.attrs:\n",
    "        raw_href = first_link[\"href\"]\n",
    "        parsed = urlparse(raw_href)\n",
    "        query_params = parse_qs(parsed.query)\n",
    "        if \"uddg\" in query_params:\n",
    "            time.sleep(5)\n",
    "            return unquote(query_params[\"uddg\"][0])  # Enlace decodificado\n",
    "        else:\n",
    "            time.sleep(5)\n",
    "            return raw_href  # Por si acaso ya es directo\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08427403",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_platforms['api_ddg'] = df_platforms['platform_url'].apply(duckduckgo_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb243ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "platform_url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "api_ddg",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "30819601-c40e-41de-a3d8-3f044f256e6b",
       "rows": [
        [
         "0",
         "observation.org",
         "https://observation.org/api/docs/"
        ],
        [
         "1",
         "seasearch.org.uk",
         "https://www.seasearch.org.uk/"
        ],
        [
         "2",
         "natuurpunt.be",
         "https://www.natuurpunt.be/snuit/aanspreekpunt-integriteit-api"
        ],
        [
         "3",
         "slu.se/artdatabanken",
         "https://www.slu.se/artdatabanken/rapportering-och-fynd/oppna-data-och-apier/"
        ],
        [
         "4",
         "theroadlab.co.uk",
         "https://www.theroadlab.co.uk/"
        ],
        [
         "5",
         "exploreyourshore.ie",
         "https://exploreyourshore.ie/"
        ],
        [
         "6",
         "eyeonwater.org",
         "https://www.eyeonwater.org/api/"
        ],
        [
         "7",
         "iseahorse.org",
         "https://github.com/zeke/seahorse"
        ],
        [
         "8",
         "redpromar.org",
         "https://redpromar.org/"
        ],
        [
         "9",
         "coastwards.org",
         "https://github.com/maureentsakiris/coastwards"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>platform_url</th>\n",
       "      <th>api_ddg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>observation.org</td>\n",
       "      <td>https://observation.org/api/docs/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>seasearch.org.uk</td>\n",
       "      <td>https://www.seasearch.org.uk/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>natuurpunt.be</td>\n",
       "      <td>https://www.natuurpunt.be/snuit/aanspreekpunt-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>slu.se/artdatabanken</td>\n",
       "      <td>https://www.slu.se/artdatabanken/rapportering-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>theroadlab.co.uk</td>\n",
       "      <td>https://www.theroadlab.co.uk/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>exploreyourshore.ie</td>\n",
       "      <td>https://exploreyourshore.ie/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>eyeonwater.org</td>\n",
       "      <td>https://www.eyeonwater.org/api/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>iseahorse.org</td>\n",
       "      <td>https://github.com/zeke/seahorse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>redpromar.org</td>\n",
       "      <td>https://redpromar.org/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>coastwards.org</td>\n",
       "      <td>https://github.com/maureentsakiris/coastwards</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           platform_url                                            api_ddg\n",
       "0       observation.org                  https://observation.org/api/docs/\n",
       "1      seasearch.org.uk                      https://www.seasearch.org.uk/\n",
       "2         natuurpunt.be  https://www.natuurpunt.be/snuit/aanspreekpunt-...\n",
       "3  slu.se/artdatabanken  https://www.slu.se/artdatabanken/rapportering-...\n",
       "4      theroadlab.co.uk                      https://www.theroadlab.co.uk/\n",
       "5   exploreyourshore.ie                       https://exploreyourshore.ie/\n",
       "6        eyeonwater.org                    https://www.eyeonwater.org/api/\n",
       "7         iseahorse.org                   https://github.com/zeke/seahorse\n",
       "8         redpromar.org                             https://redpromar.org/\n",
       "9        coastwards.org      https://github.com/maureentsakiris/coastwards"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_platforms[[\"platform_url\", 'api_ddg']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759108b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_dict = {\n",
    "    \"eyeonwater.org\": \"https://www.eyeonwater.org/api/\",\n",
    "    \"iseahorse.org\": \"https://github.com/zeke/seahorse\",\n",
    "    \"coastwards.org\": \"https://github.com/maureentsakiris/coastwards\",\n",
    "}\n",
    "for k,v in api_dict.items():\n",
    "    df_platforms.loc[df_platforms['platform_url'] == k, \"api\"] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4379f2d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "api",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "d4ae5a98-7519-4743-ba51-039f32fbeb17",
       "rows": [
        [
         "0",
         "https://observation.org/api-docs"
        ],
        [
         "1",
         null
        ],
        [
         "2",
         null
        ],
        [
         "3",
         null
        ],
        [
         "4",
         null
        ],
        [
         "5",
         null
        ],
        [
         "6",
         "https://www.eyeonwater.org/api/"
        ],
        [
         "7",
         "https://github.com/zeke/seahorse"
        ],
        [
         "8",
         "https://redpromar.org/api/v1"
        ],
        [
         "9",
         "https://github.com/maureentsakiris/coastwards"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 10
       }
      },
      "text/plain": [
       "0                 https://observation.org/api-docs\n",
       "1                                             None\n",
       "2                                             None\n",
       "3                                             None\n",
       "4                                             None\n",
       "5                                             None\n",
       "6                  https://www.eyeonwater.org/api/\n",
       "7                 https://github.com/zeke/seahorse\n",
       "8                     https://redpromar.org/api/v1\n",
       "9    https://github.com/maureentsakiris/coastwards\n",
       "Name: api, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_platforms[\"api\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787c927c",
   "metadata": {},
   "source": [
    "# organization_of_managers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42vy1rcua1u",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_organization_from_whois(url):\n",
    "    \"\"\"\n",
    "    Extracts the organization name from WHOIS data of the domain.\n",
    "    This is more reliable than parsing website content.\n",
    "    \n",
    "    Args:\n",
    "        url (str): Platform URL\n",
    "        \n",
    "    Returns:\n",
    "        str: Organization name from WHOIS data if found, None otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import whois\n",
    "        \n",
    "        # Ensure URL has protocol and extract domain\n",
    "        if not url.startswith(('http://', 'https://')):\n",
    "            url = 'https://' + url\n",
    "        \n",
    "        # Parse domain from URL\n",
    "        parsed_url = urlparse(url)\n",
    "        domain = parsed_url.netloc\n",
    "        \n",
    "        # Remove www prefix if present\n",
    "        if domain.startswith('www.'):\n",
    "            domain = domain[4:]\n",
    "        \n",
    "        # Get WHOIS information\n",
    "        domain_info = whois.whois(domain)\n",
    "        \n",
    "        # Try different fields that might contain organization info\n",
    "        org_fields = ['org', 'organization', 'registrant_organization', 'registrant', 'admin_organization']\n",
    "        \n",
    "        for field in org_fields:\n",
    "            if hasattr(domain_info, field):\n",
    "                org_value = getattr(domain_info, field)\n",
    "                if org_value:\n",
    "                    # Handle case where value might be a list\n",
    "                    if isinstance(org_value, list):\n",
    "                        org_value = org_value[0] if org_value else None\n",
    "                    \n",
    "                    if org_value and isinstance(org_value, str):\n",
    "                        # Clean the organization name\n",
    "                        org_clean = org_value.strip()\n",
    "                        \n",
    "                        # Skip if it's just privacy protection or empty\n",
    "                        privacy_indicators = [\n",
    "                            'privacy', 'protection', 'private', 'whoisguard', 'proxy',\n",
    "                            'redacted', 'data protected', 'contact privacy'\n",
    "                        ]\n",
    "                        \n",
    "                        if (org_clean and \n",
    "                            len(org_clean) > 2 and \n",
    "                            not any(indicator in org_clean.lower() for indicator in privacy_indicators)):\n",
    "                            return org_clean\n",
    "        \n",
    "        # If no organization found in standard fields, try registrant name\n",
    "        if hasattr(domain_info, 'registrant_name') and domain_info.registrant_name:\n",
    "            registrant = domain_info.registrant_name\n",
    "            if isinstance(registrant, list):\n",
    "                registrant = registrant[0] if registrant else None\n",
    "            \n",
    "            if registrant and isinstance(registrant, str):\n",
    "                registrant_clean = registrant.strip()\n",
    "                privacy_indicators = [\n",
    "                    'privacy', 'protection', 'private', 'whoisguard', 'proxy',\n",
    "                    'redacted', 'data protected', 'contact privacy'\n",
    "                ]\n",
    "                \n",
    "                if (registrant_clean and \n",
    "                    len(registrant_clean) > 2 and \n",
    "                    not any(indicator in registrant_clean.lower() for indicator in privacy_indicators)):\n",
    "                    return registrant_clean\n",
    "        \n",
    "        return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting organization from WHOIS for {url}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "odk4b8u8dq",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the WHOIS-based organization extraction function to all platforms\n",
    "df_platforms['organization_of_managers'] = df_platforms['platform_url'].apply(extract_organization_from_whois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e033f748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "organization_of_managers",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "d857d5e7-2b8d-4a2f-baf7-a50c734e4302",
       "rows": [
        [
         "0",
         null
        ],
        [
         "1",
         null
        ],
        [
         "2",
         null
        ],
        [
         "3",
         "fresve9742-00001"
        ],
        [
         "4",
         null
        ],
        [
         "5",
         null
        ],
        [
         "6",
         "MARIS BV"
        ],
        [
         "7",
         null
        ],
        [
         "8",
         "CARTOGRAFICA+CANARIAS+SA"
        ],
        [
         "9",
         null
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 10
       }
      },
      "text/plain": [
       "0                        None\n",
       "1                        None\n",
       "2                        None\n",
       "3            fresve9742-00001\n",
       "4                        None\n",
       "5                        None\n",
       "6                    MARIS BV\n",
       "7                        None\n",
       "8    CARTOGRAFICA+CANARIAS+SA\n",
       "9                        None\n",
       "Name: organization_of_managers, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_platforms['organization_of_managers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05096a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_platforms.to_csv(\"../data/df_platforms.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5641df66",
   "metadata": {},
   "source": [
    "Search for another strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd04b5b",
   "metadata": {},
   "source": [
    "# platform_license"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2f9d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def detect_license(text):\n",
    "    text = text.replace('\\n', ' ').replace('\\r', ' ').lower()\n",
    "\n",
    "    patterns = [\n",
    "        # Common copyright (symbol or world)\n",
    "        r'¬©\\s*\\d{4}[^\\.\\n]*',\n",
    "        r'copyright\\s*¬©?\\s*\\d{4}[^\\.\\n]*',\n",
    "        r'copyright\\s+[\\w\\s\\.\\-&,]*\\d{4}[^\\.\\n]*',\n",
    "        r'[^\\.]*¬©\\s*\\d{4}',  # Match text before and after ¬© symbol   \n",
    "        r'powered by.*?¬©\\s*\\d{4}',\n",
    "        r'todos los derechos reservados',\n",
    "        r'all rights reserved',\n",
    "        r'tous droits r√©serv√©s',\n",
    "        r'alle rechte vorbehalten',\n",
    "        r'tutti i diritti riservati',\n",
    "\n",
    "        # Creative Commons\n",
    "        r'creative commons[^<\\n]{0,100}',\n",
    "        r'cc\\s*(by|by-sa|by-nc|by-nd|0)[\\s\\-0-9\\.]*',\n",
    "\n",
    "        # Other licenses\n",
    "        r'mit license',\n",
    "        r'licensed under the mit license',\n",
    "        r'gpl license',\n",
    "        r'licensed under the gpl',\n",
    "        r'bsd license',\n",
    "        r'apache license',\n",
    "        r'european union public licence',\n",
    "        r'licencia.*mit',\n",
    "        r'licencia.*gpl',\n",
    "        r'licencia.*apache',\n",
    "        r'licencia.*bsd',\n",
    "        r'licenza.*',\n",
    "        r'lizenz.*',\n",
    "        r'licence.*'\n",
    "    ]\n",
    "\n",
    "    for pat in patterns:\n",
    "        match = re.search(pat, text, re.IGNORECASE)\n",
    "        if match:\n",
    "            return match.group(0).strip()\n",
    "\n",
    "    return None\n",
    "\n",
    "def extract_license(url):\n",
    "    try:\n",
    "        # Ensure URL has protocol\n",
    "        if not url.startswith(('http://', 'https://')):\n",
    "            url = 'https://' + url\n",
    "        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}\n",
    "        resp = requests.get(url, timeout=10, headers=headers)\n",
    "        soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "        texto = soup.get_text(separator=' ', strip=True)\n",
    "        return detect_license(texto)\n",
    "    except Exception as e:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a479fefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_platforms['platform_license'] = df_platforms['platform_url'].apply(extract_license)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628264c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "platform_url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "platform_license",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "ad7d0239-57af-47d1-976a-c157f9252a14",
       "rows": [
        [
         "0",
         "observation.org",
         null
        ],
        [
         "1",
         "seasearch.org.uk",
         "¬© 2025 seasearch/mcs uk join our free trial get started today before this once in a lifetime opportunity expires"
        ],
        [
         "2",
         "natuurpunt.be",
         "¬© 2025 natuurpunt footer menu cookieverklaring algemene voorwaarden en privacy meldpunt klokkenluiders contact"
        ],
        [
         "3",
         "slu.se/artdatabanken",
         null
        ],
        [
         "4",
         "theroadlab.co.uk",
         "¬© 2022 by roadlab"
        ],
        [
         "5",
         "exploreyourshore.ie",
         null
        ],
        [
         "6",
         "eyeonwater.org",
         "¬© 2025 maris b"
        ],
        [
         "7",
         "iseahorse.org",
         "¬© 2025 project seahorse"
        ],
        [
         "8",
         "redpromar.org",
         "¬© 2025 redpromar aviso legal pol√≠tica de privacidad pol√≠tica de cookies seleccionar idioma spanish english portuguese"
        ],
        [
         "9",
         "coastwards.org",
         null
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>platform_url</th>\n",
       "      <th>platform_license</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>observation.org</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>seasearch.org.uk</td>\n",
       "      <td>¬© 2025 seasearch/mcs uk join our free trial ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>natuurpunt.be</td>\n",
       "      <td>¬© 2025 natuurpunt footer menu cookieverklaring...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>slu.se/artdatabanken</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>theroadlab.co.uk</td>\n",
       "      <td>¬© 2022 by roadlab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>exploreyourshore.ie</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>eyeonwater.org</td>\n",
       "      <td>¬© 2025 maris b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>iseahorse.org</td>\n",
       "      <td>¬© 2025 project seahorse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>redpromar.org</td>\n",
       "      <td>¬© 2025 redpromar aviso legal pol√≠tica de priva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>coastwards.org</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           platform_url                                   platform_license\n",
       "0       observation.org                                               None\n",
       "1      seasearch.org.uk  ¬© 2025 seasearch/mcs uk join our free trial ge...\n",
       "2         natuurpunt.be  ¬© 2025 natuurpunt footer menu cookieverklaring...\n",
       "3  slu.se/artdatabanken                                               None\n",
       "4      theroadlab.co.uk                                  ¬© 2022 by roadlab\n",
       "5   exploreyourshore.ie                                               None\n",
       "6        eyeonwater.org                                     ¬© 2025 maris b\n",
       "7         iseahorse.org                            ¬© 2025 project seahorse\n",
       "8         redpromar.org  ¬© 2025 redpromar aviso legal pol√≠tica de priva...\n",
       "9        coastwards.org                                               None"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_platforms[[\"platform_url\", 'platform_license']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93aac0ad",
   "metadata": {},
   "source": [
    "observation.org is working with anti-bot technology that deny capturing information using requests. Selenium or playwright would be necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e1d70e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'creative commons attribution 4.0 license. minka incorporates consent commons icons, allowing for easy visual compreh'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test for web with not copyright license\n",
    "extract_license(\"https://minka-sdg.org\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b234aab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_platforms.to_csv(\"../data/df_platforms.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66cb277",
   "metadata": {},
   "source": [
    "# platform_email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07443c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search email in home\n",
    "def get_email(url):\n",
    "    try:\n",
    "        # Ensure URL has protocol\n",
    "        if not url.startswith(('http://', 'https://')):\n",
    "            url = 'https://' + url\n",
    "        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}\n",
    "        response = requests.get(url, timeout=10, headers=headers)\n",
    "        if response.status_code != 200:\n",
    "            return None\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        text = soup.get_text()\n",
    "        emails = re.findall(r\"[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+\", text)\n",
    "        return emails[0] if emails else None\n",
    "    except Exception as e:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0bdbf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "platform_email",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "35f546b7-e59e-499c-b84e-37857f278f23",
       "rows": [
        [
         "0",
         null
        ],
        [
         "1",
         null
        ],
        [
         "2",
         null
        ],
        [
         "3",
         null
        ],
        [
         "4",
         null
        ],
        [
         "5",
         "info@biodiversityireland.ie"
        ],
        [
         "6",
         null
        ],
        [
         "7",
         "info@projectseahorse.org"
        ],
        [
         "8",
         null
        ],
        [
         "9",
         null
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 10
       }
      },
      "text/plain": [
       "0                           None\n",
       "1                           None\n",
       "2                           None\n",
       "3                           None\n",
       "4                           None\n",
       "5    info@biodiversityireland.ie\n",
       "6                           None\n",
       "7       info@projectseahorse.org\n",
       "8                           None\n",
       "9                           None\n",
       "Name: platform_email, dtype: object"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_platforms['platform_email'] = df_platforms['platform_url'].apply(get_email)\n",
    "df_platforms.platform_email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8769d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_email_from_possible_pages(base_url):\n",
    "    contact_paths = [\n",
    "        '', '/contact', '/contact-us', '/contacto', '/a-propos', '/kontakt',\n",
    "        '/contatti', '/contato', '/assistance', '/chi-siamo', '/uber-uns',\n",
    "        '/soporte', '/support', '/supporto', '/ajuda', '/acerca-de', '/sobre',\n",
    "        '/hilfe', '/steun', '/over-ons'\n",
    "    ]\n",
    "    for path in contact_paths:\n",
    "        email = get_email(base_url.rstrip('/') + path)\n",
    "        if email:\n",
    "            return email\n",
    "    return None\n",
    "\n",
    "df_platforms['platform_email'] = df_platforms['platform_url'].apply(get_email_from_possible_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2274b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "platform_email",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "c055cdec-a7c4-473b-a51d-fe9112a61350",
       "rows": [
        [
         "0",
         null
        ],
        [
         "1",
         null
        ],
        [
         "2",
         null
        ],
        [
         "3",
         null
        ],
        [
         "4",
         null
        ],
        [
         "5",
         "info@biodiversityireland.ie"
        ],
        [
         "6",
         null
        ],
        [
         "7",
         "info@projectseahorse.org"
        ],
        [
         "8",
         "redpromar.medioambiente@gobiernodecanarias.org"
        ],
        [
         "9",
         null
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 10
       }
      },
      "text/plain": [
       "0                                              None\n",
       "1                                              None\n",
       "2                                              None\n",
       "3                                              None\n",
       "4                                              None\n",
       "5                       info@biodiversityireland.ie\n",
       "6                                              None\n",
       "7                          info@projectseahorse.org\n",
       "8    redpromar.medioambiente@gobiernodecanarias.org\n",
       "9                                              None\n",
       "Name: platform_email, dtype: object"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_platforms['platform_email']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b0693a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_platforms.to_csv(\"../data/df_platforms.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b58ce9",
   "metadata": {},
   "source": [
    "# country_of_managers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72614a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whois\n",
    "\n",
    "def get_country_from_whois(domain):\n",
    "    try:\n",
    "        w = whois.whois(domain)\n",
    "        return w.get('country')\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "df_platforms['country_from_whois'] = df_platforms['platform_url'].apply(get_country_from_whois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce06b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "country_from_whois",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "1a4a8665-dfc2-47f6-94e1-63f1d144926a",
       "rows": [
        [
         "0",
         "GB"
        ],
        [
         "1",
         null
        ],
        [
         "2",
         null
        ],
        [
         "3",
         null
        ],
        [
         "4",
         null
        ],
        [
         "5",
         null
        ],
        [
         "6",
         "NL"
        ],
        [
         "7",
         "CA"
        ],
        [
         "8",
         "ES"
        ],
        [
         "9",
         "US"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 10
       }
      },
      "text/plain": [
       "0      GB\n",
       "1    None\n",
       "2    None\n",
       "3    None\n",
       "4    None\n",
       "5    None\n",
       "6      NL\n",
       "7      CA\n",
       "8      ES\n",
       "9      US\n",
       "Name: country_from_whois, dtype: object"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_platforms['country_from_whois']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66901dd3",
   "metadata": {},
   "source": [
    "- Determine the country from which a website operates based on the server's IP address, using a geolocation API. This allows us to know where the servers (the data) are physically hosted. Example: a French organization may have its servers in the US."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdd3ee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "platform_url",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "024a2601-d5cb-4c1a-baa9-2aa1b6d6470e",
       "rows": [
        [
         "0",
         "observation.org"
        ],
        [
         "1",
         "seasearch.org.uk"
        ],
        [
         "2",
         "natuurpunt.be"
        ],
        [
         "3",
         "slu.se/artdatabanken"
        ],
        [
         "4",
         "theroadlab.co.uk"
        ],
        [
         "5",
         "exploreyourshore.ie"
        ],
        [
         "6",
         "eyeonwater.org"
        ],
        [
         "7",
         "iseahorse.org"
        ],
        [
         "8",
         "redpromar.org"
        ],
        [
         "9",
         "coastwards.org"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 10
       }
      },
      "text/plain": [
       "0         observation.org\n",
       "1        seasearch.org.uk\n",
       "2           natuurpunt.be\n",
       "3    slu.se/artdatabanken\n",
       "4        theroadlab.co.uk\n",
       "5     exploreyourshore.ie\n",
       "6          eyeonwater.org\n",
       "7           iseahorse.org\n",
       "8           redpromar.org\n",
       "9          coastwards.org\n",
       "Name: platform_url, dtype: object"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_platforms.platform_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f91cfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with ip-api.com\n",
    "from urllib.parse import urlparse\n",
    "import socket\n",
    "import requests\n",
    "\n",
    "def country_from_ip(url):\n",
    "    try:\n",
    "        if url == \"slu.se/artdatabanken\":\n",
    "            url = \"slu.se\"\n",
    "        # Extract domain (without http/https or routes)\n",
    "        parsed = urlparse(url)\n",
    "        domain = parsed.netloc or parsed.path  # in case the URL doesn't have a scheme\n",
    "\n",
    "        # Remove www if necessary\n",
    "        if domain.startswith('www.'):\n",
    "            domain = domain[4:]\n",
    "\n",
    "        # Resolve IP\n",
    "        ip = socket.gethostbyname(domain)\n",
    "\n",
    "        # Query geolocalization API\n",
    "        r = requests.get(f\"http://ip-api.com/json/{ip}\", timeout=10)\n",
    "        if r.status_code == 200:\n",
    "            time.sleep(1.4) # limit of 45 requests per minute\n",
    "            return r.json().get(\"country\")\n",
    "    except Exception as e:\n",
    "        return None\n",
    "    \n",
    "df_platforms['country_servers'] = df_platforms['platform_url'].apply(country_from_ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365ea497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "country_servers",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "1ff483d0-bd47-4ea8-88a6-3063f8a3b124",
       "rows": [
        [
         "0",
         "The Netherlands"
        ],
        [
         "1",
         "Canada"
        ],
        [
         "2",
         "Canada"
        ],
        [
         "3",
         "Sweden"
        ],
        [
         "4",
         "United States"
        ],
        [
         "5",
         "Ireland"
        ],
        [
         "6",
         "The Netherlands"
        ],
        [
         "7",
         "France"
        ],
        [
         "8",
         "Spain"
        ],
        [
         "9",
         "Germany"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 10
       }
      },
      "text/plain": [
       "0    The Netherlands\n",
       "1             Canada\n",
       "2             Canada\n",
       "3             Sweden\n",
       "4      United States\n",
       "5            Ireland\n",
       "6    The Netherlands\n",
       "7             France\n",
       "8              Spain\n",
       "9            Germany\n",
       "Name: country_servers, dtype: object"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_platforms['country_servers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b75f936",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_platforms.to_csv(\"../data/df_platforms.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765d07cf",
   "metadata": {},
   "source": [
    "# data_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jvo808cn6ll",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_download_options(url):\n",
    "    \"\"\"\n",
    "    Detects if a platform offers data download options.\n",
    "    Searches for download links, export options, and data access features.\n",
    "    \n",
    "    Args:\n",
    "        url (str): Platform URL\n",
    "        \n",
    "    Returns:\n",
    "        str: Description of download options if found, None otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Ensure URL has protocol\n",
    "        if not url.startswith(('http://', 'https://')):\n",
    "            url = 'https://' + url\n",
    "        \n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
    "        }\n",
    "        \n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        page_text = soup.get_text().lower()\n",
    "        \n",
    "        # Check for anti-bot protection\n",
    "        if 'botstopper' in page_text or 'checking if you are not a bot' in page_text:\n",
    "            return \"Protected by anti-bot\"\n",
    "        \n",
    "        download_options = []\n",
    "        \n",
    "        # Terms related to data download/export\n",
    "        download_terms = [\n",
    "            # English\n",
    "            'download data', 'export data', 'data download', 'data export',\n",
    "            'download dataset', 'export dataset', 'bulk download', 'batch download',\n",
    "            'csv download', 'excel download', 'json download', 'xml download',\n",
    "            'download observations', 'export observations', 'data access',\n",
    "            'download records', 'export records', 'get data', 'api download',\n",
    "            \n",
    "            # Spanish\n",
    "            'descargar datos', 'exportar datos', 'descarga de datos',\n",
    "            'descargar registros', 'exportar registros',\n",
    "            \n",
    "            # French\n",
    "            't√©l√©charger donn√©es', 'exporter donn√©es', 't√©l√©chargement donn√©es',\n",
    "            \n",
    "            # German\n",
    "            'daten herunterladen', 'daten exportieren', 'datendownload',\n",
    "            \n",
    "            # Dutch\n",
    "            'data downloaden', 'gegevens downloaden', 'data exporteren'\n",
    "        ]\n",
    "        \n",
    "        # Search for download terms in text\n",
    "        found_terms = []\n",
    "        for term in download_terms:\n",
    "            if term in page_text:\n",
    "                found_terms.append(term)\n",
    "        \n",
    "        # Search for download links\n",
    "        download_links = []\n",
    "        for link in soup.find_all('a', href=True):\n",
    "            href = link.get('href')\n",
    "            href_lower = href.lower()\n",
    "            link_text = link.get_text(strip=True).lower()\n",
    "            \n",
    "            # Check for download-related URLs\n",
    "            download_patterns = [\n",
    "                'download', 'export', 'csv', 'excel', 'json', 'xml', \n",
    "                'data.csv', 'data.json', 'data.xml', '.zip', 'bulk'\n",
    "            ]\n",
    "            \n",
    "            if any(pattern in href_lower for pattern in download_patterns):\n",
    "                # Convert to absolute URL if relative\n",
    "                if href.startswith('/'):\n",
    "                    absolute_url = urljoin(url, href)\n",
    "                elif href.startswith('http'):\n",
    "                    absolute_url = href\n",
    "                else:\n",
    "                    absolute_url = urljoin(url, '/' + href)\n",
    "                download_links.append(f\"{absolute_url}\")\n",
    "            elif any(pattern in link_text for pattern in download_patterns):\n",
    "                # Convert to absolute URL if relative\n",
    "                if href.startswith('/'):\n",
    "                    absolute_url = urljoin(url, href)\n",
    "                elif href.startswith('http'):\n",
    "                    absolute_url = href\n",
    "                else:\n",
    "                    absolute_url = urljoin(url, '/' + href)\n",
    "                download_links.append(f\"{absolute_url}\")\n",
    "        \n",
    "        # Search for file format mentions\n",
    "        file_formats = []\n",
    "        format_patterns = [\n",
    "            r'csv\\s+format', r'excel\\s+format', r'json\\s+format', \n",
    "            r'xml\\s+format', r'\\.csv', r'\\.xlsx?', r'\\.json', r'\\.xml'\n",
    "        ]\n",
    "        \n",
    "        for pattern in format_patterns:\n",
    "            matches = re.findall(pattern, page_text)\n",
    "            if matches:\n",
    "                file_formats.extend(matches)\n",
    "        \n",
    "        # Search for API endpoints that might provide data\n",
    "        api_endpoints = []\n",
    "        if '/api' in page_text or 'rest api' in page_text or 'graphql' in page_text:\n",
    "            api_endpoints.append(\"API available\")\n",
    "        \n",
    "        # Compile results\n",
    "        if found_terms or download_links or file_formats or api_endpoints:\n",
    "            result_parts = []\n",
    "            \n",
    "            if found_terms:\n",
    "                result_parts.append(f\"{', '.join(set(found_terms[:3]))}\")  # Limit to 3\n",
    "            \n",
    "            if download_links:\n",
    "                result_parts.append(f\"{', '.join(download_links[:2])}\")  # Limit to 2\n",
    "            \n",
    "            if file_formats:\n",
    "                result_parts.append(f\"{', '.join(set(file_formats[:3]))}\")  # Limit to 3\n",
    "            \n",
    "            if api_endpoints:\n",
    "                result_parts.append(\"API: Available\")\n",
    "            \n",
    "            return \" | \".join(result_parts)\n",
    "        \n",
    "        return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error checking download options for {url}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1hgnphcqyo1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error checking download options for https://coastwards.org: HTTPSConnectionPool(host='coastwards.org', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7ff0c49120d0>: Failed to establish a new connection: [Errno 111] Conexi√≥n rehusada'))\n"
     ]
    }
   ],
   "source": [
    "df_platforms['data_download_options'] = df_platforms['platform_url'].apply(extract_data_download_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95v6mha5126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "platform_url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "data_download_options",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "2b482356-ac49-45bc-a712-224612ca51c9",
       "rows": [
        [
         "0",
         "observation.org",
         "Protected by anti-bot"
        ],
        [
         "1",
         "seasearch.org.uk",
         null
        ],
        [
         "2",
         "natuurpunt.be",
         "https://natuurpunt.be/natuurgebieden"
        ],
        [
         "3",
         "slu.se/artdatabanken",
         null
        ],
        [
         "4",
         "theroadlab.co.uk",
         "https://www.theroadlab.co.uk/download"
        ],
        [
         "5",
         "exploreyourshore.ie",
         null
        ],
        [
         "6",
         "eyeonwater.org",
         null
        ],
        [
         "7",
         "iseahorse.org",
         null
        ],
        [
         "8",
         "redpromar.org",
         null
        ],
        [
         "9",
         "coastwards.org",
         null
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>platform_url</th>\n",
       "      <th>data_download_options</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>observation.org</td>\n",
       "      <td>Protected by anti-bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>seasearch.org.uk</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>natuurpunt.be</td>\n",
       "      <td>https://natuurpunt.be/natuurgebieden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>slu.se/artdatabanken</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>theroadlab.co.uk</td>\n",
       "      <td>https://www.theroadlab.co.uk/download</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>exploreyourshore.ie</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>eyeonwater.org</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>iseahorse.org</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>redpromar.org</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>coastwards.org</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           platform_url                  data_download_options\n",
       "0       observation.org                  Protected by anti-bot\n",
       "1      seasearch.org.uk                                   None\n",
       "2         natuurpunt.be   https://natuurpunt.be/natuurgebieden\n",
       "3  slu.se/artdatabanken                                   None\n",
       "4      theroadlab.co.uk  https://www.theroadlab.co.uk/download\n",
       "5   exploreyourshore.ie                                   None\n",
       "6        eyeonwater.org                                   None\n",
       "7         iseahorse.org                                   None\n",
       "8         redpromar.org                                   None\n",
       "9        coastwards.org                                   None"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_platforms[['platform_url', 'data_download_options']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac6538d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_platforms.to_csv(\"../data/df_platforms.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8nwrudl6ev9",
   "metadata": {},
   "source": [
    "# data_standards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fo4n6ox5oxf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_data_standards(url):\n",
    "    \"\"\"\n",
    "    Detects data standards mentioned on a platform.\n",
    "    Searches for common data standards like Darwin Core, Dublin Core, etc.\n",
    "    \n",
    "    Args:\n",
    "        url (str): Platform URL\n",
    "        \n",
    "    Returns:\n",
    "        str: List of detected data standards, None if none found\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Ensure URL has protocol\n",
    "        if not url.startswith(('http://', 'https://')):\n",
    "            url = 'https://' + url\n",
    "        \n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
    "        }\n",
    "        \n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        page_text = soup.get_text().lower()\n",
    "        \n",
    "        # Check for anti-bot protection\n",
    "        if 'botstopper' in page_text or 'checking if you are not a bot' in page_text:\n",
    "            return \"Protected by anti-bot\"\n",
    "        \n",
    "        # Common data standards to search for\n",
    "        data_standards = {\n",
    "            # Biodiversity standards\n",
    "            'Darwin Core': ['darwin core', 'darwincore', 'dwc'],\n",
    "            'ABCD': ['abcd', 'access to biological collection data'],\n",
    "            'EML': ['eml', 'ecological metadata language'],\n",
    "            'GBIF': ['gbif', 'global biodiversity information facility'],\n",
    "            \n",
    "            # General metadata standards\n",
    "            'Dublin Core': ['dublin core', 'dublincore', 'dc metadata'],\n",
    "            'ISO 19115': ['iso 19115', 'iso19115', 'geographic information metadata'],\n",
    "            'DCAT': ['dcat', 'data catalog vocabulary'],\n",
    "            'Schema.org': ['schema.org', 'schema org', 'structured data'],\n",
    "            \n",
    "            # Scientific data standards\n",
    "            'FAIR': ['fair data', 'fair principles', 'findable accessible interoperable reusable'],\n",
    "            'DataCite': ['datacite', 'data cite', 'doi metadata'],\n",
    "            'ORCID': ['orcid', 'open researcher and contributor id'],\n",
    "            'DOI': ['digital object identifier', 'doi'],\n",
    "            \n",
    "            # Environmental/Earth sciences\n",
    "            'CF Conventions': ['cf conventions', 'climate and forecast', 'netcdf'],\n",
    "            'ISO 19139': ['iso 19139', 'iso19139'],\n",
    "            'OGC': ['ogc', 'open geospatial consortium'],\n",
    "            'WMS': ['web map service', 'wms'],\n",
    "            'WFS': ['web feature service', 'wfs'],\n",
    "            \n",
    "            # Data exchange formats\n",
    "            'JSON-LD': ['json-ld', 'json linked data'],\n",
    "            'RDF': ['rdf', 'resource description framework'],\n",
    "            'OWL': ['owl', 'web ontology language'],\n",
    "            'SKOS': ['skos', 'simple knowledge organization system'],\n",
    "            \n",
    "            # Marine/Ocean standards\n",
    "            'OBIS': ['obis', 'ocean biogeographic information system'],\n",
    "            'ICES': ['ices', 'international council for the exploration of the sea'],\n",
    "            'SeaDataNet': ['seadatanet', 'sea data net'],\n",
    "            \n",
    "            # Research data standards\n",
    "            'CEDARS': ['cedars', 'comprehensive extensible data archival and retrieval system'],\n",
    "            'DataVerse': ['dataverse', 'data verse'],\n",
    "            'Zenodo': ['zenodo'],\n",
    "            'Figshare': ['figshare'],\n",
    "        }\n",
    "        \n",
    "        found_standards = []\n",
    "        \n",
    "        # Search for each standard\n",
    "        for standard_name, terms in data_standards.items():\n",
    "            for term in terms:\n",
    "                if term in page_text:\n",
    "                    found_standards.append(standard_name)\n",
    "                    break  # Found this standard, move to next\n",
    "        \n",
    "        # Also search in meta tags and structured data\n",
    "        meta_standards = []\n",
    "        \n",
    "        # Check meta tags\n",
    "        for meta in soup.find_all('meta'):\n",
    "            content = meta.get('content', '').lower()\n",
    "            name = meta.get('name', '').lower()\n",
    "            \n",
    "            for standard_name, terms in data_standards.items():\n",
    "                for term in terms:\n",
    "                    if term in content or term in name:\n",
    "                        meta_standards.append(standard_name)\n",
    "                        break\n",
    "        \n",
    "        # Check for structured data (JSON-LD, microdata)\n",
    "        json_ld = soup.find_all('script', type='application/ld+json')\n",
    "        if json_ld:\n",
    "            found_standards.append('JSON-LD')\n",
    "        \n",
    "        # Check for microdata\n",
    "        if soup.find_all(attrs={'itemtype': True}):\n",
    "            found_standards.append('Microdata')\n",
    "        \n",
    "        # Combine and deduplicate\n",
    "        all_standards = list(set(found_standards + meta_standards))\n",
    "        \n",
    "        if all_standards:\n",
    "            return ', '.join(sorted(all_standards))\n",
    "        \n",
    "        return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error detecting data standards for {url}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jk1lpvfb6kp",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error detecting data standards for https://coastwards.org: HTTPSConnectionPool(host='coastwards.org', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7ff0c4db8590>: Failed to establish a new connection: [Errno 111] Conexi√≥n rehusada'))\n"
     ]
    }
   ],
   "source": [
    "df_platforms['data_standards'] = df_platforms['platform_url'].apply(detect_data_standards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "w57nyoxj5sd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "platform_url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "data_standards",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "e358a914-0ad3-4c91-a741-723df60d6c4a",
       "rows": [
        [
         "0",
         "observation.org",
         "Protected by anti-bot"
        ],
        [
         "1",
         "seasearch.org.uk",
         "DOI"
        ],
        [
         "2",
         "natuurpunt.be",
         null
        ],
        [
         "3",
         "slu.se/artdatabanken",
         null
        ],
        [
         "4",
         "theroadlab.co.uk",
         "JSON-LD"
        ],
        [
         "5",
         "exploreyourshore.ie",
         "JSON-LD, OWL"
        ],
        [
         "6",
         "eyeonwater.org",
         null
        ],
        [
         "7",
         "iseahorse.org",
         "ICES, JSON-LD"
        ],
        [
         "8",
         "redpromar.org",
         null
        ],
        [
         "9",
         "coastwards.org",
         null
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>platform_url</th>\n",
       "      <th>data_standards</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>observation.org</td>\n",
       "      <td>Protected by anti-bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>seasearch.org.uk</td>\n",
       "      <td>DOI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>natuurpunt.be</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>slu.se/artdatabanken</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>theroadlab.co.uk</td>\n",
       "      <td>JSON-LD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>exploreyourshore.ie</td>\n",
       "      <td>JSON-LD, OWL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>eyeonwater.org</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>iseahorse.org</td>\n",
       "      <td>ICES, JSON-LD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>redpromar.org</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>coastwards.org</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           platform_url         data_standards\n",
       "0       observation.org  Protected by anti-bot\n",
       "1      seasearch.org.uk                    DOI\n",
       "2         natuurpunt.be                   None\n",
       "3  slu.se/artdatabanken                   None\n",
       "4      theroadlab.co.uk                JSON-LD\n",
       "5   exploreyourshore.ie           JSON-LD, OWL\n",
       "6        eyeonwater.org                   None\n",
       "7         iseahorse.org          ICES, JSON-LD\n",
       "8         redpromar.org                   None\n",
       "9        coastwards.org                   None"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_platforms[['platform_url', 'data_standards']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b37617",
   "metadata": {},
   "source": [
    "- Biodiversity Standards: Darwin Core, ABCD, EML, GBIF\n",
    "- General Metadata Standards: Dublin Core, ISO 19115, DCAT, Schema.org\n",
    "- Scientific Standards: FAIR, DataCite, ORCID, DOI\n",
    "- Environmental/Geospatial Standards: CF Conventions, OGC, WMS, WFS\n",
    "- Data Exchange Formats: JSON-LD, RDF, OWL, SKOS\n",
    "- Marine Standards: OBIS, ICES, SeaDataNet\n",
    "- Data Repositories: DataVerse, Zenodo, Figshare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f22237",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_platforms.to_csv(\"../data/df_platforms.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rsiw7ues0np",
   "metadata": {},
   "source": [
    "# data_license"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qqhzj3ylc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_data_license(url):\n",
    "    \"\"\"\n",
    "    Detects licensing information for data on platforms.\n",
    "    Uses a broad approach to capture any licensing mentions.\n",
    "    \n",
    "    Args:\n",
    "        url (str): Platform URL\n",
    "        \n",
    "    Returns:\n",
    "        str: License info if found, guidance if not found\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not url.startswith(('http://', 'https://')):\n",
    "            url = 'https://' + url\n",
    "        \n",
    "        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            return \"Page not accessible\"\n",
    "            \n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        text = soup.get_text().lower()\n",
    "        \n",
    "        # Check for anti-bot\n",
    "        if 'botstopper' in text or 'checking if you are not a bot' in text:\n",
    "            return \"Protected by anti-bot\"\n",
    "        \n",
    "        found_licenses = []\n",
    "        \n",
    "        # 1. Creative Commons (broad search)\n",
    "        if 'creative commons' in text:\n",
    "            if 'cc by-sa' in text or 'attribution-sharealike' in text:\n",
    "                found_licenses.append('CC BY-SA')\n",
    "            elif 'cc by-nc-sa' in text:\n",
    "                found_licenses.append('CC BY-NC-SA')\n",
    "            elif 'cc by-nc' in text or 'noncommercial' in text:\n",
    "                found_licenses.append('CC BY-NC')\n",
    "            elif 'cc by' in text or 'attribution' in text:\n",
    "                found_licenses.append('CC BY')\n",
    "            elif 'cc0' in text or 'public domain' in text:\n",
    "                found_licenses.append('CC0')\n",
    "            else:\n",
    "                found_licenses.append('Creative Commons')\n",
    "        \n",
    "        # 2. Other open licenses\n",
    "        if 'open data commons' in text or 'odc' in text:\n",
    "            found_licenses.append('Open Data Commons')\n",
    "        if 'open database license' in text or 'odbl' in text:\n",
    "            found_licenses.append('ODbL')\n",
    "        if 'open government' in text and 'licen' in text:\n",
    "            found_licenses.append('Open Government Licence')\n",
    "        \n",
    "        # 3. General usage terms (very broad)\n",
    "        if 'open access' in text:\n",
    "            found_licenses.append('Open Access')\n",
    "        if 'freely available' in text or 'free to use' in text:\n",
    "            found_licenses.append('Free Use')\n",
    "        if 'public domain' in text and 'creative commons' not in text:\n",
    "            found_licenses.append('Public Domain')\n",
    "        if 'non-commercial' in text or 'noncommercial' in text:\n",
    "            found_licenses.append('Non-Commercial Use')\n",
    "        if 'academic use' in text or 'educational use' in text:\n",
    "            found_licenses.append('Academic Use')\n",
    "        if 'research use' in text or 'research purposes' in text:\n",
    "            found_licenses.append('Research Use')\n",
    "        if 'attribution required' in text:\n",
    "            found_licenses.append('Attribution Required')\n",
    "        if 'all rights reserved' in text:\n",
    "            found_licenses.append('All Rights Reserved')\n",
    "        \n",
    "        # 4. Look for any mention of \"license\" or \"licence\"\n",
    "        if not found_licenses:\n",
    "            if 'license' in text or 'licence' in text:\n",
    "                found_licenses.append('Licensed (unspecified)')\n",
    "        \n",
    "        # 5. Check for CC images\n",
    "        if not found_licenses:\n",
    "            for img in soup.find_all('img'):\n",
    "                src = img.get('src', '').lower()\n",
    "                alt = img.get('alt', '').lower()\n",
    "                if any(cc in src or cc in alt for cc in ['creativecommons', 'cc-by', 'cc0']):\n",
    "                    found_licenses.append('Creative Commons (Badge)')\n",
    "                    break\n",
    "        \n",
    "        # 6. Check for CC links\n",
    "        if not found_licenses:\n",
    "            for link in soup.find_all('a', href=True):\n",
    "                href = link.get('href').lower()\n",
    "                if 'creativecommons.org' in href:\n",
    "                    found_licenses.append('Creative Commons (Link)')\n",
    "                    break\n",
    "        \n",
    "        # Return results\n",
    "        if found_licenses:\n",
    "            # Remove duplicates while preserving order\n",
    "            unique_licenses = []\n",
    "            seen = set()\n",
    "            for license_name in found_licenses:\n",
    "                if license_name not in seen:\n",
    "                    seen.add(license_name)\n",
    "                    unique_licenses.append(license_name)\n",
    "            \n",
    "            return ', '.join(unique_licenses[:3])\n",
    "        \n",
    "        # If no licenses found, check if we can access terms pages\n",
    "        try:\n",
    "            terms_response = requests.head(url + '/terms', headers=headers, timeout=5)\n",
    "            if terms_response.status_code == 200:\n",
    "                return \"Check terms/legal pages\"\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        return \"No license info found\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error detecting license for {url}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8izoctxx3t",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error detecting license for https://coastwards.org: HTTPSConnectionPool(host='coastwards.org', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7ff0c4f1e890>: Failed to establish a new connection: [Errno 111] Conexi√≥n rehusada'))\n"
     ]
    }
   ],
   "source": [
    "df_platforms['data_license'] = df_platforms['platform_url'].apply(detect_data_license)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90u8jld7gm",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "platform_url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "data_license",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "cc3ef5d6-18e4-4340-ac04-6663ac784271",
       "rows": [
        [
         "0",
         "observation.org",
         "Protected by anti-bot"
        ],
        [
         "1",
         "seasearch.org.uk",
         "No license info found"
        ],
        [
         "2",
         "natuurpunt.be",
         "No license info found"
        ],
        [
         "3",
         "slu.se/artdatabanken",
         "No license info found"
        ],
        [
         "4",
         "theroadlab.co.uk",
         "No license info found"
        ],
        [
         "5",
         "exploreyourshore.ie",
         "No license info found"
        ],
        [
         "6",
         "eyeonwater.org",
         "No license info found"
        ],
        [
         "7",
         "iseahorse.org",
         "All Rights Reserved"
        ],
        [
         "8",
         "redpromar.org",
         "Creative Commons (Badge)"
        ],
        [
         "9",
         "coastwards.org",
         null
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>platform_url</th>\n",
       "      <th>data_license</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>observation.org</td>\n",
       "      <td>Protected by anti-bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>seasearch.org.uk</td>\n",
       "      <td>No license info found</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>natuurpunt.be</td>\n",
       "      <td>No license info found</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>slu.se/artdatabanken</td>\n",
       "      <td>No license info found</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>theroadlab.co.uk</td>\n",
       "      <td>No license info found</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>exploreyourshore.ie</td>\n",
       "      <td>No license info found</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>eyeonwater.org</td>\n",
       "      <td>No license info found</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>iseahorse.org</td>\n",
       "      <td>All Rights Reserved</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>redpromar.org</td>\n",
       "      <td>Creative Commons (Badge)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>coastwards.org</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           platform_url              data_license\n",
       "0       observation.org     Protected by anti-bot\n",
       "1      seasearch.org.uk     No license info found\n",
       "2         natuurpunt.be     No license info found\n",
       "3  slu.se/artdatabanken     No license info found\n",
       "4      theroadlab.co.uk     No license info found\n",
       "5   exploreyourshore.ie     No license info found\n",
       "6        eyeonwater.org     No license info found\n",
       "7         iseahorse.org       All Rights Reserved\n",
       "8         redpromar.org  Creative Commons (Badge)\n",
       "9        coastwards.org                      None"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_platforms[['platform_url', 'data_license']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30faec05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_platforms.to_csv(\"../data/df_platforms.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
