{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c04943",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from google_play_scraper import app\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba575ab",
   "metadata": {},
   "source": [
    "# Extract selected Android Apps info from Google Store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d214bb38",
   "metadata": {},
   "source": [
    "- climatewatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49c55e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"owner\": \"SPOTTERON\",\n",
      "  \"contact_email\": \"office@spotteron.net\",\n",
      "  \"privacy_policy\": \"https://www.spotteron.net/privacy\",\n",
      "  \"languages_available\": null,\n",
      "  \"created_at\": \"Feb 5, 2021\",\n",
      "  \"developer_website\": \"https://www.spotteron.app\",\n",
      "  \"description\": \"The ClimateWatch program is the collaborative brainchild of Earthwatch Australia, the Bureau of Meteorology and the University of Melbourne to understand how changes in temperature and rainfall are affecting the seasonal behaviour of Australia's plants and animals. The first continental phenology project in the Southern Hemisphere, ClimateWatch enables every Australian to be involved in collecting and recording data that will help shape our country\\u2019s scientific response to climate change.\\r\\n\\r\\nWhat is phenology?\\r\\nPhenology is the study of periodic plant and animal life cycle events and how these are influenced by seasonal and interannual variations in climate. Examples include bird nesting, insect hatching, plant flowering, and fruit ripening. Many studies have already provided insight into the relationship between climate variables, such as temperature and rainfall, to the timing of these phenophases. Monitoring phenology is important as changes can impact entire biological communities, our food sources and our environment. Unfortunately few significant datasets have been collected and researched in Australia and the Southern Hemisphere.\\r\\n\\r\\nWe need your help capturing the impact climate change is having on our plants and wildlife. With our free ClimateWatch app, you can gather information in your own backyard, on the way to school, in your school ground, or at a local park. The information you collect will help us develop adaptation strategies for species\\u2019 survival into the future.\\r\\n\\r\\nWe acknowledge our funders, QBE Insurance and Helen Macpherson Smith Trust, without whom this superb upgrade to the ClimateWatch app would not have been possible. Thanks to Parks Victoria for supporting the \\u2018ClimateWatch in Parks\\u2019 program, connecting communities and enabling them to take action on climate change.\\r\\nThe ClimateWatch App is running on the SPOTTERON Citizen Science platform.\",\n",
      "  \"currency\": \"USD\",\n",
      "  \"summary\": \"Let's spot Australia's nature & record its adaptation to climate change\",\n",
      "  \"genre\": \"Education\",\n",
      "  \"comments\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "app_id = \"com.spotteron.climatewatch\"\n",
    "info = app(app_id, lang='en')\n",
    "\n",
    "# Main Data\n",
    "datos_extraidos = {\n",
    "    'owner': info.get('developer'),\n",
    "    'contact_email': info.get('developerEmail'),\n",
    "    'privacy_policy': info.get('privacyPolicy'),\n",
    "    'languages_available': info.get('contentRatingDescription'),\n",
    "    'created_at': info.get('released'),\n",
    "    \"developer_website\": info.get('developerWebsite'),\n",
    "    \"description\": info.get(\"description\"),    \n",
    "    \"currency\": info.get(\"currency\"),\n",
    "    \"summary\": info.get(\"summary\"),\n",
    "    \"genre\": info.get(\"genre\"),\n",
    "    \"comments\": info.get(\"comments\"),\n",
    "}\n",
    "\n",
    "print(json.dumps(datos_extraidos, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79d708ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL DATA com.spotteron.climatewatch:\n",
      "{\n",
      "  \"title\": \"ClimateWatch | SPOTTERON\",\n",
      "  \"description\": \"The ClimateWatch program is the collaborative brainchild of Earthwatch Australia, the Bureau of Meteorology and the University of Melbourne to understand how changes in temperature and rainfall are affecting the seasonal behaviour of Australia's plants and animals. The first continental phenology project in the Southern Hemisphere, ClimateWatch enables every Australian to be involved in collecting and recording data that will help shape our country’s scientific response to climate change.\\r\\n\\r\\nWhat is phenology?\\r\\nPhenology is the study of periodic plant and animal life cycle events and how these are influenced by seasonal and interannual variations in climate. Examples include bird nesting, insect hatching, plant flowering, and fruit ripening. Many studies have already provided insight into the relationship between climate variables, such as temperature and rainfall, to the timing of these phenophases. Monitoring phenology is important as changes can impact entire biological communities, our food sources and our environment. Unfortunately few significant datasets have been collected and researched in Australia and the Southern Hemisphere.\\r\\n\\r\\nWe need your help capturing the impact climate change is having on our plants and wildlife. With our free ClimateWatch app, you can gather information in your own backyard, on the way to school, in your school ground, or at a local park. The information you collect will help us develop adaptation strategies for species’ survival into the future.\\r\\n\\r\\nWe acknowledge our funders, QBE Insurance and Helen Macpherson Smith Trust, without whom this superb upgrade to the ClimateWatch app would not have been possible. Thanks to Parks Victoria for supporting the ‘ClimateWatch in Parks’ program, connecting communities and enabling them to take action on climate change.\\r\\nThe ClimateWatch App is running on the SPOTTERON Citizen Science platform.\",\n",
      "  \"descriptionHTML\": \"The ClimateWatch program is the collaborative brainchild of Earthwatch Australia, the Bureau of Meteorology and the University of Melbourne to understand how changes in temperature and rainfall are affecting the seasonal behaviour of Australia&#39;s plants and animals. The first continental phenology project in the Southern Hemisphere, ClimateWatch enables every Australian to be involved in collecting and recording data that will help shape our country’s scientific response to climate change.<br><br>What is phenology?<br>Phenology is the study of periodic plant and animal life cycle events and how these are influenced by seasonal and interannual variations in climate. Examples include bird nesting, insect hatching, plant flowering, and fruit ripening. Many studies have already provided insight into the relationship between climate variables, such as temperature and rainfall, to the timing of these phenophases. Monitoring phenology is important as changes can impact entire biological communities, our food sources and our environment. Unfortunately few significant datasets have been collected and researched in Australia and the Southern Hemisphere.<br><br>We need your help capturing the impact climate change is having on our plants and wildlife. With our free ClimateWatch app, you can gather information in your own backyard, on the way to school, in your school ground, or at a local park. The information you collect will help us develop adaptation strategies for species’ survival into the future.<br><br>We acknowledge our funders, QBE Insurance and Helen Macpherson Smith Trust, without whom this superb upgrade to the ClimateWatch app would not have been possible. Thanks to Parks Victoria for supporting the ‘ClimateWatch in Parks’ program, connecting communities and enabling them to take action on climate change.<br>The ClimateWatch App is running on the SPOTTERON Citizen Science platform.\",\n",
      "  \"summary\": \"Let's spot Australia's nature & record its adaptation to climate change\",\n",
      "  \"installs\": \"1,000+\",\n",
      "  \"minInstalls\": 1000,\n",
      "  \"realInstalls\": 4239,\n",
      "  \"score\": 0,\n",
      "  \"ratings\": 0,\n",
      "  \"reviews\": 0,\n",
      "  \"histogram\": [\n",
      "    0,\n",
      "    0,\n",
      "    0,\n",
      "    0,\n",
      "    0\n",
      "  ],\n",
      "  \"price\": 0,\n",
      "  \"free\": true,\n",
      "  \"currency\": \"USD\",\n",
      "  \"sale\": false,\n",
      "  \"saleTime\": null,\n",
      "  \"originalPrice\": null,\n",
      "  \"saleText\": null,\n",
      "  \"offersIAP\": false,\n",
      "  \"inAppProductPrice\": null,\n",
      "  \"developer\": \"SPOTTERON\",\n",
      "  \"developerId\": \"6074809323558115618\",\n",
      "  \"developerEmail\": \"office@spotteron.net\",\n",
      "  \"developerWebsite\": \"https://www.spotteron.app\",\n",
      "  \"developerAddress\": null,\n",
      "  \"privacyPolicy\": \"https://www.spotteron.net/privacy\",\n",
      "  \"genre\": \"Education\",\n",
      "  \"genreId\": \"EDUCATION\",\n",
      "  \"categories\": [],\n",
      "  \"icon\": \"https://play-lh.googleusercontent.com/FFd3mC19Yjit2J7wkKzCuokZbXONwo2bZ46FvKvOj58V-wEXbTen25PJkYHE6GvFC7o\",\n",
      "  \"headerImage\": \"https://play-lh.googleusercontent.com/noHDUSNHzCZovuWP5rWVpBUHDW24XM39RDxpeJHSTjuEGbq-p_J26wewS3QhuWKvxCY\",\n",
      "  \"screenshots\": [\n",
      "    \"https://play-lh.googleusercontent.com/JV_c2XtgSjO7-dvk8c96zzE3Ac8576OqrRL-XsYWoVwAJIS3Y4PmGyNiW30tX4Ir0fQ\",\n",
      "    \"https://play-lh.googleusercontent.com/qNTyegEPd7Ij0OcYdyS0RcC9NMTXSTCLXOu7dcYwrN_HqBISgLyQlQ3udlaJwAXHJw\",\n",
      "    \"https://play-lh.googleusercontent.com/fDU07t6QeUntos7-ChJTetT4q3b8KCUol7Lz6laESFSiYjatuiJgW6DMz9jUht2DkdE\",\n",
      "    \"https://play-lh.googleusercontent.com/VvaGT1oXdy8rnFEX55FfiOtbAHM_6CgKlCkEQXrvpIMFShb-CWE8QxYUruQM_T6ai3qt\",\n",
      "    \"https://play-lh.googleusercontent.com/MGrNW32bEQNvoZfd1wYe8o5U2dBrlTqPGU0aQb3FmX_av2AIwn4gKvJDBYhZX7uAupc\",\n",
      "    \"https://play-lh.googleusercontent.com/6LiougLrHJfCi4fTqWYGqzSrMSnMnfMqsMkNFPxh-LleAZxtjEBC1huRwcg0thARdA\",\n",
      "    \"https://play-lh.googleusercontent.com/CsukPCSuypxNRU-ETgJrdPd5fu7eSz7wivCQOWyJ5Wc8o9nW74uyRHJj-lNc6mhX1M1g\",\n",
      "    \"https://play-lh.googleusercontent.com/ygLPOnpsJgWZy2Cm8YvblSR8QFiAmW5fKloV3xh-8mHHg3BBp94K1e6tjJrG4NBv4iI\",\n",
      "    \"https://play-lh.googleusercontent.com/xyTcXy5XOME7ClmI9igiMqjuWRNgfZw58gDe94mLrGX_00qmEd31UR5bibMSr6WXOIM\",\n",
      "    \"https://play-lh.googleusercontent.com/H7aivaX4el4KSp8GTyy2VYszRimzmtQmQ8jmvNvtpWLUoCeA5u8FAqRn8_BjnjJWyQg\",\n",
      "    \"https://play-lh.googleusercontent.com/M7nX1-c8uePxvYhax7JwNo4PxwwPEtyY-Ev35c3b_oMSIT59o-RahwJIo5Y-FEdNoN0\",\n",
      "    \"https://play-lh.googleusercontent.com/7LMAJXqgIeQzCufv8KyyD8axOV9fUedYAcT-zI31_TonSrXzPjFXqbDB7kC8GuTmj7I\",\n",
      "    \"https://play-lh.googleusercontent.com/HxIbSNwNujsIocK1vQl3-1b6vKBXXJTW1Izdg6LS5LDvn39dR21Y6eobjOcQwPZpRHg\",\n",
      "    \"https://play-lh.googleusercontent.com/aSVCH7_WN08RyJ7BDjBuY3FIF9FaEHtqO_-mf_I7qg6F9pBxfdH1-dgxz3W2BGDHADM\",\n",
      "    \"https://play-lh.googleusercontent.com/Pdk_XfjdIp4VHtuk1ETyIam9zASTKUVYP8kbd0NKUWeASyvP8zJTOdPbHqDO-ruV8dwo\",\n",
      "    \"https://play-lh.googleusercontent.com/C9dIwvcCf4QhMcwhiZA_whO9jdHxidPnygudhDex4fZCjR-wxj6NCRzbP5JuH5daST4\",\n",
      "    \"https://play-lh.googleusercontent.com/J-Nm-jEQa22LkJBJqFZmNxPq7o0WvtqwmhlKvxYD__b5iPU-GaxVN2IID64_ZD6UA2-l\",\n",
      "    \"https://play-lh.googleusercontent.com/IoLxdNYSzA7K3SJ25N3sZSXKuW94jnV1t81DfYC3-isfCXYAeozDZ614zrkl6LdKC295\",\n",
      "    \"https://play-lh.googleusercontent.com/Tg-JpzhIH6_ZyrMMyh-4zDb80KinR1Xe7LlkhiHhyiZDyslsskBcwEOCL8Jt4LlGZqE\"\n",
      "  ],\n",
      "  \"video\": null,\n",
      "  \"videoImage\": null,\n",
      "  \"contentRating\": \"Everyone\",\n",
      "  \"contentRatingDescription\": null,\n",
      "  \"adSupported\": false,\n",
      "  \"containsAds\": false,\n",
      "  \"released\": \"Feb 5, 2021\",\n",
      "  \"lastUpdatedOn\": null,\n",
      "  \"updated\": null,\n",
      "  \"version\": \"Varies with device\",\n",
      "  \"comments\": [],\n",
      "  \"appId\": \"com.spotteron.climatewatch\",\n",
      "  \"url\": \"https://play.google.com/store/apps/details?id=com.spotteron.climatewatch&hl=en&gl=us\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Available fields in Google Store\n",
    "from google_play_scraper import app\n",
    "import json\n",
    "\n",
    "app_id = \"com.spotteron.climatewatch\"\n",
    "info = app(app_id, lang='en', country='us')\n",
    "\n",
    "print(f\"FULL DATA {app_id}:\")\n",
    "print(json.dumps(info, indent=2, ensure_ascii=False, default=str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "820ddff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pending scraping to complete info\n",
    "info_url = \"https://www.spotteron.com/climatewatch/info\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1414cb60",
   "metadata": {},
   "source": [
    "* crowdwater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d727705b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"owner\": \"SPOTTERON\",\n",
      "  \"contact_email\": \"office@spotteron.net\",\n",
      "  \"privacy_policy\": \"https://www.spotteron.net/terms-of-use\",\n",
      "  \"languages_available\": null,\n",
      "  \"created_at\": \"Feb 27, 2017\",\n",
      "  \"developer_website\": \"http://www.spotteron.net\",\n",
      "  \"description\": \"CrowdWater is a SNF-funded project at the University of Zurich, Department of Geography, Unit Hydrology & Climate.\\r\\n\\r\\nThis PhD project aims to examine the potential of \\u201ccrowdsourcing\\u201d, meaning observations of voluntary participants. As the name suggests, the project looks at the potential of crowdsourcing in the field of hydrology. We will collect water level, streamflow and soil moisture data. The project will not only look at the possibilities of collecting data but also at the value of this data for hydrological forecasts. The long-term aim of the project is to collect a large amount of data and to improve the forecast of hydrological events, such as droughts or floods.\\r\\n\\r\\nThere are two basic parts of the CrowdWater project. On the one hand, we will assess public involvement in hydrological observations. For this we use a \\u201cgeocaching\\u201d type approach with the help of smartphones. By using an app that will be developed over the coming months, users can install a virtual measuring station. Anyone can then add their observations to this station and all observations will be collected and published anonymously on the CrowdWater homepage. Another goal of the CrowdWater project is to analyse the potential of using the collected data for hydrological models. This question will be addressed by using hydrological computer models to predict streamflow. These models will assess the benefit of the crowd-sourced data.\\r\\n\\r\\nAt the moment the app is under development, so for now we are collecting data with the help of information boards and paper forms at various locations in the greater Zurich area. This data will help us to improve our methodology and enables us to make a first assessment of the data quality. As soon as new stations are installed, we will post the location here and on facebook.\\r\\n\\r\\nCrowdWater is powered by SPOTTERON Citizen Science Apps.\",\n",
      "  \"currency\": \"USD\",\n",
      "  \"summary\": \"Crowdwater is a Citizen Science project about hydrology.\",\n",
      "  \"genre\": \"Education\",\n",
      "  \"comments\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "app_id = \"com.spotteron.crowdwater\"\n",
    "info = app(app_id, lang='en')\n",
    "\n",
    "# Main Data\n",
    "datos_extraidos = {\n",
    "    'owner': info.get('developer'),\n",
    "    'contact_email': info.get('developerEmail'),\n",
    "    'privacy_policy': info.get('privacyPolicy'),\n",
    "    'languages_available': info.get('contentRatingDescription'),\n",
    "    'created_at': info.get('released'),\n",
    "    \"developer_website\": info.get('developerWebsite'),\n",
    "    \"description\": info.get(\"description\"),    \n",
    "    \"currency\": info.get(\"currency\"),\n",
    "    \"summary\": info.get(\"summary\"),\n",
    "    \"genre\": info.get(\"genre\"),\n",
    "    \"comments\": info.get(\"comments\"),\n",
    "}\n",
    "\n",
    "print(json.dumps(datos_extraidos, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db39ab74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL DATA com.spotteron.crowdwater:\n",
      "{\n",
      "  \"title\": \"CrowdWater | SPOTTERON\",\n",
      "  \"description\": \"CrowdWater is a SNF-funded project at the University of Zurich, Department of Geography, Unit Hydrology & Climate.\\r\\n\\r\\nThis PhD project aims to examine the potential of “crowdsourcing”, meaning observations of voluntary participants. As the name suggests, the project looks at the potential of crowdsourcing in the field of hydrology. We will collect water level, streamflow and soil moisture data. The project will not only look at the possibilities of collecting data but also at the value of this data for hydrological forecasts. The long-term aim of the project is to collect a large amount of data and to improve the forecast of hydrological events, such as droughts or floods.\\r\\n\\r\\nThere are two basic parts of the CrowdWater project. On the one hand, we will assess public involvement in hydrological observations. For this we use a “geocaching” type approach with the help of smartphones. By using an app that will be developed over the coming months, users can install a virtual measuring station. Anyone can then add their observations to this station and all observations will be collected and published anonymously on the CrowdWater homepage. Another goal of the CrowdWater project is to analyse the potential of using the collected data for hydrological models. This question will be addressed by using hydrological computer models to predict streamflow. These models will assess the benefit of the crowd-sourced data.\\r\\n\\r\\nAt the moment the app is under development, so for now we are collecting data with the help of information boards and paper forms at various locations in the greater Zurich area. This data will help us to improve our methodology and enables us to make a first assessment of the data quality. As soon as new stations are installed, we will post the location here and on facebook.\\r\\n\\r\\nCrowdWater is powered by SPOTTERON Citizen Science Apps.\",\n",
      "  \"descriptionHTML\": \"CrowdWater is a SNF-funded project at the University of Zurich, Department of Geography, Unit Hydrology &amp; Climate.<br><br>This PhD project aims to examine the potential of “crowdsourcing”, meaning observations of voluntary participants. As the name suggests, the project looks at the potential of crowdsourcing in the field of hydrology. We will collect water level, streamflow and soil moisture data. The project will not only look at the possibilities of collecting data but also at the value of this data for hydrological forecasts. The long-term aim of the project is to collect a large amount of data and to improve the forecast of hydrological events, such as droughts or floods.<br><br>There are two basic parts of the CrowdWater project. On the one hand, we will assess public involvement in hydrological observations. For this we use a “geocaching” type approach with the help of smartphones. By using an app that will be developed over the coming months, users can install a virtual measuring station. Anyone can then add their observations to this station and all observations will be collected and published anonymously on the CrowdWater homepage. Another goal of the CrowdWater project is to analyse the potential of using the collected data for hydrological models. This question will be addressed by using hydrological computer models to predict streamflow. These models will assess the benefit of the crowd-sourced data.<br><br>At the moment the app is under development, so for now we are collecting data with the help of information boards and paper forms at various locations in the greater Zurich area. This data will help us to improve our methodology and enables us to make a first assessment of the data quality. As soon as new stations are installed, we will post the location here and on facebook.<br><br>CrowdWater is powered by SPOTTERON Citizen Science Apps.\",\n",
      "  \"summary\": \"Crowdwater is a Citizen Science project about hydrology.\",\n",
      "  \"installs\": \"5,000+\",\n",
      "  \"minInstalls\": 5000,\n",
      "  \"realInstalls\": 7428,\n",
      "  \"score\": 0,\n",
      "  \"ratings\": 0,\n",
      "  \"reviews\": 0,\n",
      "  \"histogram\": [\n",
      "    0,\n",
      "    0,\n",
      "    0,\n",
      "    0,\n",
      "    0\n",
      "  ],\n",
      "  \"price\": 0,\n",
      "  \"free\": true,\n",
      "  \"currency\": \"USD\",\n",
      "  \"sale\": false,\n",
      "  \"saleTime\": null,\n",
      "  \"originalPrice\": null,\n",
      "  \"saleText\": null,\n",
      "  \"offersIAP\": false,\n",
      "  \"inAppProductPrice\": null,\n",
      "  \"developer\": \"SPOTTERON\",\n",
      "  \"developerId\": \"6074809323558115618\",\n",
      "  \"developerEmail\": \"office@spotteron.net\",\n",
      "  \"developerWebsite\": \"http://www.spotteron.net\",\n",
      "  \"developerAddress\": null,\n",
      "  \"privacyPolicy\": \"https://www.spotteron.net/terms-of-use\",\n",
      "  \"genre\": \"Education\",\n",
      "  \"genreId\": \"EDUCATION\",\n",
      "  \"categories\": [],\n",
      "  \"icon\": \"https://play-lh.googleusercontent.com/L-5BZ-xPbau5TC-ONNAVATLxcoO2VeMTp4q96F_VZUAX8M78xJ3k_MIGoY1npCMVLDA\",\n",
      "  \"headerImage\": \"https://play-lh.googleusercontent.com/lTS4ih7KkMY2uwLOBgk2xXwH7QIIuCZL4QsLjbUZ_D-G8Wie2_dx5DfSkv-LAabBgMrL\",\n",
      "  \"screenshots\": [\n",
      "    \"https://play-lh.googleusercontent.com/5U23p_1aFo4xanw7jp9tZBsl95Y2NQ4VO_aJEDazWnvQ3XXr1eGYMoBC4Qfkb0U2zc4\",\n",
      "    \"https://play-lh.googleusercontent.com/n6W0teSMLjpNbEUpu6RLu2FWByGXmt5y447zZNkDH8kWqXywzzrnO8OYh2ZAcPnECNY\",\n",
      "    \"https://play-lh.googleusercontent.com/5XDSKN0gLIuRXecG938pfE3gUkUCWvaxTiyECo1WycI8gunnhLPjXs69cwNme2GS1Q\",\n",
      "    \"https://play-lh.googleusercontent.com/qisYpswdDpPpxe1Nv0_5EaC2dhtsH22I_cAgFPuRVYmUo_A-xklSpVPGBT21wCU80qKM\",\n",
      "    \"https://play-lh.googleusercontent.com/Oq0wdHkI_zczhIGsAtID_7J6614MfLl8ZegpzGhSxuVp5eGK0TFebsiEnnaKwE8x3sA\",\n",
      "    \"https://play-lh.googleusercontent.com/PB_4JUEDAY4PxkRQ8mI2dmmMMXKmeeSn7Tss2eHyoKRMb3wOqo5o1oTiyPkb8h8VOk_B\",\n",
      "    \"https://play-lh.googleusercontent.com/EDVZhgI27Ot7SBS3ZprGL3hGaIY8cVTxGMHG-6qPJpJUsUT_Pkggj9I7D9ZSpF1OXQA\",\n",
      "    \"https://play-lh.googleusercontent.com/Rg-4fPi-39Z4iGwO3bTTDjTVkRv8QAMKKxw1x3FUvCkQrhd5b_GI3toYHH1JQtHMmA\",\n",
      "    \"https://play-lh.googleusercontent.com/pFJEOgT4C2SozlPfXoVANdxPx8U-y__X-vWbSloR4QiddYhmoZFAWJDpYdCEBPCMr_Y\",\n",
      "    \"https://play-lh.googleusercontent.com/MYw_0xYe-m1X6eXgr85L0CRpNpwsYJg9Cf5FGBGXPNRs1XKti85_-Kdt99bE5hu8OncJ\",\n",
      "    \"https://play-lh.googleusercontent.com/fXWr1C5xX7Gzh9ns07DxdbANqGSGK_JiAfEqGyXDqzvG7Llbp2-i8OU55_48fSqCow\",\n",
      "    \"https://play-lh.googleusercontent.com/-Jbi6mlgpLn4rb3iLK5JyB3KLSKsBobyaQG51j9ByRilRa-SjIARM2VFhPo6zfnOR2w\",\n",
      "    \"https://play-lh.googleusercontent.com/hI1aaidSYWqxF-Us93Ao12Q4VwRI-z7UK6_2ZZrJA_Q7-6sHt1fbHdJKuAPemkiduU0\",\n",
      "    \"https://play-lh.googleusercontent.com/pultPSUwSpjm71xXZgcUhUXQr1lxOmmU9ctHID9s-ulFcxn6OesGTu3iG7cdWUy5kQ\",\n",
      "    \"https://play-lh.googleusercontent.com/0SCVLu-B6gVfDe8ytn3108JMHB8nxOilOLCyXvhzw8L_w_AsDGzKRH8vMWaY6d9Z0w4\",\n",
      "    \"https://play-lh.googleusercontent.com/7bDrzr2l0xBlpfXc4ADnAWDYnRjqaOJgxpvB7-CXWeHsDWP-efUcr63uzKRrWZzcgN0\",\n",
      "    \"https://play-lh.googleusercontent.com/gpvS9OkIWrOIy2z_8YRZDtvKpO-n8dv1B8eLT4Kb6okvfvSJSWWp7uFWZVKUKiK8Krg\",\n",
      "    \"https://play-lh.googleusercontent.com/5xEMv1fhVRnbXYNFbeyKgBoHH6rEifuEMy2_1zMpdPVG0a-f3AdltrtnludWIY4xUjDI\",\n",
      "    \"https://play-lh.googleusercontent.com/0jeN9Px8zRHFW_dxqwCoLxld_aW2OYj1kxBvwtT4WPcNzMxdNK7aplb4wmyvrn13IA\"\n",
      "  ],\n",
      "  \"video\": \"https://www.youtube.com/embed/nfoXzAEsO_A?ps=play&vq=large&rel=0&autohide=1&showinfo=0\",\n",
      "  \"videoImage\": \"https://play-lh.googleusercontent.com/lTS4ih7KkMY2uwLOBgk2xXwH7QIIuCZL4QsLjbUZ_D-G8Wie2_dx5DfSkv-LAabBgMrL\",\n",
      "  \"contentRating\": \"Everyone\",\n",
      "  \"contentRatingDescription\": null,\n",
      "  \"adSupported\": false,\n",
      "  \"containsAds\": false,\n",
      "  \"released\": \"Feb 27, 2017\",\n",
      "  \"lastUpdatedOn\": null,\n",
      "  \"updated\": null,\n",
      "  \"version\": \"Varies with device\",\n",
      "  \"comments\": [],\n",
      "  \"appId\": \"com.spotteron.crowdwater\",\n",
      "  \"url\": \"https://play.google.com/store/apps/details?id=com.spotteron.crowdwater&hl=en&gl=us\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from google_play_scraper import app\n",
    "import json\n",
    "\n",
    "info = app(app_id, lang='en', country='us')\n",
    "\n",
    "print(f\"FULL DATA {app_id}:\")\n",
    "print(json.dumps(info, indent=2, ensure_ascii=False, default=str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb032c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pending scraping to complete info\n",
    "info_url = \"https://www.spotteron.com/crowdwater/info\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c29d1e",
   "metadata": {},
   "source": [
    "# iOS apps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5ed53d",
   "metadata": {},
   "source": [
    "`year_creation` and `genre`, available in iOS data. Save other information, but not included in fields of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "202d1947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tea Bag Index | SPOTTERON\n",
      "year_creation: 2019\n",
      "Education\n",
      "Saved data\n",
      "\n",
      "CoastSnap | SPOTTERON\n",
      "year_creation: 2020\n",
      "Education\n",
      "Saved data\n",
      "\n",
      "Coastal Observer | SPOTTERON\n",
      "year_creation: 2019\n",
      "Education\n",
      "Saved data\n",
      "\n",
      "Roadkill | SPOTTERON\n",
      "year_creation: 2015\n",
      "Education\n",
      "Saved data\n",
      "\n",
      "Star-Spotting | SPOTTERON\n",
      "year_creation: 2019\n",
      "Education\n",
      "Saved data\n",
      "\n",
      "SpiderSpotter | SPOTTERON\n",
      "year_creation: 2019\n",
      "Education\n",
      "Saved data\n",
      "\n",
      "CrowdWater | SPOTTERON\n",
      "year_creation: 2017\n",
      "Education\n",
      "Saved data\n",
      "\n",
      "Our Outdoors | SPOTTERON\n",
      "year_creation: 2020\n",
      "Health & Fitness\n",
      "Saved data\n",
      "\n",
      "Alpine School App | SPOTTERON\n",
      "year_creation: 2019\n",
      "Education\n",
      "Saved data\n",
      "\n",
      "Spot-a-Bee | SPOTTERON\n",
      "year_creation: 2020\n",
      "Education\n",
      "Saved data\n",
      "\n",
      "Big City Birds | SPOTTERON\n",
      "year_creation: 2020\n",
      "Education\n",
      "Saved data\n",
      "\n",
      "Minka\n",
      "year_creation: 2023\n",
      "Education\n",
      "Saved data\n",
      "\n",
      "SIBRA | SPOTTERON\n",
      "year_creation: 2020\n",
      "Education\n",
      "Saved data\n",
      "\n",
      "MAKENYA | SPOTTERON\n",
      "year_creation: 2021\n",
      "Travel\n",
      "Saved data\n",
      "\n",
      "ClimateWatch | SPOTTERON\n",
      "year_creation: 2021\n",
      "Education\n",
      "Saved data\n",
      "\n",
      "What's going on? | SPOTTERON\n",
      "year_creation: 2017\n",
      "Education\n",
      "Saved data\n",
      "\n",
      "WaldrApp | SPOTTERON\n",
      "year_creation: 2017\n",
      "Education\n",
      "Saved data\n",
      "\n",
      "Forschen im Almtal | SPOTTERON\n",
      "year_creation: 2017\n",
      "Education\n",
      "Saved data\n",
      "\n",
      "KraMobil | SPOTTERON\n",
      "year_creation: 2020\n",
      "Education\n",
      "Saved data\n",
      "\n",
      "Landauf LandApp BW | SPOTTERON\n",
      "year_creation: 2019\n",
      "Education\n",
      "Saved data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def extraer_metadata_ios_completa(app_id=app_id, country=\"us\"):\n",
    "    \"\"\"\n",
    "    Extrae metadata completa de iOS App Store\n",
    "    \"\"\"\n",
    "    url = f\"https://itunes.apple.com/lookup?id={app_id}&country={country}&entity=software\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        data = response.json()\n",
    "        \n",
    "        if data['resultCount'] == 0:\n",
    "            return None\n",
    "        \n",
    "        info = data['results'][0]\n",
    "        \n",
    "        # Función auxiliar para convertir tamaño\n",
    "        def calcular_size_mb(size_bytes):\n",
    "            if not size_bytes:\n",
    "                return None\n",
    "            try:\n",
    "                # Convertir a int si es string\n",
    "                size_int = int(size_bytes) if isinstance(size_bytes, str) else size_bytes\n",
    "                return round(size_int / (1024*1024), 2)\n",
    "            except:\n",
    "                return None\n",
    "        \n",
    "        # Función auxiliar para extraer año\n",
    "        def extraer_year(fecha_str):\n",
    "            if not fecha_str:\n",
    "                return None\n",
    "            try:\n",
    "                return datetime.fromisoformat(fecha_str.replace('Z', '+00:00')).year\n",
    "            except:\n",
    "                return None\n",
    "        \n",
    "        # Mapeo a estructura deseada\n",
    "        metadata = {\n",
    "            # IDENTIFICACIÓN\n",
    "            'app_id': info.get('bundleId'),\n",
    "            'track_id': info.get('trackId'),\n",
    "            'title': info.get('trackName'),\n",
    "            'url': info.get('trackViewUrl'),\n",
    "            \n",
    "            # DESARROLLADOR\n",
    "            'owner': info.get('artistName'),\n",
    "            'seller_name': info.get('sellerName'),\n",
    "            'developer_id': info.get('artistId'),\n",
    "            'developer_website': info.get('sellerUrl'),\n",
    "            \n",
    "            # FECHAS\n",
    "            'created_at': info.get('releaseDate'),\n",
    "            'updated_at': info.get('currentVersionReleaseDate'),\n",
    "            'year_creation': extraer_year(info.get('releaseDate')),\n",
    "            \n",
    "            # VERSIÓN Y TÉCNICO\n",
    "            'version': info.get('version'),\n",
    "            'size_bytes': info.get('fileSizeBytes'),\n",
    "            'size_mb': calcular_size_mb(info.get('fileSizeBytes')),\n",
    "            'minimum_ios_version': info.get('minimumOsVersion'),\n",
    "            \n",
    "            # IDIOMAS\n",
    "            'languages_available': info.get('languageCodesISO2A', []),\n",
    "            'language_count': len(info.get('languageCodesISO2A', [])),\n",
    "            \n",
    "            # CATEGORÍAS\n",
    "            'primary_genre': info.get('primaryGenreName'),\n",
    "            'genres': info.get('genres', []),\n",
    "            'category': info.get('primaryGenreName'),\n",
    "            \n",
    "            # RATINGS Y POPULARIDAD\n",
    "            'content_rating': info.get('trackContentRating'),\n",
    "            'average_rating': info.get('averageUserRating'),\n",
    "            'rating_count': info.get('userRatingCount'),\n",
    "            'current_version_rating': info.get('averageUserRatingForCurrentVersion'),\n",
    "            'current_version_rating_count': info.get('userRatingCountForCurrentVersion'),\n",
    "            \n",
    "            # PRECIO\n",
    "            'price': info.get('price'),\n",
    "            'formatted_price': info.get('formattedPrice'),\n",
    "            'currency': info.get('currency'),\n",
    "            \n",
    "            # MULTIMEDIA\n",
    "            'icon_60': info.get('artworkUrl60'),\n",
    "            'icon_100': info.get('artworkUrl100'),\n",
    "            'icon_512': info.get('artworkUrl512'),\n",
    "            'screenshots': info.get('screenshotUrls', []),\n",
    "            'screenshots_count': len(info.get('screenshotUrls', [])),\n",
    "            \n",
    "            # DESCRIPCIÓN\n",
    "            'description': info.get('description'),\n",
    "            'release_notes': info.get('releaseNotes'),\n",
    "            \n",
    "            # DISPOSITIVOS\n",
    "            'supported_devices': info.get('supportedDevices', []),\n",
    "            'is_game_center_enabled': info.get('isGameCenterEnabled', False),\n",
    "        }\n",
    "        \n",
    "        return metadata\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# Extraer desde URL\n",
    "def extraer_desde_url_ios(url):\n",
    "    \"\"\"\n",
    "    Extrae app_id de una URL de App Store y obtiene metadata\n",
    "    Ejemplo: https://apps.apple.com/us/app/tea-bag-index-spotteron/id1465181150?uo=4\n",
    "    \"\"\"\n",
    "    import re\n",
    "    \n",
    "    # Extraer app_id de la URL\n",
    "    match = re.search(r'/id(\\d+)', url)\n",
    "    if match:\n",
    "        app_id = match.group(1)\n",
    "        return extraer_metadata_ios_completa(app_id)\n",
    "    else:\n",
    "        print(\"No se pudo extraer el App ID de la URL\")\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    urls_ios = [\n",
    "        \"https://apps.apple.com/us/app/tea-bag-index-spotteron/id1465181150?uo=4\",\n",
    "        \"https://apps.apple.com/us/app/coastsnap-spotteron/id1529921850?uo=4\",\n",
    "        \"https://apps.apple.com/us/app/coastal-observer-spotteron/id1475663669?uo=4\",\n",
    "        \"https://apps.apple.com/us/app/roadkill-spotteron/id1007563102?uo=4\",\n",
    "        \"https://apps.apple.com/us/app/star-spotting-spotteron/id1450415974?uo=4\",\n",
    "        \"https://apps.apple.com/us/app/spiderspotter-spotteron/id1476447376?uo=4\",\n",
    "        \"https://apps.apple.com/us/app/crowdwater-spotteron/id1213513623?uo=4\",\n",
    "        \"https://apps.apple.com/us/app/our-outdoors-spotteron/id1496552078?uo=4\",\n",
    "        \"https://apps.apple.com/us/app/alpine-school-app-spotteron/id1461511006?uo=4\",\n",
    "        \"https://apps.apple.com/us/app/spot-a-bee-spotteron/id1509849471?uo=4\",\n",
    "        \"https://apps.apple.com/us/app/big-city-birds-spotteron/id1526169674?uo=4\",\n",
    "        \"https://apps.apple.com/us/app/minka/id6449294767?uo=4\",\n",
    "        \"https://apps.apple.com/us/app/sibra-spotteron/id1510855764?uo=4\",\n",
    "        \"https://apps.apple.com/us/app/makenya-spotteron/id1556701011?uo=4\",\n",
    "        \"https://apps.apple.com/us/app/climatewatch-spotteron/id1552422143?uo=4\",\n",
    "        \"https://apps.apple.com/us/app/whats-going-on-spotteron/id1278417727?uo=4\",\n",
    "        \"https://apps.apple.com/us/app/waldrapp-spotteron/id1292294112?uo=4\",\n",
    "        \"https://apps.apple.com/us/app/forschen-im-almtal-spotteron/id1292290494?uo=4\",\n",
    "        \"https://apps.apple.com/us/app/kramobil-spotteron/id1506993342?uo=4\",\n",
    "        \"https://apps.apple.com/us/app/landauf-landapp-bw-spotteron/id1456388123?uo=4\",\n",
    "    ]\n",
    "    for url in urls_ios:\n",
    "        metadata = extraer_desde_url_ios(url)\n",
    "        \n",
    "        if metadata:\n",
    "            with open(f'json_data/{metadata[\"app_id\"]}.json', 'w', encoding='utf-8') as f:\n",
    "                json.dump(metadata, f, indent=2, ensure_ascii=False)\n",
    "            \n",
    "            print(f\"{metadata['title']}\\nyear_creation: {metadata['year_creation']}\")\n",
    "            print(f\"{metadata['primary_genre']}\")\n",
    "            print(\"Saved data\\n\")\n",
    "        else:\n",
    "            print(\"\\nNo data saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e5e903",
   "metadata": {},
   "source": [
    "Saved info url in spotteron website, to scrap for more information about every project. Example: https://www.spotteron.com/climatewatch/info\n",
    "\n",
    "All urls have the same structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df7f414",
   "metadata": {},
   "source": [
    "# Process with platforms_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b46a1da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin, urlparse\n",
    "import time\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1924776",
   "metadata": {},
   "outputs": [],
   "source": [
    "platform_list = [\n",
    "    \"https://observation.org/\",\n",
    "    \"https://ornitologia.org/\",\n",
    "    \"https://mics.tools/\",\n",
    "    \"https://www.zooniverse.org/\",\n",
    "    \"https://www.pocket.science/products/ispex/\",\n",
    "    \"https://www.ispotnature.org/\",\n",
    "    \"https://plantnet.org/en/\",\n",
    "    \"https://smartcitizen.me/\",\n",
    "    \"https://artportalen.se/\",\n",
    "    \"https://minka-sdg.org/\",\n",
    "    \"https://sensor.community/en/\",\n",
    "    \"https://www.spotteron.com\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "07f1e2d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "platform_url",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "006f398a-a7da-4115-9ec9-35051ca4afd5",
       "rows": [
        [
         "0",
         "https://observation.org/"
        ],
        [
         "1",
         "https://ornitologia.org/"
        ],
        [
         "2",
         "https://mics.tools/"
        ],
        [
         "3",
         "https://www.zooniverse.org/"
        ],
        [
         "4",
         "https://www.pocket.science/products/ispex/"
        ],
        [
         "5",
         "https://www.ispotnature.org/"
        ],
        [
         "6",
         "https://plantnet.org/en/"
        ],
        [
         "7",
         "https://smartcitizen.me/"
        ],
        [
         "8",
         "https://artportalen.se/"
        ],
        [
         "9",
         "https://minka-sdg.org/"
        ],
        [
         "10",
         "https://sensor.community/en/"
        ],
        [
         "11",
         "https://www.spotteron.com"
        ],
        [
         "12",
         "https://smartcitizen.me/"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 13
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>platform_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://observation.org/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://ornitologia.org/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://mics.tools/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.zooniverse.org/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.pocket.science/products/ispex/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://www.ispotnature.org/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://plantnet.org/en/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://smartcitizen.me/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://artportalen.se/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://minka-sdg.org/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>https://sensor.community/en/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>https://www.spotteron.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>https://smartcitizen.me/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  platform_url\n",
       "0                     https://observation.org/\n",
       "1                     https://ornitologia.org/\n",
       "2                          https://mics.tools/\n",
       "3                  https://www.zooniverse.org/\n",
       "4   https://www.pocket.science/products/ispex/\n",
       "5                 https://www.ispotnature.org/\n",
       "6                     https://plantnet.org/en/\n",
       "7                     https://smartcitizen.me/\n",
       "8                      https://artportalen.se/\n",
       "9                       https://minka-sdg.org/\n",
       "10                https://sensor.community/en/\n",
       "11                   https://www.spotteron.com\n",
       "12                    https://smartcitizen.me/"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_platforms = pd.DataFrame(platform_list)\n",
    "df_platforms.columns = ['platform_url']\n",
    "df_platforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d196a255",
   "metadata": {},
   "source": [
    "## active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "680f0513",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_website(url):\n",
    "    try:\n",
    "        # Ensure URL has protocol\n",
    "        if not url.startswith(('http://', 'https://')):\n",
    "            url = 'https://' + url\n",
    "        session = requests.Session()\n",
    "        session.headers.update({\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\",\n",
    "            \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n",
    "            \"Accept-Language\": \"en-US,en;q=0.5\",\n",
    "            \"Referer\": \"https://www.google.com/\"\n",
    "        })\n",
    "        response = session.get(url, timeout=5)\n",
    "        return f\"Status code: {response.status_code}\"\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return f\"Fallo: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "968861de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_platforms['active'] = df_platforms['platform_url'].apply(check_website)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "802134af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "active",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "11f5591e-4403-4f82-bd98-88181b1bd951",
       "rows": [
        [
         "0",
         "Status code: 200"
        ],
        [
         "1",
         "Status code: 200"
        ],
        [
         "2",
         "Status code: 200"
        ],
        [
         "3",
         "Status code: 200"
        ],
        [
         "4",
         "Status code: 200"
        ],
        [
         "5",
         "Status code: 200"
        ],
        [
         "6",
         "Status code: 200"
        ],
        [
         "7",
         "Status code: 200"
        ],
        [
         "8",
         "Status code: 200"
        ],
        [
         "9",
         "Status code: 200"
        ],
        [
         "10",
         "Status code: 200"
        ],
        [
         "11",
         "Status code: 200"
        ],
        [
         "12",
         "Status code: 200"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 13
       }
      },
      "text/plain": [
       "0     Status code: 200\n",
       "1     Status code: 200\n",
       "2     Status code: 200\n",
       "3     Status code: 200\n",
       "4     Status code: 200\n",
       "5     Status code: 200\n",
       "6     Status code: 200\n",
       "7     Status code: 200\n",
       "8     Status code: 200\n",
       "9     Status code: 200\n",
       "10    Status code: 200\n",
       "11    Status code: 200\n",
       "12    Status code: 200\n",
       "Name: active, dtype: object"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_platforms['active']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ebdd4e",
   "metadata": {},
   "source": [
    "## platform_about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0a1ad11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_about_link(base_url):\n",
    "    \"\"\"\n",
    "    Extracts the 'About' link from a website.\n",
    "    Searches for common variations of 'About' links on the site.\n",
    "    \n",
    "    Args:\n",
    "        base_url (str): Base URL of the platform\n",
    "        \n",
    "    Returns:\n",
    "        str: URL of the About page if found, None if not\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Ensure URL has protocol\n",
    "        if not base_url.startswith(('http://', 'https://')):\n",
    "            base_url = 'https://' + base_url\n",
    "        \n",
    "        # Configure headers to avoid blocking\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "            'Accept-Language': 'en-US,en;q=0.5',\n",
    "            'Accept-Encoding': 'gzip, deflate',\n",
    "            'Connection': 'keep-alive',\n",
    "        }\n",
    "        \n",
    "        # Make HTTP request\n",
    "        response = requests.get(base_url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Parse HTML\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Possible 'About' link texts\n",
    "        about_texts = [\n",
    "            'about', 'about us', 'about this site', 'who we are', \n",
    "            'quienes somos', 'acerca de', 'sobre nosotros', 'over ons',\n",
    "            'chi siamo', 'wer sind wir', 'à propos', 'om oss'\n",
    "        ]\n",
    "        \n",
    "        # Search for links containing 'About' related texts\n",
    "        for link in soup.find_all('a', href=True):\n",
    "            link_text = link.get_text(strip=True).lower()\n",
    "            href = link.get('href')\n",
    "            \n",
    "            # Check if link text contains any variation of 'about'\n",
    "            if any(about_text in link_text for about_text in about_texts):\n",
    "                # Convert to absolute URL if relative\n",
    "                if href.startswith('/'):\n",
    "                    about_url = urljoin(base_url, href)\n",
    "                elif href.startswith('http'):\n",
    "                    about_url = href\n",
    "                else:\n",
    "                    about_url = urljoin(base_url, '/' + href)\n",
    "                \n",
    "                return about_url\n",
    "        \n",
    "        # If not found, search common 'about' page URLs\n",
    "        common_about_paths = ['/about', '/about-us', '/about.html', '/who-we-are', '/info']\n",
    "        for path in common_about_paths:\n",
    "            test_url = urljoin(base_url, path)\n",
    "            try:\n",
    "                test_response = requests.head(test_url, headers=headers, timeout=5)\n",
    "                if test_response.status_code == 200:\n",
    "                    return test_url\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "        return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error procesando {base_url}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f830b4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_platforms['platform_about'] = df_platforms['platform_url'].apply(extract_about_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "c5c3670e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13 entries, 0 to 12\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   platform_url    13 non-null     object\n",
      " 1   active          13 non-null     object\n",
      " 2   platform_about  6 non-null      object\n",
      "dtypes: object(3)\n",
      "memory usage: 444.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df_platforms.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "9d3a25db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "platform_url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "active",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "platform_about",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "b7f84dfb-3878-482a-9e31-85a55219d0bc",
       "rows": [
        [
         "0",
         "https://observation.org/",
         "Status code: 200",
         "https://observation.org/about"
        ],
        [
         "1",
         "https://ornitologia.org/",
         "Status code: 200",
         null
        ],
        [
         "2",
         "https://mics.tools/",
         "Status code: 200",
         "https://about.mics.tools"
        ],
        [
         "3",
         "https://www.zooniverse.org/",
         "Status code: 200",
         "https://www.zooniverse.org/about"
        ],
        [
         "4",
         "https://www.pocket.science/products/ispex/",
         "Status code: 200",
         "https://www.pocket.science/index.html#about"
        ],
        [
         "5",
         "https://www.ispotnature.org/",
         "Status code: 200",
         null
        ],
        [
         "6",
         "https://plantnet.org/en/",
         "Status code: 200",
         null
        ],
        [
         "7",
         "https://smartcitizen.me/",
         "Status code: 200",
         null
        ],
        [
         "8",
         "https://artportalen.se/",
         "Status code: 200",
         null
        ],
        [
         "9",
         "https://minka-sdg.org/",
         "Status code: 200",
         "https://minka-sdg.org/pages/about_us"
        ],
        [
         "10",
         "https://sensor.community/en/",
         "Status code: 200",
         null
        ],
        [
         "11",
         "https://www.spotteron.com",
         "Status code: 200",
         "https://www.spotteron.com/about"
        ],
        [
         "12",
         "https://smartcitizen.me/",
         "Status code: 200",
         null
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 13
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>platform_url</th>\n",
       "      <th>active</th>\n",
       "      <th>platform_about</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://observation.org/</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>https://observation.org/about</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://ornitologia.org/</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://mics.tools/</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>https://about.mics.tools</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.zooniverse.org/</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>https://www.zooniverse.org/about</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.pocket.science/products/ispex/</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>https://www.pocket.science/index.html#about</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://www.ispotnature.org/</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://plantnet.org/en/</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://smartcitizen.me/</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://artportalen.se/</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://minka-sdg.org/</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>https://minka-sdg.org/pages/about_us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>https://sensor.community/en/</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>https://www.spotteron.com</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>https://www.spotteron.com/about</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>https://smartcitizen.me/</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  platform_url            active  \\\n",
       "0                     https://observation.org/  Status code: 200   \n",
       "1                     https://ornitologia.org/  Status code: 200   \n",
       "2                          https://mics.tools/  Status code: 200   \n",
       "3                  https://www.zooniverse.org/  Status code: 200   \n",
       "4   https://www.pocket.science/products/ispex/  Status code: 200   \n",
       "5                 https://www.ispotnature.org/  Status code: 200   \n",
       "6                     https://plantnet.org/en/  Status code: 200   \n",
       "7                     https://smartcitizen.me/  Status code: 200   \n",
       "8                      https://artportalen.se/  Status code: 200   \n",
       "9                       https://minka-sdg.org/  Status code: 200   \n",
       "10                https://sensor.community/en/  Status code: 200   \n",
       "11                   https://www.spotteron.com  Status code: 200   \n",
       "12                    https://smartcitizen.me/  Status code: 200   \n",
       "\n",
       "                                 platform_about  \n",
       "0                 https://observation.org/about  \n",
       "1                                          None  \n",
       "2                      https://about.mics.tools  \n",
       "3              https://www.zooniverse.org/about  \n",
       "4   https://www.pocket.science/index.html#about  \n",
       "5                                          None  \n",
       "6                                          None  \n",
       "7                                          None  \n",
       "8                                          None  \n",
       "9          https://minka-sdg.org/pages/about_us  \n",
       "10                                         None  \n",
       "11              https://www.spotteron.com/about  \n",
       "12                                         None  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_platforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f9d11d",
   "metadata": {},
   "source": [
    "## year_creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68c28ab",
   "metadata": {},
   "source": [
    "Using register of domain, info in whois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "3345e33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whois\n",
    "\n",
    "def get_domain_creation_year(url):\n",
    "    # Ensure URL has protocol\n",
    "    if not url.startswith(('http://', 'https://')):\n",
    "        url = 'https://' + url\n",
    "    try:\n",
    "        domain = whois.whois(url)\n",
    "        creation_date = domain.creation_date\n",
    "        if isinstance(creation_date, list):  # Some WHOIS return multiple dates\n",
    "            creation_date = creation_date[0]\n",
    "        return creation_date.year\n",
    "    except Exception as e:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7e9fc5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-11 18:48:05,922 - whois.whois - ERROR - Error trying to connect to socket: closing socket - [Errno -2] Nombre o servicio desconocido\n",
      "2025-12-11 18:48:40,586 - whois.whois - ERROR - Error trying to connect to socket: closing socket - [Errno -2] Nombre o servicio desconocido\n"
     ]
    }
   ],
   "source": [
    "df_platforms['year_creation'] = df_platforms['platform_url'].apply(get_domain_creation_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "10dbcdf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "year_creation",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "b91ecc57-0ea9-4589-9f77-46ec09928ac6",
       "rows": [
        [
         "0",
         "2002.0"
        ],
        [
         "1",
         "2000.0"
        ],
        [
         "2",
         null
        ],
        [
         "3",
         "2008.0"
        ],
        [
         "4",
         "2021.0"
        ],
        [
         "5",
         "2012.0"
        ],
        [
         "6",
         "2014.0"
        ],
        [
         "7",
         "2012.0"
        ],
        [
         "8",
         "2005.0"
        ],
        [
         "9",
         "2021.0"
        ],
        [
         "10",
         null
        ],
        [
         "11",
         "2013.0"
        ],
        [
         "12",
         "2012.0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 13
       }
      },
      "text/plain": [
       "0     2002.0\n",
       "1     2000.0\n",
       "2        NaN\n",
       "3     2008.0\n",
       "4     2021.0\n",
       "5     2012.0\n",
       "6     2014.0\n",
       "7     2012.0\n",
       "8     2005.0\n",
       "9     2021.0\n",
       "10       NaN\n",
       "11    2013.0\n",
       "12    2012.0\n",
       "Name: year_creation, dtype: float64"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_platforms['year_creation']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d2aff5",
   "metadata": {},
   "source": [
    "## terms_use_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "9f0ac35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_terms_link(url):\n",
    "    \"\"\"\n",
    "    Extracts the link to a web page's terms of use/conditions.\n",
    "    Searches for common variations of terms links in multiple languages.\n",
    "\n",
    "    Args:\n",
    "        url (str): Platform URL\n",
    "\n",
    "    Returns:\n",
    "        str: URL of the terms page if found, None otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Ensure the URL has a protocol\n",
    "        if not url.startswith(('http://', 'https://')):\n",
    "            url = 'https://' + url\n",
    "        \n",
    "        # Configure headers to avoid blocking\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "            'Accept-Language': 'en-US,en;q=0.5',\n",
    "            'Accept-Encoding': 'gzip, deflate',\n",
    "            'Connection': 'keep-alive',\n",
    "        }\n",
    "        \n",
    "        # Make a request\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Parse HTML\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Possible term link texts (in multiple languages)\n",
    "        terms_texts = [\n",
    "            # English\n",
    "            'terms', 'terms of use', 'terms of service', 'terms and conditions', \n",
    "            'conditions of use', 'user terms', 'service terms', 'legal terms',\n",
    "            'terms & conditions', 'tos', 'terms of service agreement',\n",
    "            \n",
    "            # Spanish\n",
    "            'términos', 'términos de uso', 'términos y condiciones', \n",
    "            'condiciones de uso', 'términos del servicio', 'condiciones',\n",
    "            'términos legales', 'condiciones legales',\n",
    "            \n",
    "            # French\n",
    "            'conditions', 'conditions d\\'utilisation', 'termes', \n",
    "            'conditions générales', 'cgu', 'mentions légales',\n",
    "            \n",
    "            # German\n",
    "            'nutzungsbedingungen', 'geschäftsbedingungen', 'bedingungen',\n",
    "            'agb', 'nutzungsbestimmungen',\n",
    "            \n",
    "            # Dutch\n",
    "            'gebruiksvoorwaarden', 'voorwaarden', 'algemene voorwaarden',\n",
    "            \n",
    "            # Italian\n",
    "            'termini', 'condizioni', 'termini di utilizzo', 'condizioni d\\'uso',\n",
    "            \n",
    "            # Other common patterns\n",
    "            'legal', 'legal notice', 'disclaimer'\n",
    "        ]\n",
    "        \n",
    "        # Search for links that contain texts related to terms\n",
    "        for link in soup.find_all('a', href=True):\n",
    "            link_text = link.get_text(strip=True).lower()\n",
    "            href = link.get('href')\n",
    "            \n",
    "            # Check if the link text contains any term variations\n",
    "            if any(term_text in link_text for term_text in terms_texts):\n",
    "                # Convert to absolute URL if relative\n",
    "                if href.startswith('/'):\n",
    "                    terms_url = urljoin(url, href)\n",
    "                elif href.startswith('http'):\n",
    "                    terms_url = href\n",
    "                else:\n",
    "                    terms_url = urljoin(url, '/' + href)\n",
    "                \n",
    "                return terms_url\n",
    "        \n",
    "        # If not found in links, search in footer or common areas\n",
    "        footer_elements = soup.find_all(['footer', 'div'], class_=re.compile(r'footer|legal|terms', re.I))\n",
    "        for footer in footer_elements:\n",
    "            for link in footer.find_all('a', href=True):\n",
    "                link_text = link.get_text(strip=True).lower()\n",
    "                href = link.get('href')\n",
    "                \n",
    "                if any(term_text in link_text for term_text in terms_texts):\n",
    "                    if href.startswith('/'):\n",
    "                        terms_url = urljoin(url, href)\n",
    "                    elif href.startswith('http'):\n",
    "                        terms_url = href\n",
    "                    else:\n",
    "                        terms_url = urljoin(url, '/' + href)\n",
    "                    \n",
    "                    return terms_url\n",
    "        \n",
    "        # If not found, search for common URLs of term pages\n",
    "        common_terms_paths = [\n",
    "            '/terms', '/terms-of-use', '/terms-of-service', '/terms-and-conditions',\n",
    "            '/tos', '/legal', '/conditions', '/user-terms', '/service-terms',\n",
    "            '/terms.html', '/terms.php', '/legal.html', '/conditions.html',\n",
    "            '/privacy-policy', '/legal-notice', '/disclaimer'\n",
    "        ]\n",
    "        \n",
    "        for path in common_terms_paths:\n",
    "            test_url = urljoin(url, path)\n",
    "            try:\n",
    "                test_response = requests.head(test_url, headers=headers, timeout=5)\n",
    "                if test_response.status_code == 200:\n",
    "                    return test_url\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "        return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing terms in {url}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "69f9fe27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_platforms['terms_link'] = df_platforms['platform_url'].apply(extract_terms_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d1d88d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "platform_url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "active",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "platform_about",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "year_creation",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "terms_link",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "9239d81b-ad99-4963-8187-43b4a0720369",
       "rows": [
        [
         "0",
         "https://observation.org/",
         "Status code: 200",
         "https://observation.org/about",
         "2002.0",
         "https://observation.org/terms"
        ],
        [
         "1",
         "https://ornitologia.org/",
         "Status code: 200",
         null,
         "2000.0",
         "https://ornitologia.org/ca/quisom/associacio/avis-legal.html"
        ],
        [
         "2",
         "https://mics.tools/",
         "Status code: 200",
         "https://about.mics.tools",
         null,
         null
        ],
        [
         "3",
         "https://www.zooniverse.org/",
         "Status code: 200",
         "https://www.zooniverse.org/about",
         "2008.0",
         "https://www.zooniverse.org/privacy-policy"
        ],
        [
         "4",
         "https://www.pocket.science/products/ispex/",
         "Status code: 200",
         "https://www.pocket.science/index.html#about",
         "2021.0",
         null
        ],
        [
         "5",
         "https://www.ispotnature.org/",
         "Status code: 200",
         null,
         "2012.0",
         null
        ],
        [
         "6",
         "https://plantnet.org/en/",
         "Status code: 200",
         null,
         "2014.0",
         "https://identify.plantnet.org/en/terms_of_use"
        ],
        [
         "7",
         "https://smartcitizen.me/",
         "Status code: 200",
         null,
         "2012.0",
         null
        ],
        [
         "8",
         "https://artportalen.se/",
         "Status code: 200",
         null,
         "2005.0",
         "https://artportalen.se/FieldDiary"
        ],
        [
         "9",
         "https://minka-sdg.org/",
         "Status code: 200",
         "https://minka-sdg.org/pages/about_us",
         "2021.0",
         "https://minka-sdg.org/pages/terms_and_agreements"
        ],
        [
         "10",
         "https://sensor.community/en/",
         "Status code: 200",
         null,
         null,
         "https://sensor.community/en/privacy-terms/"
        ],
        [
         "11",
         "https://www.spotteron.com",
         "Status code: 200",
         "https://www.spotteron.com/about",
         "2013.0",
         "https://www.spotteron.com/#identifier_8031"
        ],
        [
         "12",
         "https://smartcitizen.me/",
         "Status code: 200",
         null,
         "2012.0",
         null
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 13
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>platform_url</th>\n",
       "      <th>active</th>\n",
       "      <th>platform_about</th>\n",
       "      <th>year_creation</th>\n",
       "      <th>terms_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://observation.org/</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>https://observation.org/about</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>https://observation.org/terms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://ornitologia.org/</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>None</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>https://ornitologia.org/ca/quisom/associacio/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://mics.tools/</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>https://about.mics.tools</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.zooniverse.org/</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>https://www.zooniverse.org/about</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>https://www.zooniverse.org/privacy-policy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.pocket.science/products/ispex/</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>https://www.pocket.science/index.html#about</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://www.ispotnature.org/</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>None</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://plantnet.org/en/</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>None</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>https://identify.plantnet.org/en/terms_of_use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://smartcitizen.me/</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>None</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://artportalen.se/</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>None</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>https://artportalen.se/FieldDiary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://minka-sdg.org/</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>https://minka-sdg.org/pages/about_us</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>https://minka-sdg.org/pages/terms_and_agreements</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>https://sensor.community/en/</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://sensor.community/en/privacy-terms/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>https://www.spotteron.com</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>https://www.spotteron.com/about</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>https://www.spotteron.com/#identifier_8031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>https://smartcitizen.me/</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>None</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  platform_url            active  \\\n",
       "0                     https://observation.org/  Status code: 200   \n",
       "1                     https://ornitologia.org/  Status code: 200   \n",
       "2                          https://mics.tools/  Status code: 200   \n",
       "3                  https://www.zooniverse.org/  Status code: 200   \n",
       "4   https://www.pocket.science/products/ispex/  Status code: 200   \n",
       "5                 https://www.ispotnature.org/  Status code: 200   \n",
       "6                     https://plantnet.org/en/  Status code: 200   \n",
       "7                     https://smartcitizen.me/  Status code: 200   \n",
       "8                      https://artportalen.se/  Status code: 200   \n",
       "9                       https://minka-sdg.org/  Status code: 200   \n",
       "10                https://sensor.community/en/  Status code: 200   \n",
       "11                   https://www.spotteron.com  Status code: 200   \n",
       "12                    https://smartcitizen.me/  Status code: 200   \n",
       "\n",
       "                                 platform_about  year_creation  \\\n",
       "0                 https://observation.org/about         2002.0   \n",
       "1                                          None         2000.0   \n",
       "2                      https://about.mics.tools            NaN   \n",
       "3              https://www.zooniverse.org/about         2008.0   \n",
       "4   https://www.pocket.science/index.html#about         2021.0   \n",
       "5                                          None         2012.0   \n",
       "6                                          None         2014.0   \n",
       "7                                          None         2012.0   \n",
       "8                                          None         2005.0   \n",
       "9          https://minka-sdg.org/pages/about_us         2021.0   \n",
       "10                                         None            NaN   \n",
       "11              https://www.spotteron.com/about         2013.0   \n",
       "12                                         None         2012.0   \n",
       "\n",
       "                                           terms_link  \n",
       "0                       https://observation.org/terms  \n",
       "1   https://ornitologia.org/ca/quisom/associacio/a...  \n",
       "2                                                None  \n",
       "3           https://www.zooniverse.org/privacy-policy  \n",
       "4                                                None  \n",
       "5                                                None  \n",
       "6       https://identify.plantnet.org/en/terms_of_use  \n",
       "7                                                None  \n",
       "8                   https://artportalen.se/FieldDiary  \n",
       "9    https://minka-sdg.org/pages/terms_and_agreements  \n",
       "10         https://sensor.community/en/privacy-terms/  \n",
       "11         https://www.spotteron.com/#identifier_8031  \n",
       "12                                               None  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_platforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23081f22",
   "metadata": {},
   "source": [
    "## privacy_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "16c5a6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_privacy_policy_link(url):\n",
    "    \"\"\"\n",
    "    Extracts the privacy policy link from a web page.\n",
    "    Finds common variations of privacy links in multiple languages.\n",
    "\n",
    "    Args:\n",
    "        url (str): Platform URL\n",
    "\n",
    "    Returns:\n",
    "        str: URL of the privacy policy page if found, None otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Ensure the URL has a protocol\n",
    "        if not url.startswith(('http://', 'https://')):\n",
    "            url = 'https://' + url\n",
    "        \n",
    "        # Configure headers to avoid blocking\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "            'Accept-Language': 'en-US,en;q=0.5',\n",
    "            'Accept-Encoding': 'gzip, deflate',\n",
    "            'Connection': 'keep-alive',\n",
    "        }\n",
    "        \n",
    "        # Making request\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Parsing HTML\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Possible privacy link texts (in multiple languages)\n",
    "        privacy_texts = [\n",
    "            # English\n",
    "            'privacy', 'privacy policy', 'privacy notice', 'privacy statement',\n",
    "            'data protection', 'data policy', 'privacy terms', 'privacy agreement',\n",
    "            'data privacy', 'privacy & cookies', 'cookie policy',\n",
    "            \n",
    "            # Spanish\n",
    "            'privacidad', 'política de privacidad', 'aviso de privacidad',\n",
    "            'política de datos', 'protección de datos', 'términos de privacidad',\n",
    "            'política de cookies', 'aviso legal', 'protección de la privacidad',\n",
    "            \n",
    "            # French\n",
    "            'confidentialité', 'politique de confidentialité', \n",
    "            'protection des données', 'vie privée', 'données personnelles',\n",
    "            'politique de cookies', 'rgpd', 'gdpr',\n",
    "            \n",
    "            # German\n",
    "            'datenschutz', 'datenschutzerklärung', 'datenschutzrichtlinie',\n",
    "            'datenschutzbestimmungen', 'privatsphäre', 'dsgvo',\n",
    "            \n",
    "            # Dutch\n",
    "            'privacy', 'privacybeleid', 'gegevensbescherming', 'avg',\n",
    "            'privacyverklaring', 'cookiebeleid',\n",
    "            \n",
    "            # Italian\n",
    "            'privacy', 'politica privacy', 'protezione dati', 'riservatezza',\n",
    "            'gdpr', 'informativa privacy', 'politica dei cookie',\n",
    "            \n",
    "            # Other patterns\n",
    "            'gdpr', 'rgpd', 'cookies', 'cookie notice', 'data handling'\n",
    "        ]\n",
    "        \n",
    "        # Search for links that contain privacy-related texts\n",
    "        for link in soup.find_all('a', href=True):\n",
    "            link_text = link.get_text(strip=True).lower()\n",
    "            href = link.get('href')\n",
    "            \n",
    "            # Check if the link text contains any privacy variations\n",
    "            if any(privacy_text in link_text for privacy_text in privacy_texts):\n",
    "                # Convert to absolute URL if relative\n",
    "                if href.startswith('/'):\n",
    "                    privacy_url = urljoin(url, href)\n",
    "                elif href.startswith('http'):\n",
    "                    privacy_url = href\n",
    "                else:\n",
    "                    privacy_url = urljoin(url, '/' + href)\n",
    "                \n",
    "                return privacy_url\n",
    "        \n",
    "        # If not found in main links, search in footer or common areas\n",
    "        footer_elements = soup.find_all(['footer', 'div'], class_=re.compile(r'footer|legal|privacy|cookie', re.I))\n",
    "        for footer in footer_elements:\n",
    "            for link in footer.find_all('a', href=True):\n",
    "                link_text = link.get_text(strip=True).lower()\n",
    "                href = link.get('href')\n",
    "                \n",
    "                if any(privacy_text in link_text for privacy_text in privacy_texts):\n",
    "                    if href.startswith('/'):\n",
    "                        privacy_url = urljoin(url, href)\n",
    "                    elif href.startswith('http'):\n",
    "                        privacy_url = href\n",
    "                    else:\n",
    "                        privacy_url = urljoin(url, '/' + href)\n",
    "                    \n",
    "                    return privacy_url\n",
    "        \n",
    "        # If not found, search for common privacy page URLs\n",
    "        common_privacy_paths = [\n",
    "            '/privacy', '/privacy-policy', '/privacy-notice', '/privacy-statement',\n",
    "            '/data-protection', '/data-policy', '/cookies', '/cookie-policy',\n",
    "            '/privacy.html', '/privacy.php', '/datenschutz', '/confidentialite',\n",
    "            '/privacidad', '/gdpr', '/data-privacy', '/cookie-notice'\n",
    "        ]\n",
    "        \n",
    "        for path in common_privacy_paths:\n",
    "            test_url = urljoin(url, path)\n",
    "            try:\n",
    "                test_response = requests.head(test_url, headers=headers, timeout=5)\n",
    "                if test_response.status_code == 200:\n",
    "                    return test_url\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "        return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error procesando privacidad en {url}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "b84df8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_platforms['privacy_link'] = df_platforms['platform_url'].apply(extract_privacy_policy_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "0ca67694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "platform_url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "active",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "platform_about",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "year_creation",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "terms_link",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "privacy_link",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "0f0be202-855f-4bb3-b4bd-41a1573eea5c",
       "rows": [
        [
         "0",
         "https://observation.org/",
         "Status code: 200",
         "https://observation.org/about",
         "2002.0",
         "https://observation.org/terms",
         "https://observation.org/privacy"
        ],
        [
         "1",
         "https://ornitologia.org/",
         "Status code: 200",
         null,
         "2000.0",
         "https://ornitologia.org/ca/quisom/associacio/avis-legal.html",
         null
        ],
        [
         "2",
         "https://mics.tools/",
         "Status code: 200",
         "https://about.mics.tools",
         null,
         null,
         null
        ],
        [
         "3",
         "https://www.zooniverse.org/",
         "Status code: 200",
         "https://www.zooniverse.org/about",
         "2008.0",
         "https://www.zooniverse.org/privacy-policy",
         "https://www.zooniverse.org/privacy"
        ],
        [
         "4",
         "https://www.pocket.science/products/ispex/",
         "Status code: 200",
         "https://www.pocket.science/index.html#about",
         "2021.0",
         null,
         null
        ],
        [
         "5",
         "https://www.ispotnature.org/",
         "Status code: 200",
         null,
         "2012.0",
         null,
         "https://www.ispotnature.org/cookies"
        ],
        [
         "6",
         "https://plantnet.org/en/",
         "Status code: 200",
         null,
         "2014.0",
         "https://identify.plantnet.org/en/terms_of_use",
         null
        ],
        [
         "7",
         "https://smartcitizen.me/",
         "Status code: 200",
         null,
         "2012.0",
         null,
         null
        ],
        [
         "8",
         "https://artportalen.se/",
         "Status code: 200",
         null,
         "2005.0",
         "https://artportalen.se/FieldDiary",
         null
        ],
        [
         "9",
         "https://minka-sdg.org/",
         "Status code: 200",
         "https://minka-sdg.org/pages/about_us",
         "2021.0",
         "https://minka-sdg.org/pages/terms_and_agreements",
         "https://minka-sdg.org/pages/privacy_policy"
        ],
        [
         "10",
         "https://sensor.community/en/",
         "Status code: 200",
         null,
         null,
         "https://sensor.community/en/privacy-terms/",
         "https://sensor.community/en/privacy-terms/"
        ],
        [
         "11",
         "https://www.spotteron.com",
         "Status code: 200",
         "https://www.spotteron.com/about",
         "2013.0",
         "https://www.spotteron.com/#identifier_8031",
         "https://www.spotteron.com/citizen-science-app-features/privacy-data-safety"
        ],
        [
         "12",
         "https://smartcitizen.me/",
         "Status code: 200",
         null,
         "2012.0",
         null,
         null
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 13
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>platform_url</th>\n",
       "      <th>active</th>\n",
       "      <th>platform_about</th>\n",
       "      <th>year_creation</th>\n",
       "      <th>terms_link</th>\n",
       "      <th>privacy_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://observation.org/</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>https://observation.org/about</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>https://observation.org/terms</td>\n",
       "      <td>https://observation.org/privacy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://ornitologia.org/</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>None</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>https://ornitologia.org/ca/quisom/associacio/a...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://mics.tools/</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>https://about.mics.tools</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.zooniverse.org/</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>https://www.zooniverse.org/about</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>https://www.zooniverse.org/privacy-policy</td>\n",
       "      <td>https://www.zooniverse.org/privacy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.pocket.science/products/ispex/</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>https://www.pocket.science/index.html#about</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://www.ispotnature.org/</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>None</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.ispotnature.org/cookies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://plantnet.org/en/</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>None</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>https://identify.plantnet.org/en/terms_of_use</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://smartcitizen.me/</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>None</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://artportalen.se/</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>None</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>https://artportalen.se/FieldDiary</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://minka-sdg.org/</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>https://minka-sdg.org/pages/about_us</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>https://minka-sdg.org/pages/terms_and_agreements</td>\n",
       "      <td>https://minka-sdg.org/pages/privacy_policy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>https://sensor.community/en/</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://sensor.community/en/privacy-terms/</td>\n",
       "      <td>https://sensor.community/en/privacy-terms/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>https://www.spotteron.com</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>https://www.spotteron.com/about</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>https://www.spotteron.com/#identifier_8031</td>\n",
       "      <td>https://www.spotteron.com/citizen-science-app-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>https://smartcitizen.me/</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>None</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  platform_url            active  \\\n",
       "0                     https://observation.org/  Status code: 200   \n",
       "1                     https://ornitologia.org/  Status code: 200   \n",
       "2                          https://mics.tools/  Status code: 200   \n",
       "3                  https://www.zooniverse.org/  Status code: 200   \n",
       "4   https://www.pocket.science/products/ispex/  Status code: 200   \n",
       "5                 https://www.ispotnature.org/  Status code: 200   \n",
       "6                     https://plantnet.org/en/  Status code: 200   \n",
       "7                     https://smartcitizen.me/  Status code: 200   \n",
       "8                      https://artportalen.se/  Status code: 200   \n",
       "9                       https://minka-sdg.org/  Status code: 200   \n",
       "10                https://sensor.community/en/  Status code: 200   \n",
       "11                   https://www.spotteron.com  Status code: 200   \n",
       "12                    https://smartcitizen.me/  Status code: 200   \n",
       "\n",
       "                                 platform_about  year_creation  \\\n",
       "0                 https://observation.org/about         2002.0   \n",
       "1                                          None         2000.0   \n",
       "2                      https://about.mics.tools            NaN   \n",
       "3              https://www.zooniverse.org/about         2008.0   \n",
       "4   https://www.pocket.science/index.html#about         2021.0   \n",
       "5                                          None         2012.0   \n",
       "6                                          None         2014.0   \n",
       "7                                          None         2012.0   \n",
       "8                                          None         2005.0   \n",
       "9          https://minka-sdg.org/pages/about_us         2021.0   \n",
       "10                                         None            NaN   \n",
       "11              https://www.spotteron.com/about         2013.0   \n",
       "12                                         None         2012.0   \n",
       "\n",
       "                                           terms_link  \\\n",
       "0                       https://observation.org/terms   \n",
       "1   https://ornitologia.org/ca/quisom/associacio/a...   \n",
       "2                                                None   \n",
       "3           https://www.zooniverse.org/privacy-policy   \n",
       "4                                                None   \n",
       "5                                                None   \n",
       "6       https://identify.plantnet.org/en/terms_of_use   \n",
       "7                                                None   \n",
       "8                   https://artportalen.se/FieldDiary   \n",
       "9    https://minka-sdg.org/pages/terms_and_agreements   \n",
       "10         https://sensor.community/en/privacy-terms/   \n",
       "11         https://www.spotteron.com/#identifier_8031   \n",
       "12                                               None   \n",
       "\n",
       "                                         privacy_link  \n",
       "0                     https://observation.org/privacy  \n",
       "1                                                None  \n",
       "2                                                None  \n",
       "3                  https://www.zooniverse.org/privacy  \n",
       "4                                                None  \n",
       "5                 https://www.ispotnature.org/cookies  \n",
       "6                                                None  \n",
       "7                                                None  \n",
       "8                                                None  \n",
       "9          https://minka-sdg.org/pages/privacy_policy  \n",
       "10         https://sensor.community/en/privacy-terms/  \n",
       "11  https://www.spotteron.com/citizen-science-app-...  \n",
       "12                                               None  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_platforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aaf2ca9",
   "metadata": {},
   "source": [
    "## code_repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "b8bb010f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_code_repository_link(url):\n",
    "    \"\"\"\n",
    "    Extracts the link to a web platform's code repository.\n",
    "    Searches for links to GitHub, GitLab, Bitbucket, and other code repositories.\n",
    "\n",
    "    Args:\n",
    "        url (str): Platform URL\n",
    "\n",
    "    Returns:\n",
    "        str: Code repository URL if found, None otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not url.startswith(('http://', 'https://')):\n",
    "            url = 'https://' + url\n",
    "        \n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "            'Accept-Language': 'en-US,en;q=0.5',\n",
    "            'Accept-Encoding': 'gzip, deflate',\n",
    "            'Connection': 'keep-alive',\n",
    "        }\n",
    "        \n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Known code repository domains\n",
    "        repo_domains = [\n",
    "            'github.com', 'gitlab.com', 'bitbucket.org', 'sourceforge.net',\n",
    "            'codeberg.org', 'git.sr.ht', 'gitea.com', 'gitee.com'\n",
    "        ]\n",
    "        \n",
    "        # HIGH PRIORITY: Find direct links to known repositories\n",
    "        for link in soup.find_all('a', href=True):\n",
    "            href = link.get('href')\n",
    "            \n",
    "            # Check if the link points to a known repository\n",
    "            for domain in repo_domains:\n",
    "                if domain in href:\n",
    "                    # Verify that it is not just the main domain and that it is a valid repo\n",
    "                    if href.count('/') >= 2 and not href.endswith(domain):\n",
    "                        # Check that it does not end in extensions that are not repos\n",
    "                        if not any(ext in href.lower() for ext in ['.png', '.jpg', '.gif', '.svg', '.css', '.js']):\n",
    "                            return href\n",
    "        \n",
    "        # Search for very specific texts in source code\n",
    "        specific_repo_texts = [\n",
    "            'source code', 'github', 'gitlab', 'view source', 'download source',\n",
    "            'fork on github', 'clone', 'git repository', 'código fuente'\n",
    "        ]\n",
    "        \n",
    "        # Search for links with VERY specific text from repositories\n",
    "        for link in soup.find_all('a', href=True):\n",
    "            link_text = link.get_text(strip=True).lower()\n",
    "            href = link.get('href')\n",
    "            \n",
    "            # Only search for very specific texts that point to known domains\n",
    "            if any(specific_text in link_text for specific_text in specific_repo_texts):\n",
    "                for domain in repo_domains:\n",
    "                    if domain in href:\n",
    "                        return href\n",
    "        \n",
    "        # Search developer/footer areas with strict criteria\n",
    "        developer_areas = soup.find_all(['footer', 'div'], \n",
    "                                      class_=re.compile(r'developer|code|source|footer', re.I))\n",
    "        \n",
    "        for area in developer_areas:\n",
    "            for link in area.find_all('a', href=True):\n",
    "                href = link.get('href')\n",
    "                link_text = link.get_text(strip=True).lower()\n",
    "                \n",
    "                # Only search known domains with very specific text\n",
    "                for domain in repo_domains:\n",
    "                    if domain in href and any(text in link_text for text in specific_repo_texts):\n",
    "                        return href\n",
    "        \n",
    "        # Search in meta tags (known domains only)\n",
    "        meta_tags = soup.find_all('meta')\n",
    "        for meta in meta_tags:\n",
    "            content = meta.get('content', '')\n",
    "            for domain in repo_domains:\n",
    "                if domain in content and content.count('/') >= 2:\n",
    "                    return content\n",
    "        \n",
    "        # 5. Search GitHub badges (very specific)\n",
    "        for img in soup.find_all('img'):\n",
    "            src = img.get('src', '')\n",
    "            if 'shields.io' in src and 'github' in src:\n",
    "                parent_link = img.find_parent('a')\n",
    "                if parent_link and parent_link.get('href'):\n",
    "                    href = parent_link.get('href')\n",
    "                    if 'github.com' in href:\n",
    "                        return href\n",
    "                \n",
    "        return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing repository in {url}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "1995e5e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "platform_url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "active",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "platform_about",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "year_creation",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "terms_link",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "privacy_link",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "code_repository",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "d1a402a7-5509-4d4b-83ef-e8df28dd93cf",
       "rows": [
        [
         "0",
         "https://observation.org/",
         "Status code: 200",
         "https://observation.org/about",
         "2002.0",
         "https://observation.org/terms",
         "https://observation.org/privacy",
         null
        ],
        [
         "1",
         "https://ornitologia.org/",
         "Status code: 200",
         null,
         "2000.0",
         "https://ornitologia.org/ca/quisom/associacio/avis-legal.html",
         null,
         null
        ],
        [
         "2",
         "https://mics.tools/",
         "Status code: 200",
         "https://about.mics.tools",
         null,
         null,
         null,
         null
        ],
        [
         "3",
         "https://www.zooniverse.org/",
         "Status code: 200",
         "https://www.zooniverse.org/about",
         "2008.0",
         "https://www.zooniverse.org/privacy-policy",
         "https://www.zooniverse.org/privacy",
         null
        ],
        [
         "4",
         "https://www.pocket.science/products/ispex/",
         "Status code: 200",
         "https://www.pocket.science/index.html#about",
         "2021.0",
         null,
         null,
         null
        ],
        [
         "5",
         "https://www.ispotnature.org/",
         "Status code: 200",
         null,
         "2012.0",
         null,
         "https://www.ispotnature.org/cookies",
         null
        ],
        [
         "6",
         "https://plantnet.org/en/",
         "Status code: 200",
         null,
         "2014.0",
         "https://identify.plantnet.org/en/terms_of_use",
         null,
         "https://github.com/plantnet"
        ],
        [
         "7",
         "https://smartcitizen.me/",
         "Status code: 200",
         null,
         "2012.0",
         null,
         null,
         null
        ],
        [
         "8",
         "https://artportalen.se/",
         "Status code: 200",
         null,
         "2005.0",
         "https://artportalen.se/FieldDiary",
         null,
         null
        ],
        [
         "9",
         "https://minka-sdg.org/",
         "Status code: 200",
         "https://minka-sdg.org/pages/about_us",
         "2021.0",
         "https://minka-sdg.org/pages/terms_and_agreements",
         "https://minka-sdg.org/pages/privacy_policy",
         null
        ],
        [
         "10",
         "https://sensor.community/en/",
         "Status code: 200",
         null,
         null,
         "https://sensor.community/en/privacy-terms/",
         "https://sensor.community/en/privacy-terms/",
         "https://github.com/opendata-stuttgart/meta/wiki/Translations"
        ],
        [
         "11",
         "https://www.spotteron.com",
         "Status code: 200",
         "https://www.spotteron.com/about",
         "2013.0",
         "https://www.spotteron.com/#identifier_8031",
         "https://www.spotteron.com/citizen-science-app-features/privacy-data-safety",
         null
        ],
        [
         "12",
         "https://smartcitizen.me/",
         "Status code: 200",
         null,
         "2012.0",
         null,
         null,
         null
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 13
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>platform_url</th>\n",
       "      <th>active</th>\n",
       "      <th>platform_about</th>\n",
       "      <th>year_creation</th>\n",
       "      <th>terms_link</th>\n",
       "      <th>privacy_link</th>\n",
       "      <th>code_repository</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://observation.org/</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>https://observation.org/about</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>https://observation.org/terms</td>\n",
       "      <td>https://observation.org/privacy</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://ornitologia.org/</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>None</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>https://ornitologia.org/ca/quisom/associacio/a...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://mics.tools/</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>https://about.mics.tools</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.zooniverse.org/</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>https://www.zooniverse.org/about</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>https://www.zooniverse.org/privacy-policy</td>\n",
       "      <td>https://www.zooniverse.org/privacy</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.pocket.science/products/ispex/</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>https://www.pocket.science/index.html#about</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://www.ispotnature.org/</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>None</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.ispotnature.org/cookies</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://plantnet.org/en/</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>None</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>https://identify.plantnet.org/en/terms_of_use</td>\n",
       "      <td>None</td>\n",
       "      <td>https://github.com/plantnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://smartcitizen.me/</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>None</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://artportalen.se/</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>None</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>https://artportalen.se/FieldDiary</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://minka-sdg.org/</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>https://minka-sdg.org/pages/about_us</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>https://minka-sdg.org/pages/terms_and_agreements</td>\n",
       "      <td>https://minka-sdg.org/pages/privacy_policy</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>https://sensor.community/en/</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://sensor.community/en/privacy-terms/</td>\n",
       "      <td>https://sensor.community/en/privacy-terms/</td>\n",
       "      <td>https://github.com/opendata-stuttgart/meta/wik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>https://www.spotteron.com</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>https://www.spotteron.com/about</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>https://www.spotteron.com/#identifier_8031</td>\n",
       "      <td>https://www.spotteron.com/citizen-science-app-...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>https://smartcitizen.me/</td>\n",
       "      <td>Status code: 200</td>\n",
       "      <td>None</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  platform_url            active  \\\n",
       "0                     https://observation.org/  Status code: 200   \n",
       "1                     https://ornitologia.org/  Status code: 200   \n",
       "2                          https://mics.tools/  Status code: 200   \n",
       "3                  https://www.zooniverse.org/  Status code: 200   \n",
       "4   https://www.pocket.science/products/ispex/  Status code: 200   \n",
       "5                 https://www.ispotnature.org/  Status code: 200   \n",
       "6                     https://plantnet.org/en/  Status code: 200   \n",
       "7                     https://smartcitizen.me/  Status code: 200   \n",
       "8                      https://artportalen.se/  Status code: 200   \n",
       "9                       https://minka-sdg.org/  Status code: 200   \n",
       "10                https://sensor.community/en/  Status code: 200   \n",
       "11                   https://www.spotteron.com  Status code: 200   \n",
       "12                    https://smartcitizen.me/  Status code: 200   \n",
       "\n",
       "                                 platform_about  year_creation  \\\n",
       "0                 https://observation.org/about         2002.0   \n",
       "1                                          None         2000.0   \n",
       "2                      https://about.mics.tools            NaN   \n",
       "3              https://www.zooniverse.org/about         2008.0   \n",
       "4   https://www.pocket.science/index.html#about         2021.0   \n",
       "5                                          None         2012.0   \n",
       "6                                          None         2014.0   \n",
       "7                                          None         2012.0   \n",
       "8                                          None         2005.0   \n",
       "9          https://minka-sdg.org/pages/about_us         2021.0   \n",
       "10                                         None            NaN   \n",
       "11              https://www.spotteron.com/about         2013.0   \n",
       "12                                         None         2012.0   \n",
       "\n",
       "                                           terms_link  \\\n",
       "0                       https://observation.org/terms   \n",
       "1   https://ornitologia.org/ca/quisom/associacio/a...   \n",
       "2                                                None   \n",
       "3           https://www.zooniverse.org/privacy-policy   \n",
       "4                                                None   \n",
       "5                                                None   \n",
       "6       https://identify.plantnet.org/en/terms_of_use   \n",
       "7                                                None   \n",
       "8                   https://artportalen.se/FieldDiary   \n",
       "9    https://minka-sdg.org/pages/terms_and_agreements   \n",
       "10         https://sensor.community/en/privacy-terms/   \n",
       "11         https://www.spotteron.com/#identifier_8031   \n",
       "12                                               None   \n",
       "\n",
       "                                         privacy_link  \\\n",
       "0                     https://observation.org/privacy   \n",
       "1                                                None   \n",
       "2                                                None   \n",
       "3                  https://www.zooniverse.org/privacy   \n",
       "4                                                None   \n",
       "5                 https://www.ispotnature.org/cookies   \n",
       "6                                                None   \n",
       "7                                                None   \n",
       "8                                                None   \n",
       "9          https://minka-sdg.org/pages/privacy_policy   \n",
       "10         https://sensor.community/en/privacy-terms/   \n",
       "11  https://www.spotteron.com/citizen-science-app-...   \n",
       "12                                               None   \n",
       "\n",
       "                                      code_repository  \n",
       "0                                                None  \n",
       "1                                                None  \n",
       "2                                                None  \n",
       "3                                                None  \n",
       "4                                                None  \n",
       "5                                                None  \n",
       "6                         https://github.com/plantnet  \n",
       "7                                                None  \n",
       "8                                                None  \n",
       "9                                                None  \n",
       "10  https://github.com/opendata-stuttgart/meta/wik...  \n",
       "11                                               None  \n",
       "12                                               None  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_platforms['code_repository'] = df_platforms['platform_url'].apply(extract_code_repository_link)\n",
    "\n",
    "df_platforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "ff4dbee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "df_platforms.to_csv(\"../data/df_platforms_20251210.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432bf762",
   "metadata": {},
   "source": [
    "## language_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "7a801093",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_website_tech(url, timeout=10):\n",
    "    \"\"\"\n",
    "    Analyzes a URL to detect web technologies used    \n",
    "    \"\"\"\n",
    "    result = {\n",
    "        'url': url,\n",
    "        'technologies': [],\n",
    "        'language': None,\n",
    "        'framework': None,\n",
    "        'server': None,\n",
    "        'headers': {},\n",
    "        'status_code': None,\n",
    "        'error': None\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        if not url.startswith(('http://', 'https://')):\n",
    "            url = 'https://' + url\n",
    "            \n",
    "        # Make HTTP request\n",
    "        response = requests.get(url, timeout=timeout, allow_redirects=True)\n",
    "        result['status_code'] = response.status_code\n",
    "        \n",
    "        # Analyze headers\n",
    "        headers = response.headers\n",
    "        result['headers'] = dict(headers)\n",
    "        \n",
    "        # Get HTML content\n",
    "        html_content = response.text.lower()\n",
    "        \n",
    "        # Detect technologies by headers\n",
    "        tech_info = detect_tech_from_headers(headers)\n",
    "        result.update(tech_info)\n",
    "        \n",
    "        # Detect technologies by HTML content\n",
    "        html_tech = detect_tech_from_html(html_content)\n",
    "        result['technologies'].extend(html_tech)\n",
    "        \n",
    "        # Detect by URL patterns\n",
    "        url_tech = detect_tech_from_url(url)\n",
    "        result['technologies'].extend(url_tech)\n",
    "        \n",
    "        # Determine primary language\n",
    "        result['language'] = determine_primary_language(result)\n",
    "        \n",
    "        # Drop duplicates\n",
    "        result['technologies'] = list(set(result['technologies']))\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        result['error'] = str(e)\n",
    "    except Exception as e:\n",
    "        result['error'] = f\"Unexpected error: {str(e)}\"\n",
    "    \n",
    "    return result\n",
    "\n",
    "def detect_tech_from_headers(headers):\n",
    "    \"\"\"Detects technologies based on HTTP headers\"\"\"\n",
    "    tech_info = {\n",
    "        'technologies': [],\n",
    "        'language': None,\n",
    "        'framework': None,\n",
    "        'server': None\n",
    "    }\n",
    "    \n",
    "    # Convert headers to lowercase for search\n",
    "    headers_lower = {k.lower(): v for k, v in headers.items()}\n",
    "    \n",
    "    # Detect web server\n",
    "    if 'server' in headers_lower:\n",
    "        server = headers_lower['server']\n",
    "        tech_info['server'] = server\n",
    "        \n",
    "        if 'apache' in server.lower():\n",
    "            tech_info['technologies'].append('Apache')\n",
    "        if 'nginx' in server.lower():\n",
    "            tech_info['technologies'].append('Nginx')\n",
    "        if 'iis' in server.lower():\n",
    "            tech_info['technologies'].append('IIS')\n",
    "    \n",
    "    # Detect language by specific headers\n",
    "    if 'x-powered-by' in headers_lower:\n",
    "        powered_by = headers_lower['x-powered-by'].lower()\n",
    "        \n",
    "        if 'php' in powered_by:\n",
    "            tech_info['language'] = 'PHP'\n",
    "            tech_info['technologies'].append('PHP')\n",
    "        elif 'asp.net' in powered_by:\n",
    "            tech_info['language'] = 'ASP.NET'\n",
    "            tech_info['technologies'].append('ASP.NET')\n",
    "        elif 'express' in powered_by:\n",
    "            tech_info['language'] = 'Node.js'\n",
    "            tech_info['technologies'].append('Node.js')\n",
    "            tech_info['technologies'].append('Express')\n",
    "    \n",
    "    # Detect Ruby on Rails\n",
    "    if 'x-runtime' in headers_lower:\n",
    "        tech_info['language'] = 'Ruby'\n",
    "        tech_info['framework'] = 'Ruby on Rails'\n",
    "        tech_info['technologies'].append('Ruby on Rails')\n",
    "    \n",
    "    # Detect by cookies\n",
    "    if 'set-cookie' in headers_lower:\n",
    "        cookies = headers_lower['set-cookie'].lower()\n",
    "        \n",
    "        if 'phpsessid' in cookies:\n",
    "            tech_info['language'] = 'PHP'\n",
    "            tech_info['technologies'].append('PHP')\n",
    "        elif 'jsessionid' in cookies:\n",
    "            tech_info['language'] = 'Java'\n",
    "            tech_info['technologies'].append('Java')\n",
    "        elif '_session_id' in cookies and 'rails' in cookies:\n",
    "            tech_info['language'] = 'Ruby'\n",
    "            tech_info['technologies'].append('Ruby on Rails')\n",
    "    \n",
    "    # Detect CloudFlare\n",
    "    if 'cf-ray' in headers_lower:\n",
    "        tech_info['technologies'].append('CloudFlare')\n",
    "    \n",
    "    return tech_info\n",
    "\n",
    "def detect_tech_from_html(html_content):\n",
    "    \"\"\"Detects technologies by analyzing HTML content\"\"\"\n",
    "    technologies = []\n",
    "    \n",
    "    # WordPress\n",
    "    if any(indicator in html_content for indicator in [\n",
    "        'wp-content', 'wp-includes', 'wordpress', '/wp-json/'\n",
    "    ]):\n",
    "        technologies.append('WordPress')\n",
    "    \n",
    "    # Drupal\n",
    "    if any(indicator in html_content for indicator in [\n",
    "        'drupal', 'sites/default/files', 'misc/drupal.js'\n",
    "    ]):\n",
    "        technologies.append('Drupal')\n",
    "    \n",
    "    # Joomla\n",
    "    if any(indicator in html_content for indicator in [\n",
    "        'joomla', 'option=com_', 'joomla.org'\n",
    "    ]):\n",
    "        technologies.append('Joomla')\n",
    "    \n",
    "    # React\n",
    "    if any(indicator in html_content for indicator in [\n",
    "        'react', 'data-reactroot', '__react', 'react-dom'\n",
    "    ]):\n",
    "        technologies.append('React')\n",
    "    \n",
    "    # Vue.js\n",
    "    if any(indicator in html_content for indicator in [\n",
    "        'vue.js', 'vue.min.js', 'v-if=', 'v-for='\n",
    "    ]):\n",
    "        technologies.append('Vue.js')\n",
    "    \n",
    "    # Angular\n",
    "    if any(indicator in html_content for indicator in [\n",
    "        'angular', 'ng-app', 'ng-controller', 'angular.min.js'\n",
    "    ]):\n",
    "        technologies.append('Angular')\n",
    "    \n",
    "    # jQuery\n",
    "    if any(indicator in html_content for indicator in [\n",
    "        'jquery', 'jquery.min.js', '$.fn.jquery'\n",
    "    ]):\n",
    "        technologies.append('jQuery')\n",
    "    \n",
    "    # Bootstrap\n",
    "    if any(indicator in html_content for indicator in [\n",
    "        'bootstrap', 'bootstrap.min.css', 'bootstrap.css'\n",
    "    ]):\n",
    "        technologies.append('Bootstrap')\n",
    "    \n",
    "    # Django (Python)\n",
    "    if any(indicator in html_content for indicator in [\n",
    "        'csrfmiddlewaretoken', 'django', '__admin_media_prefix__'\n",
    "    ]):\n",
    "        technologies.append('Django')\n",
    "    \n",
    "    # Laravel (PHP)\n",
    "    if any(indicator in html_content for indicator in [\n",
    "        'laravel_session', 'laravel', 'csrf-token'\n",
    "    ]):\n",
    "        technologies.append('Laravel')\n",
    "    \n",
    "    # Ruby on Rails\n",
    "    if any(indicator in html_content for indicator in [\n",
    "        'csrf-param', 'csrf-token', 'rails', 'data-method='\n",
    "    ]):\n",
    "        technologies.append('Ruby on Rails')\n",
    "    \n",
    "    # Google Analytics\n",
    "    if any(indicator in html_content for indicator in [\n",
    "        'google-analytics', 'gtag(', 'ga('\n",
    "    ]):\n",
    "        technologies.append('Google Analytics')\n",
    "    \n",
    "    return technologies\n",
    "\n",
    "def detect_tech_from_url(url):\n",
    "    \"\"\"Detects technologies based on URL patterns\"\"\"\n",
    "    technologies = []\n",
    "    \n",
    "    # Analyze file extensions\n",
    "    if '.php' in url:\n",
    "        technologies.append('PHP')\n",
    "    elif '.asp' in url or '.aspx' in url:\n",
    "        technologies.append('ASP.NET')\n",
    "    elif '.jsp' in url:\n",
    "        technologies.append('Java')\n",
    "    elif '.py' in url:\n",
    "        technologies.append('Python')\n",
    "    elif '.rb' in url:\n",
    "        technologies.append('Ruby')\n",
    "    elif '.cfm' in url:\n",
    "        technologies.append('ColdFusion')\n",
    "    \n",
    "    # WordPress specific patterns\n",
    "    if any(pattern in url for pattern in ['/wp-content/', '/wp-admin/', '/wp-includes/']):\n",
    "        technologies.append('WordPress')\n",
    "    \n",
    "    # Drupal patterns\n",
    "    if any(pattern in url for pattern in ['/node/', '/admin/config/']):\n",
    "        technologies.append('Drupal')\n",
    "    \n",
    "    return technologies\n",
    "\n",
    "def determine_primary_language(result):\n",
    "    \"\"\"Determine the primary language based on all the information\"\"\"\n",
    "    technologies = result['technologies']\n",
    "    \n",
    "    # Priority for specific frameworks\n",
    "    if 'Ruby on Rails' in technologies:\n",
    "        return 'Ruby'\n",
    "    elif 'Django' in technologies:\n",
    "        return 'Python'\n",
    "    elif 'Laravel' in technologies:\n",
    "        return 'PHP'\n",
    "    elif 'ASP.NET' in technologies:\n",
    "        return 'ASP.NET'\n",
    "    elif 'PHP' in technologies or 'WordPress' in technologies:\n",
    "        return 'PHP'\n",
    "    elif 'Java' in technologies:\n",
    "        return 'Java'\n",
    "    elif 'Node.js' in technologies:\n",
    "        return 'JavaScript (Node.js)'\n",
    "    elif any(js_tech in technologies for js_tech in ['React', 'Vue.js', 'Angular']):\n",
    "        return 'JavaScript'\n",
    "    elif result['language'] is not None:\n",
    "        return result['language']\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "7a006e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funtion to return just language\n",
    "def get_language(url):\n",
    "    try:\n",
    "        result = analyze_website_tech(url)\n",
    "        return result['language']\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "df_platforms['programming_language'] = df_platforms['platform_url'].apply(get_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "bb6441b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "programming_language",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "b830f425-142c-4f45-bdbe-a91c6b9e76cc",
       "rows": [
        [
         "0",
         "Python"
        ],
        [
         "1",
         null
        ],
        [
         "2",
         "Ruby"
        ],
        [
         "3",
         "PHP"
        ],
        [
         "4",
         null
        ],
        [
         "5",
         "PHP"
        ],
        [
         "6",
         "PHP"
        ],
        [
         "7",
         "JavaScript"
        ],
        [
         "8",
         "ASP.NET"
        ],
        [
         "9",
         "Ruby"
        ],
        [
         "10",
         null
        ],
        [
         "11",
         "PHP"
        ],
        [
         "12",
         "JavaScript"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 13
       }
      },
      "text/plain": [
       "0         Python\n",
       "1           None\n",
       "2           Ruby\n",
       "3            PHP\n",
       "4           None\n",
       "5            PHP\n",
       "6            PHP\n",
       "7     JavaScript\n",
       "8        ASP.NET\n",
       "9           Ruby\n",
       "10          None\n",
       "11           PHP\n",
       "12    JavaScript\n",
       "Name: programming_language, dtype: object"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_platforms.programming_language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173e417b",
   "metadata": {},
   "source": [
    "**NOTE:**\n",
    "* **PHP**: frameworks like Laravel, Symfony, CodeIgniter... and CMS like WordPress, Drupal, Joomla...\n",
    "* **JavaScript**: frontends like React, Vue.js, Angular, jQuery... and backends like Node.js or Express.js."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "dd152134",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_platforms.to_csv(\"../data/df_platforms_20251210.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddb2652",
   "metadata": {},
   "source": [
    "## governance_explicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ulj092u1dj",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función mejorada con debugging para encontrar governance policies\n",
    "def extract_data_governance_policy_link(url, verbose=True):\n",
    "    \"\"\"\n",
    "    Versión mejorada con debugging para extraer enlaces de governance de datos.\n",
    "    \n",
    "    Args:\n",
    "        url (str): Platform URL\n",
    "        verbose (bool): Si True, imprime información de debugging\n",
    "        \n",
    "    Returns:\n",
    "        str: URL de la página de governance si se encuentra, None en caso contrario\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print(f\"\\n--- PROCESANDO URL: {url} ---\")\n",
    "    \n",
    "    try:\n",
    "        # Ensure URL has protocol\n",
    "        if not url.startswith(('http://', 'https://')):\n",
    "            url = 'https://' + url\n",
    "        \n",
    "        # Configure headers to avoid blocking\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "            'Accept-Language': 'en-US,en;q=0.5',\n",
    "            'Accept-Encoding': 'gzip, deflate',\n",
    "            'Connection': 'keep-alive',\n",
    "        }\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"✓ Realizando petición HTTP a: {url}\")\n",
    "        \n",
    "        # Make HTTP request with longer timeout\n",
    "        response = requests.get(url, headers=headers, timeout=15)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"✓ Respuesta HTTP: {response.status_code}\")\n",
    "        \n",
    "        # Parse HTML\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"✓ HTML parseado exitosamente\")\n",
    "        \n",
    "        # Terms related to data governance (simplified and more focused)\n",
    "        governance_terms = [\n",
    "            # Core governance terms (more specific)\n",
    "            'data governance', 'data policy', 'data management', \n",
    "            'research policy', 'scientific policy', 'data stewardship',\n",
    "            'data standards', 'data guidelines', 'research guidelines',\n",
    "            'data ethics', 'research ethics', 'fair data', 'open data',\n",
    "            \n",
    "            # Spanish\n",
    "            'gobernanza de datos', 'política de datos', 'gestión de datos',\n",
    "            'política de investigación', 'ética de datos',\n",
    "            \n",
    "            # Common policy terms\n",
    "            'policy', 'policies', 'governance', 'guidelines', 'standards'\n",
    "        ]\n",
    "        \n",
    "        found_links = []\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"🔍 Buscando enlaces con términos de governance...\")\n",
    "        \n",
    "        # Search for direct links with governance-related text\n",
    "        all_links = soup.find_all('a', href=True)\n",
    "        if verbose:\n",
    "            print(f\"   - Encontrados {len(all_links)} enlaces en total\")\n",
    "        \n",
    "        links_with_governance_text = 0\n",
    "        for link in all_links:\n",
    "            link_text = link.get_text(strip=True).lower()\n",
    "            href = link.get('href')\n",
    "            \n",
    "            # Check if text contains governance terms (more flexible matching)\n",
    "            for governance_term in governance_terms:\n",
    "                if governance_term.lower() in link_text:\n",
    "                    links_with_governance_text += 1\n",
    "                    # Convert to absolute URL if relative\n",
    "                    if href.startswith('/'):\n",
    "                        governance_url = urljoin(url, href)\n",
    "                    elif href.startswith('http'):\n",
    "                        governance_url = href\n",
    "                    else:\n",
    "                        governance_url = urljoin(url, '/' + href)\n",
    "                    \n",
    "                    found_links.append((governance_url, governance_term, link_text))\n",
    "                    if verbose:\n",
    "                        print(f\"   ✓ Encontrado: '{link_text}' -> {governance_url}\")\n",
    "                    break\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"   - Enlaces con términos de governance: {links_with_governance_text}\")\n",
    "        \n",
    "        # Search in specific sections (footer, navigation, menus)\n",
    "        if verbose:\n",
    "            print(f\"Buscando en secciones específicas...\")\n",
    "        \n",
    "        specific_areas = soup.find_all(['footer', 'nav', 'div'], \n",
    "                                     class_=re.compile(r'footer|nav|menu|policy|legal|research|science|data', re.I))\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"   - Encontradas {len(specific_areas)} secciones específicas\")\n",
    "        \n",
    "        area_links_found = 0\n",
    "        for area in specific_areas:\n",
    "            area_links = area.find_all('a', href=True)\n",
    "            for link in area_links:\n",
    "                link_text = link.get_text(strip=True).lower()\n",
    "                href = link.get('href')\n",
    "                \n",
    "                for governance_term in governance_terms:\n",
    "                    if governance_term.lower() in link_text:\n",
    "                        area_links_found += 1\n",
    "                        if href.startswith('/'):\n",
    "                            governance_url = urljoin(url, href)\n",
    "                        elif href.startswith('http'):\n",
    "                            governance_url = href\n",
    "                        else:\n",
    "                            governance_url = urljoin(url, '/' + href)\n",
    "                        \n",
    "                        found_links.append((governance_url, governance_term, link_text))\n",
    "                        if verbose:\n",
    "                            print(f\"   ✓ Encontrado en sección: '{link_text}' -> {governance_url}\")\n",
    "                        break\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"   - Enlaces en secciones específicas: {area_links_found}\")\n",
    "        \n",
    "        # Search common governance policy URLs\n",
    "        if verbose:\n",
    "            print(f\"🔍 Probando URLs comunes de governance...\")\n",
    "        \n",
    "        common_governance_paths = [\n",
    "            '/data-governance', '/data-policy', '/data-management', '/research-policy',\n",
    "            '/scientific-policy', '/data-standards', '/data-guidelines', '/research-guidelines',\n",
    "            '/policy', '/policies', '/governance', '/guidelines', '/standards',\n",
    "            '/fair-data', '/open-data', '/data-ethics', '/research-ethics',\n",
    "        ]\n",
    "        \n",
    "        common_paths_found = 0\n",
    "        for path in common_governance_paths:\n",
    "            test_url = urljoin(url, path)\n",
    "            try:\n",
    "                test_response = requests.head(test_url, headers=headers, timeout=10)\n",
    "                if test_response.status_code == 200:\n",
    "                    common_paths_found += 1\n",
    "                    found_links.append((test_url, 'common_path', path))\n",
    "                    if verbose:\n",
    "                        print(f\"   ✓ URL común encontrada: {test_url}\")\n",
    "            except Exception as e:\n",
    "                if verbose and 'governance' in path:\n",
    "                    print(f\"   ✗ Error probando {test_url}: {type(e).__name__}\")\n",
    "                continue\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"   - URLs comunes encontradas: {common_paths_found}\")\n",
    "        \n",
    "        # Filter and prioritize results\n",
    "        if found_links:\n",
    "            if verbose:\n",
    "                print(f\"TOTAL ENLACES ENCONTRADOS: {len(found_links)}\")\n",
    "                \n",
    "            # Remove duplicates\n",
    "            unique_links = {}\n",
    "            for link_url, term, text in found_links:\n",
    "                if link_url not in unique_links:\n",
    "                    unique_links[link_url] = (term, text)\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"   - Enlaces únicos: {len(unique_links)}\")\n",
    "                for url_found, (term, text) in unique_links.items():\n",
    "                    print(f\"     • {url_found} (término: {term})\")\n",
    "            \n",
    "            # Prioritize by term relevance\n",
    "            priority_terms = ['data governance', 'governance', 'data policy', 'research policy', 'policy']\n",
    "            \n",
    "            # First search for high priority terms\n",
    "            for link_url, (term, text) in unique_links.items():\n",
    "                if any(priority_term in term.lower() for priority_term in priority_terms):\n",
    "                    if verbose:\n",
    "                        print(f\"SELECCIONADO (alta prioridad): {link_url}\")\n",
    "                    return link_url\n",
    "            \n",
    "            # If no high priority terms, return first found\n",
    "            first_url = list(unique_links.keys())[0]\n",
    "            if verbose:\n",
    "                print(f\"SELECCIONADO (primer encontrado): {first_url}\")\n",
    "            return first_url\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"NO SE ENCONTRARON ENLACES DE GOVERNANCE\")\n",
    "        return None\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        if verbose:\n",
    "            print(f\"ERROR DE RED: {type(e).__name__}: {str(e)}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        if verbose:\n",
    "            print(f\"ERROR INESPERADO: {type(e).__name__}: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "y3zasmd3cal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ https://observation.org/ -> https://observation.org/data-governance\n",
      "❌ https://ornitologia.org/ -> Not found\n",
      "❌ https://mics.tools/ -> Not found\n",
      "✅ https://www.zooniverse.org/ -> https://www.zooniverse.org/privacy\n",
      "❌ https://www.pocket.science/products/ispex/ -> Not found\n",
      "❌ https://www.ispotnature.org/ -> Not found\n",
      "✅ https://plantnet.org/en/ -> https://plantnet.org/open-data/\n",
      "❌ https://smartcitizen.me/ -> Not found\n",
      "❌ https://artportalen.se/ -> Not found\n",
      "✅ https://minka-sdg.org/ -> https://minka-sdg.org/pages/governance\n",
      "❌ https://sensor.community/en/ -> Not found\n",
      "✅ https://www.spotteron.com -> https://www.spotteron.com/#identifier_1515\n",
      "❌ https://smartcitizen.me/ -> Not found\n"
     ]
    }
   ],
   "source": [
    "# Aplicar la función mejorada a todo el dataframe con menos verbosidad\n",
    "def extract_governance_summary(url):\n",
    "    \"\"\"Versión resumida que solo muestra el resultado\"\"\"\n",
    "    try:\n",
    "        result = extract_data_governance_policy_link(url, verbose=False)\n",
    "        if result:\n",
    "            print(f\"✅ {url} -> {result}\")\n",
    "        else:\n",
    "            print(f\"❌ {url} -> Not found\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"{url} -> Error: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Aplicar la función mejorada\n",
    "df_platforms['governance_explicit'] = df_platforms['platform_url'].apply(extract_governance_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "66324a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_platforms.to_csv(\"../data/df_platforms_20251210.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93258deopdk",
   "metadata": {},
   "source": [
    "## API Detection\n",
    "\n",
    "Detects APIs including subdomains like `api.domain.com`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "1057e2d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "api",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "53b78d5e-0ed3-43e2-97e9-15d3ce19be2f",
       "rows": [
        [
         "0",
         "https://observation.org/api-docs"
        ],
        [
         "1",
         null
        ],
        [
         "2",
         null
        ],
        [
         "3",
         null
        ],
        [
         "4",
         null
        ],
        [
         "5",
         null
        ],
        [
         "6",
         "https://my.plantnet.org"
        ],
        [
         "7",
         null
        ],
        [
         "8",
         null
        ],
        [
         "9",
         null
        ],
        [
         "10",
         "https://api.sensor.community/"
        ],
        [
         "11",
         null
        ],
        [
         "12",
         null
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 13
       }
      },
      "text/plain": [
       "0     https://observation.org/api-docs\n",
       "1                                 None\n",
       "2                                 None\n",
       "3                                 None\n",
       "4                                 None\n",
       "5                                 None\n",
       "6              https://my.plantnet.org\n",
       "7                                 None\n",
       "8                                 None\n",
       "9                                 None\n",
       "10       https://api.sensor.community/\n",
       "11                                None\n",
       "12                                None\n",
       "Name: api, dtype: object"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First version\n",
    "def extract_api_url(url):\n",
    "    \"\"\"\n",
    "    Extracts the API URL or documentation URL from a platform.\n",
    "    Searches for API documentation, endpoints, and common API indicators.\n",
    "    \n",
    "    Args:\n",
    "        url (str): Platform URL\n",
    "        \n",
    "    Returns:\n",
    "        str: URL to API documentation/endpoint if found, None otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Ensure URL has protocol\n",
    "        if not url.startswith(('http://', 'https://')):\n",
    "            url = 'https://' + url\n",
    "        \n",
    "        # Configure headers to avoid blocking\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "            'Accept-Language': 'en-US,en;q=0.5',\n",
    "            'Accept-Encoding': 'gzip, deflate',\n",
    "            'Connection': 'keep-alive',\n",
    "        }\n",
    "        \n",
    "        # Make HTTP request\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Parse HTML\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # API-related terms to search for\n",
    "        api_terms = [\n",
    "            # High priority terms\n",
    "            'api documentation', 'api docs', 'api reference', 'api guide',\n",
    "            'developer documentation', 'developers', 'rest api',\n",
    "            \n",
    "            # Medium priority terms\n",
    "            'api', 'web api', 'json api', 'restful api', 'graphql',\n",
    "            'api endpoint', 'api access', 'api integration', 'sdk',\n",
    "            \n",
    "            # Spanish\n",
    "            'documentación api', 'guía api', 'desarrolladores',\n",
    "            \n",
    "            # French\n",
    "            'documentation api', 'guide api', 'développeurs',\n",
    "            \n",
    "            # German\n",
    "            'api dokumentation', 'entwickler',\n",
    "            \n",
    "            # Dutch\n",
    "            'api documentatie', 'ontwikkelaars'\n",
    "        ]\n",
    "        \n",
    "        found_api_links = []\n",
    "        \n",
    "        # 1. Search for direct API links in navigation and content\n",
    "        for link in soup.find_all('a', href=True):\n",
    "            link_text = link.get_text(strip=True).lower()\n",
    "            href = link.get('href')\n",
    "            \n",
    "            # Check if link text contains API terms\n",
    "            for api_term in api_terms:\n",
    "                if api_term in link_text:\n",
    "                    # Convert to absolute URL if relative\n",
    "                    if href.startswith('/'):\n",
    "                        api_url = urljoin(url, href)\n",
    "                    elif href.startswith('http'):\n",
    "                        api_url = href\n",
    "                    else:\n",
    "                        api_url = urljoin(url, '/' + href)\n",
    "                    \n",
    "                    # Add priority score based on term importance\n",
    "                    priority = 3 if api_term in ['api documentation', 'api docs', 'developers', 'api reference'] else 2\n",
    "                    found_api_links.append((api_url, api_term, link_text, priority))\n",
    "        \n",
    "        # 2. Check common API endpoint paths\n",
    "        common_api_paths = [\n",
    "            # High priority paths\n",
    "            '/api/docs', '/api-docs', '/docs/api', '/documentation/api',\n",
    "            '/developers', '/developer',\n",
    "            \n",
    "            # Medium priority paths\n",
    "            '/api', '/api/v1', '/api/v2', '/swagger', '/docs',\n",
    "            '/documentation', '/rest', '/restapi', '/graphql',\n",
    "            \n",
    "            # Lower priority paths\n",
    "            '/api.html', '/api.php', '/help/api', '/support/api',\n",
    "            '/reference/api'\n",
    "        ]\n",
    "        \n",
    "        for i, path in enumerate(common_api_paths):\n",
    "            test_url = urljoin(url, path)\n",
    "            try:\n",
    "                test_response = requests.head(test_url, headers=headers, timeout=5)\n",
    "                if test_response.status_code == 200:\n",
    "                    # Higher priority for paths at the beginning of the list\n",
    "                    priority = 3 if i < 5 else (2 if i < 10 else 1)\n",
    "                    found_api_links.append((test_url, 'common_path', path, priority))\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        # 3. Sort by priority and return the best match\n",
    "        if found_api_links:\n",
    "            # Sort by priority (highest first) and then by term quality\n",
    "            found_api_links.sort(key=lambda x: (-x[3], x[1] != 'common_path'))\n",
    "            return found_api_links[0][0]\n",
    "        \n",
    "        return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting API URL from {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "df_platforms['api'] = df_platforms['platform_url'].apply(extract_api_url)\n",
    "\n",
    "df_platforms['api']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "2c5f26c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_api_url_fixed(url):\n",
    "    \"\"\"\n",
    "    Including variations in paths.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # Ensure URL has protocol\n",
    "        if not url.startswith(('http://', 'https://')):\n",
    "            url = 'https://' + url\n",
    "\n",
    "        # Extract domain from URL\n",
    "        from urllib.parse import urlparse\n",
    "        parsed_url = urlparse(url)\n",
    "        domain = parsed_url.netloc\n",
    "        scheme = parsed_url.scheme\n",
    "\n",
    "        # Extract root domain (remove 'www.' if present)\n",
    "        if domain.startswith('www.'):\n",
    "            root_domain = domain[4:]\n",
    "        else:\n",
    "            root_domain = domain\n",
    "\n",
    "        # Configure headers to avoid blocking\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "        }\n",
    "\n",
    "        found_api_urls = []\n",
    "\n",
    "        # Common API subdomains\n",
    "        api_subdomains = [\n",
    "            f'api.{root_domain}',\n",
    "            f'developer.{root_domain}',\n",
    "            f'docs.{root_domain}',\n",
    "            f'dev.{root_domain}',\n",
    "            f'api-docs.{root_domain}'\n",
    "        ]\n",
    "\n",
    "        # Fixed paths, including variations\n",
    "        subdomain_paths = [\n",
    "            '', '/', '/docs', '/docs/', '/documentation', '/documentation/',\n",
    "            '/v1', '/v1/', '/v2', '/v2/', '/v1/docs', '/v1/docs/', '/v2/docs', '/v2/docs/',\n",
    "            '/swagger', '/swagger/', '/api-docs', '/api-docs/', '/reference', '/reference/'\n",
    "        ]\n",
    "\n",
    "        subdomains_found = 0\n",
    "        for subdomain in api_subdomains:\n",
    "\n",
    "            for path in subdomain_paths:\n",
    "                test_url = f\"{scheme}://{subdomain}{path}\"\n",
    "                try:\n",
    "                    # Usar timeout más largo para subdominios\n",
    "                    test_response = requests.head(test_url, headers=headers, timeout=12, allow_redirects=True)\n",
    "\n",
    "                    if test_response.status_code == 200:\n",
    "                        subdomains_found += 1\n",
    "                        # Máxima prioridad para api.domain.com\n",
    "                        priority = 5 if 'api.' in subdomain else 4\n",
    "                        found_api_urls.append((test_url, 'subdomain', f\"{subdomain}{path}\", priority))\n",
    "                    elif test_response.status_code in [404, 403]:\n",
    "                        # Solo mostrar 404/403 en verbose para paths relevantes\n",
    "                        if 'docs' in path or 'v1' in path:\n",
    "                            print(f\"      ❌ {test_url} -> {test_response.status_code}\")\n",
    "\n",
    "                except requests.exceptions.Timeout:\n",
    "                    print(f\"      Timeout: {test_url}\")\n",
    "                except:\n",
    "                    pass  # Ignorar otros errores silenciosamente\n",
    "\n",
    "        # FILTRAR Y PRIORIZAR RESULTADOS\n",
    "        if found_api_urls:\n",
    "\n",
    "            # Remove duplicates manteniendo la mayor prioridad\n",
    "            unique_urls = {}\n",
    "            for api_url, source, term, priority in found_api_urls:\n",
    "                if api_url not in unique_urls or unique_urls[api_url][2] < priority:\n",
    "                    unique_urls[api_url] = (source, term, priority)\n",
    "\n",
    "            # Sort by priority (highest first)\n",
    "            sorted_urls = sorted(unique_urls.items(), key=lambda x: -x[1][2])\n",
    "\n",
    "            best_url = sorted_urls[0][0]\n",
    "\n",
    "            return best_url\n",
    "\n",
    "        return None\n",
    "\n",
    "    except Exception as e:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "uubdvu2jdh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing urls\n",
      "✅ https://observation.org/ -> https://api.observation.org\n",
      "      ❌ https://api.ornitologia.org/docs -> 404\n",
      "      ❌ https://api.ornitologia.org/docs/ -> 404\n",
      "      ❌ https://api.ornitologia.org/v1 -> 404\n",
      "      ❌ https://api.ornitologia.org/v1/ -> 404\n",
      "      ❌ https://api.ornitologia.org/v1/docs -> 404\n",
      "      ❌ https://api.ornitologia.org/v1/docs/ -> 404\n",
      "      ❌ https://api.ornitologia.org/v2/docs -> 404\n",
      "      ❌ https://api.ornitologia.org/v2/docs/ -> 404\n",
      "      ❌ https://api.ornitologia.org/api-docs -> 404\n",
      "      ❌ https://api.ornitologia.org/api-docs/ -> 404\n",
      "✅ https://ornitologia.org/ -> https://api.ornitologia.org\n",
      "❌ https://mics.tools/ -> No encontrada\n",
      "      ❌ https://developer.zooniverse.org/docs -> 404\n",
      "      ❌ https://developer.zooniverse.org/docs/ -> 404\n",
      "      ❌ https://developer.zooniverse.org/v1 -> 404\n",
      "      ❌ https://developer.zooniverse.org/v1/ -> 404\n",
      "      ❌ https://developer.zooniverse.org/v1/docs -> 404\n",
      "      ❌ https://developer.zooniverse.org/v1/docs/ -> 404\n",
      "      ❌ https://developer.zooniverse.org/v2/docs -> 404\n",
      "      ❌ https://developer.zooniverse.org/v2/docs/ -> 404\n",
      "      ❌ https://developer.zooniverse.org/api-docs -> 404\n",
      "      ❌ https://developer.zooniverse.org/api-docs/ -> 404\n",
      "✅ https://www.zooniverse.org/ -> https://developer.zooniverse.org\n",
      "❌ https://www.pocket.science/products/ispex/ -> No encontrada\n",
      "      ❌ https://api.ispotnature.org/docs -> 404\n",
      "      ❌ https://api.ispotnature.org/docs/ -> 404\n",
      "      ❌ https://api.ispotnature.org/v1 -> 404\n",
      "      ❌ https://api.ispotnature.org/v1/ -> 404\n",
      "      ❌ https://api.ispotnature.org/v1/docs -> 404\n",
      "      ❌ https://api.ispotnature.org/v1/docs/ -> 404\n",
      "      ❌ https://api.ispotnature.org/v2/docs -> 404\n",
      "      ❌ https://api.ispotnature.org/v2/docs/ -> 404\n",
      "      ❌ https://api.ispotnature.org/api-docs -> 404\n",
      "      ❌ https://api.ispotnature.org/api-docs/ -> 404\n",
      "❌ https://www.ispotnature.org/ -> No encontrada\n",
      "      ❌ https://api.plantnet.org/docs -> 404\n",
      "      ❌ https://api.plantnet.org/docs/ -> 404\n",
      "      ❌ https://api.plantnet.org/v1 -> 404\n",
      "      ❌ https://api.plantnet.org/v1/ -> 404\n",
      "      ❌ https://api.plantnet.org/v1/docs -> 404\n",
      "      ❌ https://api.plantnet.org/v1/docs/ -> 404\n",
      "      ❌ https://api.plantnet.org/api-docs -> 404\n",
      "      ❌ https://api.plantnet.org/api-docs/ -> 404\n",
      "      ❌ https://docs.plantnet.org/docs -> 404\n",
      "      ❌ https://docs.plantnet.org/docs/ -> 404\n",
      "      ❌ https://docs.plantnet.org/v1 -> 404\n",
      "      ❌ https://docs.plantnet.org/v1/ -> 404\n",
      "      ❌ https://docs.plantnet.org/v1/docs -> 404\n",
      "      ❌ https://docs.plantnet.org/v1/docs/ -> 404\n",
      "      ❌ https://docs.plantnet.org/v2/docs -> 404\n",
      "      ❌ https://docs.plantnet.org/v2/docs/ -> 404\n",
      "      ❌ https://docs.plantnet.org/api-docs -> 404\n",
      "      ❌ https://docs.plantnet.org/api-docs/ -> 404\n",
      "✅ https://plantnet.org/en/ -> https://docs.plantnet.org\n",
      "      ❌ https://api.smartcitizen.me/docs -> 404\n",
      "      ❌ https://api.smartcitizen.me/docs/ -> 404\n",
      "      ❌ https://api.smartcitizen.me/v1 -> 404\n",
      "      ❌ https://api.smartcitizen.me/v1/ -> 404\n",
      "      ❌ https://api.smartcitizen.me/v1/docs -> 404\n",
      "      ❌ https://api.smartcitizen.me/v1/docs/ -> 404\n",
      "      ❌ https://api.smartcitizen.me/v2/docs -> 404\n",
      "      ❌ https://api.smartcitizen.me/v2/docs/ -> 404\n",
      "      ❌ https://api.smartcitizen.me/api-docs -> 404\n",
      "      ❌ https://api.smartcitizen.me/api-docs/ -> 404\n",
      "      ❌ https://developer.smartcitizen.me/docs -> 404\n",
      "      ❌ https://developer.smartcitizen.me/docs/ -> 404\n",
      "      ❌ https://developer.smartcitizen.me/v1 -> 404\n",
      "      ❌ https://developer.smartcitizen.me/v1/ -> 404\n",
      "      ❌ https://developer.smartcitizen.me/v1/docs -> 404\n",
      "      ❌ https://developer.smartcitizen.me/v1/docs/ -> 404\n",
      "      ❌ https://developer.smartcitizen.me/v2/docs -> 404\n",
      "      ❌ https://developer.smartcitizen.me/v2/docs/ -> 404\n",
      "      ❌ https://developer.smartcitizen.me/api-docs -> 404\n",
      "      ❌ https://developer.smartcitizen.me/api-docs/ -> 404\n",
      "      ❌ https://docs.smartcitizen.me/docs -> 404\n",
      "      ❌ https://docs.smartcitizen.me/docs/ -> 404\n",
      "      ❌ https://docs.smartcitizen.me/v1 -> 404\n",
      "      ❌ https://docs.smartcitizen.me/v1/ -> 404\n",
      "      ❌ https://docs.smartcitizen.me/v1/docs -> 404\n",
      "      ❌ https://docs.smartcitizen.me/v1/docs/ -> 404\n",
      "      ❌ https://docs.smartcitizen.me/v2/docs -> 404\n",
      "      ❌ https://docs.smartcitizen.me/v2/docs/ -> 404\n",
      "      ❌ https://docs.smartcitizen.me/api-docs -> 404\n",
      "      ❌ https://docs.smartcitizen.me/api-docs/ -> 404\n",
      "✅ https://smartcitizen.me/ -> https://api.smartcitizen.me\n",
      "❌ https://artportalen.se/ -> No encontrada\n",
      "      ❌ https://api.minka-sdg.org/v2/docs -> 404\n",
      "      ❌ https://api.minka-sdg.org/v2/docs/ -> 404\n",
      "      ❌ https://api.minka-sdg.org/api-docs -> 404\n",
      "      ❌ https://api.minka-sdg.org/api-docs/ -> 404\n",
      "✅ https://minka-sdg.org/ -> https://api.minka-sdg.org\n",
      "      ❌ https://api.sensor.community/docs -> 404\n",
      "      ❌ https://api.sensor.community/docs/ -> 404\n",
      "      ❌ https://api.sensor.community/v1/docs -> 404\n",
      "      ❌ https://api.sensor.community/v1/docs/ -> 404\n",
      "      ❌ https://api.sensor.community/v2/docs -> 404\n",
      "      ❌ https://api.sensor.community/v2/docs/ -> 404\n",
      "      ❌ https://api.sensor.community/api-docs -> 404\n",
      "      ❌ https://api.sensor.community/api-docs/ -> 404\n",
      "✅ https://sensor.community/en/ -> https://api.sensor.community\n",
      "❌ https://www.spotteron.com -> No encontrada\n",
      "      ❌ https://api.smartcitizen.me/docs -> 404\n",
      "      ❌ https://api.smartcitizen.me/docs/ -> 404\n",
      "      ❌ https://api.smartcitizen.me/v1 -> 404\n",
      "      ❌ https://api.smartcitizen.me/v1/ -> 404\n",
      "      ❌ https://api.smartcitizen.me/v1/docs -> 404\n",
      "      ❌ https://api.smartcitizen.me/v1/docs/ -> 404\n",
      "      ❌ https://api.smartcitizen.me/v2/docs -> 404\n",
      "      ❌ https://api.smartcitizen.me/v2/docs/ -> 404\n",
      "      ❌ https://api.smartcitizen.me/api-docs -> 404\n",
      "      ❌ https://api.smartcitizen.me/api-docs/ -> 404\n",
      "      ❌ https://developer.smartcitizen.me/docs -> 404\n",
      "      ❌ https://developer.smartcitizen.me/docs/ -> 404\n",
      "      ❌ https://developer.smartcitizen.me/v1 -> 404\n",
      "      ❌ https://developer.smartcitizen.me/v1/ -> 404\n",
      "      ❌ https://developer.smartcitizen.me/v1/docs -> 404\n",
      "      ❌ https://developer.smartcitizen.me/v1/docs/ -> 404\n",
      "      ❌ https://developer.smartcitizen.me/v2/docs -> 404\n",
      "      ❌ https://developer.smartcitizen.me/v2/docs/ -> 404\n",
      "      Timeout: https://developer.smartcitizen.me/swagger/\n",
      "      ❌ https://developer.smartcitizen.me/api-docs -> 404\n",
      "      ❌ https://developer.smartcitizen.me/api-docs/ -> 404\n",
      "      ❌ https://docs.smartcitizen.me/docs -> 404\n",
      "      ❌ https://docs.smartcitizen.me/docs/ -> 404\n",
      "      ❌ https://docs.smartcitizen.me/v1 -> 404\n",
      "      ❌ https://docs.smartcitizen.me/v1/ -> 404\n",
      "      ❌ https://docs.smartcitizen.me/v1/docs -> 404\n",
      "      ❌ https://docs.smartcitizen.me/v1/docs/ -> 404\n",
      "      ❌ https://docs.smartcitizen.me/v2/docs -> 404\n",
      "      ❌ https://docs.smartcitizen.me/v2/docs/ -> 404\n",
      "      ❌ https://docs.smartcitizen.me/api-docs -> 404\n",
      "      ❌ https://docs.smartcitizen.me/api-docs/ -> 404\n",
      "✅ https://smartcitizen.me/ -> https://api.smartcitizen.me\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "api",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "api_fixed",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "87b25ada-15b7-452d-a88e-cc225a94f98c",
       "rows": [
        [
         "0",
         "https://observation.org/api-docs",
         "https://api.observation.org"
        ],
        [
         "1",
         null,
         "https://api.ornitologia.org"
        ],
        [
         "2",
         null,
         null
        ],
        [
         "3",
         null,
         "https://developer.zooniverse.org"
        ],
        [
         "4",
         null,
         null
        ],
        [
         "5",
         null,
         null
        ],
        [
         "6",
         "https://my.plantnet.org",
         "https://docs.plantnet.org"
        ],
        [
         "7",
         null,
         "https://api.smartcitizen.me"
        ],
        [
         "8",
         null,
         null
        ],
        [
         "9",
         null,
         "https://api.minka-sdg.org"
        ],
        [
         "10",
         "https://api.sensor.community/",
         "https://api.sensor.community"
        ],
        [
         "11",
         null,
         null
        ],
        [
         "12",
         null,
         "https://api.smartcitizen.me"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 13
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>api</th>\n",
       "      <th>api_fixed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://observation.org/api-docs</td>\n",
       "      <td>https://api.observation.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>https://api.ornitologia.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>https://developer.zooniverse.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://my.plantnet.org</td>\n",
       "      <td>https://docs.plantnet.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>None</td>\n",
       "      <td>https://api.smartcitizen.me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>None</td>\n",
       "      <td>https://api.minka-sdg.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>https://api.sensor.community/</td>\n",
       "      <td>https://api.sensor.community</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>None</td>\n",
       "      <td>https://api.smartcitizen.me</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 api                         api_fixed\n",
       "0   https://observation.org/api-docs       https://api.observation.org\n",
       "1                               None       https://api.ornitologia.org\n",
       "2                               None                              None\n",
       "3                               None  https://developer.zooniverse.org\n",
       "4                               None                              None\n",
       "5                               None                              None\n",
       "6            https://my.plantnet.org         https://docs.plantnet.org\n",
       "7                               None       https://api.smartcitizen.me\n",
       "8                               None                              None\n",
       "9                               None         https://api.minka-sdg.org\n",
       "10     https://api.sensor.community/      https://api.sensor.community\n",
       "11                              None                              None\n",
       "12                              None       https://api.smartcitizen.me"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_api_summary_fixed(url):\n",
    "    \"\"\"Versión resumida de la función corregida\"\"\"\n",
    "    try:\n",
    "        result = extract_api_url_fixed(url)\n",
    "        if result:\n",
    "            print(f\"✅ {url} -> {result}\")\n",
    "        else:\n",
    "            print(f\"❌ {url} -> No encontrada\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"💥 {url} -> Error: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Aplicar la función corregida a todas las URLs\n",
    "print(\"Processing urls\")\n",
    "df_platforms['api_fixed'] = df_platforms['platform_url'].apply(extract_api_summary_fixed)\n",
    "\n",
    "df_platforms[['api', 'api_fixed']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "6bmb73u1nca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_api_url_improved(url):\n",
    "    \"\"\"\n",
    "    Versión mejorada que detecta APIs incluyendo subdominios.\n",
    "    \n",
    "    Args:\n",
    "        url (str): Platform URL\n",
    "        verbose (bool): Si True, imprime información de debugging\n",
    "        \n",
    "    Returns:\n",
    "        str: URL de la API o documentación si se encuentra, None en caso contrario\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Ensure URL has protocol\n",
    "        if not url.startswith(('http://', 'https://')):\n",
    "            url = 'https://' + url\n",
    "        \n",
    "        # Extract domain from URL\n",
    "        from urllib.parse import urlparse\n",
    "        parsed_url = urlparse(url)\n",
    "        domain = parsed_url.netloc\n",
    "        scheme = parsed_url.scheme\n",
    "        \n",
    "        # Configure headers to avoid blocking\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "            'Accept-Language': 'en-US,en;q=0.5',\n",
    "            'Accept-Encoding': 'gzip, deflate',\n",
    "            'Connection': 'keep-alive',\n",
    "        }\n",
    "        \n",
    "        found_api_urls = []\n",
    "        \n",
    "        # 1. BUSCAR EN LA PÁGINA PRINCIPAL\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url, headers=headers, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            \n",
    "            # API-related terms to search for\n",
    "            api_terms = [\n",
    "                'api documentation', 'api docs', 'api reference', 'api guide',\n",
    "                'developer documentation', 'developers', 'rest api', 'api',\n",
    "                'web api', 'json api', 'restful api', 'graphql', 'swagger'\n",
    "            ]\n",
    "            \n",
    "            # Search for API links in the HTML\n",
    "            for link in soup.find_all('a', href=True):\n",
    "                link_text = link.get_text(strip=True).lower()\n",
    "                href = link.get('href')\n",
    "                \n",
    "                for api_term in api_terms:\n",
    "                    if api_term in link_text:\n",
    "                        if href.startswith('/'):\n",
    "                            api_url = urljoin(url, href)\n",
    "                        elif href.startswith('http'):\n",
    "                            api_url = href\n",
    "                        else:\n",
    "                            api_url = urljoin(url, '/' + href)\n",
    "                        \n",
    "                        found_api_urls.append((api_url, 'page_link', api_term, 3))\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"   ✗ Error en página principal: {str(e)}\")\n",
    "        \n",
    "        # 2. PROBAR RUTAS COMUNES EN EL MISMO DOMINIO\n",
    "        \n",
    "        common_api_paths = [\n",
    "            '/api/docs', '/api-docs', '/docs/api', '/documentation/api',\n",
    "            '/developers', '/developer', '/api', '/api/v1', '/api/v2', \n",
    "            '/swagger', '/docs', '/documentation', '/rest', '/restapi',\n",
    "            '/api/v1/docs', '/api/v2/docs', '/v1/docs', '/v2/docs'\n",
    "        ]\n",
    "        \n",
    "        common_paths_found = 0\n",
    "        for path in common_api_paths:\n",
    "            test_url = urljoin(url, path)\n",
    "            try:\n",
    "                test_response = requests.head(test_url, headers=headers, timeout=8)\n",
    "                if test_response.status_code == 200:\n",
    "                    common_paths_found += 1\n",
    "                    found_api_urls.append((test_url, 'common_path', path, 2))\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "\n",
    "        # 3. PROBAR SUBDOMINIOS DE API\n",
    "\n",
    "        # Extract root domain (remove 'www.' if present)\n",
    "        if domain.startswith('www.'):\n",
    "            root_domain = domain[4:]\n",
    "        else:\n",
    "            root_domain = domain\n",
    "        \n",
    "        # Common API subdomains\n",
    "        api_subdomains = [\n",
    "            f'api.{root_domain}',\n",
    "            f'developer.{root_domain}',\n",
    "            f'docs.{root_domain}',\n",
    "            f'dev.{root_domain}',\n",
    "            f'api-docs.{root_domain}'\n",
    "        ]\n",
    "        \n",
    "        subdomain_paths = [\n",
    "            '', '/docs', '/documentation', '/v1', '/v2', '/v1/docs', '/v2/docs',\n",
    "            '/swagger', '/api-docs', '/reference'\n",
    "        ]\n",
    "        \n",
    "        subdomains_found = 0\n",
    "        for subdomain in api_subdomains:\n",
    "            for path in subdomain_paths:\n",
    "                test_url = f\"{scheme}://{subdomain}{path}\"\n",
    "                try:\n",
    "                    test_response = requests.head(test_url, headers=headers, timeout=8)\n",
    "                    if test_response.status_code == 200:\n",
    "                        subdomains_found += 1\n",
    "                        # Higher priority for actual API subdomains\n",
    "                        priority = 4 if 'api.' in subdomain else 3\n",
    "                        found_api_urls.append((test_url, 'subdomain', f\"{subdomain}{path}\", priority))\n",
    "\n",
    "                except:\n",
    "                    continue\n",
    "        \n",
    "        \n",
    "        # 4. FILTRAR Y PRIORIZAR RESULTADOS\n",
    "        if found_api_urls:\n",
    "            \n",
    "            # Remove duplicates\n",
    "            unique_urls = {}\n",
    "            for api_url, source, term, priority in found_api_urls:\n",
    "                if api_url not in unique_urls or unique_urls[api_url][2] < priority:\n",
    "                    unique_urls[api_url] = (source, term, priority)\n",
    "\n",
    "            # Sort by priority (highest first)\n",
    "            sorted_urls = sorted(unique_urls.items(), key=lambda x: -x[1][2])\n",
    "            \n",
    "            best_url = sorted_urls[0][0]\n",
    "            \n",
    "            return best_url\n",
    "\n",
    "        return None\n",
    "        \n",
    "    except Exception as e:\n",
    "\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "a2422864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing urls\n",
      "✅ https://observation.org/ -> https://api.observation.org\n",
      "❌ https://ornitologia.org/ -> No encontrada\n",
      "❌ https://mics.tools/ -> No encontrada\n",
      "❌ https://www.zooniverse.org/ -> No encontrada\n",
      "❌ https://www.pocket.science/products/ispex/ -> No encontrada\n",
      "❌ https://www.ispotnature.org/ -> No encontrada\n",
      "✅ https://plantnet.org/en/ -> https://my.plantnet.org\n",
      "✅ https://smartcitizen.me/ -> https://api.smartcitizen.me\n",
      "❌ https://artportalen.se/ -> No encontrada\n",
      "❌ https://minka-sdg.org/ -> No encontrada\n",
      "✅ https://sensor.community/en/ -> https://api.sensor.community/\n",
      "❌ https://www.spotteron.com -> No encontrada\n",
      "✅ https://smartcitizen.me/ -> https://api.smartcitizen.me\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "api",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "api_fixed",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "api_improved",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "4565eb15-6b57-4809-a44e-5eb10f124658",
       "rows": [
        [
         "0",
         "https://observation.org/api-docs",
         "https://api.observation.org",
         "https://api.observation.org"
        ],
        [
         "1",
         null,
         "https://api.ornitologia.org",
         null
        ],
        [
         "2",
         null,
         null,
         null
        ],
        [
         "3",
         null,
         "https://developer.zooniverse.org",
         null
        ],
        [
         "4",
         null,
         null,
         null
        ],
        [
         "5",
         null,
         null,
         null
        ],
        [
         "6",
         "https://my.plantnet.org",
         "https://docs.plantnet.org",
         "https://my.plantnet.org"
        ],
        [
         "7",
         null,
         "https://api.smartcitizen.me",
         "https://api.smartcitizen.me"
        ],
        [
         "8",
         null,
         null,
         null
        ],
        [
         "9",
         null,
         "https://api.minka-sdg.org",
         null
        ],
        [
         "10",
         "https://api.sensor.community/",
         "https://api.sensor.community",
         "https://api.sensor.community/"
        ],
        [
         "11",
         null,
         null,
         null
        ],
        [
         "12",
         null,
         "https://api.smartcitizen.me",
         "https://api.smartcitizen.me"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 13
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>api</th>\n",
       "      <th>api_fixed</th>\n",
       "      <th>api_improved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://observation.org/api-docs</td>\n",
       "      <td>https://api.observation.org</td>\n",
       "      <td>https://api.observation.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>https://api.ornitologia.org</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>https://developer.zooniverse.org</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://my.plantnet.org</td>\n",
       "      <td>https://docs.plantnet.org</td>\n",
       "      <td>https://my.plantnet.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>None</td>\n",
       "      <td>https://api.smartcitizen.me</td>\n",
       "      <td>https://api.smartcitizen.me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>None</td>\n",
       "      <td>https://api.minka-sdg.org</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>https://api.sensor.community/</td>\n",
       "      <td>https://api.sensor.community</td>\n",
       "      <td>https://api.sensor.community/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>None</td>\n",
       "      <td>https://api.smartcitizen.me</td>\n",
       "      <td>https://api.smartcitizen.me</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 api                         api_fixed  \\\n",
       "0   https://observation.org/api-docs       https://api.observation.org   \n",
       "1                               None       https://api.ornitologia.org   \n",
       "2                               None                              None   \n",
       "3                               None  https://developer.zooniverse.org   \n",
       "4                               None                              None   \n",
       "5                               None                              None   \n",
       "6            https://my.plantnet.org         https://docs.plantnet.org   \n",
       "7                               None       https://api.smartcitizen.me   \n",
       "8                               None                              None   \n",
       "9                               None         https://api.minka-sdg.org   \n",
       "10     https://api.sensor.community/      https://api.sensor.community   \n",
       "11                              None                              None   \n",
       "12                              None       https://api.smartcitizen.me   \n",
       "\n",
       "                     api_improved  \n",
       "0     https://api.observation.org  \n",
       "1                            None  \n",
       "2                            None  \n",
       "3                            None  \n",
       "4                            None  \n",
       "5                            None  \n",
       "6         https://my.plantnet.org  \n",
       "7     https://api.smartcitizen.me  \n",
       "8                            None  \n",
       "9                            None  \n",
       "10  https://api.sensor.community/  \n",
       "11                           None  \n",
       "12    https://api.smartcitizen.me  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_api_summary_improved(url):\n",
    "    \"\"\"Versión resumida de la función mejorada\"\"\"\n",
    "    try:\n",
    "        result = extract_api_url_improved(url)\n",
    "        if result:\n",
    "            print(f\"✅ {url} -> {result}\")\n",
    "        else:\n",
    "            print(f\"❌ {url} -> No encontrada\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"💥 {url} -> Error: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Aplicar la función corregida a todas las URLs\n",
    "print(\"Processing urls\")\n",
    "df_platforms['api_improved'] = df_platforms['platform_url'].apply(extract_api_summary_improved)\n",
    "\n",
    "df_platforms[['api', 'api_fixed', 'api_improved']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74699c0b",
   "metadata": {},
   "source": [
    "Using the three approaches, we check manually all results and keep the most accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "87b67580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "platform_url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "api",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "api_fixed",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "api_improved",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "6ba93382-fd92-43ea-8671-adc595eccdbf",
       "rows": [
        [
         "0",
         "https://observation.org/",
         "https://observation.org/api-docs",
         "https://api.observation.org",
         "https://api.observation.org"
        ],
        [
         "1",
         "https://ornitologia.org/",
         null,
         "https://api.ornitologia.org",
         null
        ],
        [
         "2",
         "https://mics.tools/",
         null,
         null,
         null
        ],
        [
         "3",
         "https://www.zooniverse.org/",
         null,
         "https://developer.zooniverse.org",
         null
        ],
        [
         "4",
         "https://www.pocket.science/products/ispex/",
         null,
         null,
         null
        ],
        [
         "5",
         "https://www.ispotnature.org/",
         null,
         null,
         null
        ],
        [
         "6",
         "https://plantnet.org/en/",
         "https://my.plantnet.org",
         "https://docs.plantnet.org",
         "https://my.plantnet.org"
        ],
        [
         "7",
         "https://smartcitizen.me/",
         null,
         "https://api.smartcitizen.me",
         "https://api.smartcitizen.me"
        ],
        [
         "8",
         "https://artportalen.se/",
         null,
         null,
         null
        ],
        [
         "9",
         "https://minka-sdg.org/",
         null,
         "https://api.minka-sdg.org",
         null
        ],
        [
         "10",
         "https://sensor.community/en/",
         "https://api.sensor.community/",
         "https://api.sensor.community",
         "https://api.sensor.community/"
        ],
        [
         "11",
         "https://www.spotteron.com",
         null,
         null,
         null
        ],
        [
         "12",
         "https://smartcitizen.me/",
         null,
         "https://api.smartcitizen.me",
         "https://api.smartcitizen.me"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 13
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>platform_url</th>\n",
       "      <th>api</th>\n",
       "      <th>api_fixed</th>\n",
       "      <th>api_improved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://observation.org/</td>\n",
       "      <td>https://observation.org/api-docs</td>\n",
       "      <td>https://api.observation.org</td>\n",
       "      <td>https://api.observation.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://ornitologia.org/</td>\n",
       "      <td>None</td>\n",
       "      <td>https://api.ornitologia.org</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://mics.tools/</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.zooniverse.org/</td>\n",
       "      <td>None</td>\n",
       "      <td>https://developer.zooniverse.org</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.pocket.science/products/ispex/</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://www.ispotnature.org/</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://plantnet.org/en/</td>\n",
       "      <td>https://my.plantnet.org</td>\n",
       "      <td>https://docs.plantnet.org</td>\n",
       "      <td>https://my.plantnet.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://smartcitizen.me/</td>\n",
       "      <td>None</td>\n",
       "      <td>https://api.smartcitizen.me</td>\n",
       "      <td>https://api.smartcitizen.me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://artportalen.se/</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://minka-sdg.org/</td>\n",
       "      <td>None</td>\n",
       "      <td>https://api.minka-sdg.org</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>https://sensor.community/en/</td>\n",
       "      <td>https://api.sensor.community/</td>\n",
       "      <td>https://api.sensor.community</td>\n",
       "      <td>https://api.sensor.community/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>https://www.spotteron.com</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>https://smartcitizen.me/</td>\n",
       "      <td>None</td>\n",
       "      <td>https://api.smartcitizen.me</td>\n",
       "      <td>https://api.smartcitizen.me</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  platform_url  \\\n",
       "0                     https://observation.org/   \n",
       "1                     https://ornitologia.org/   \n",
       "2                          https://mics.tools/   \n",
       "3                  https://www.zooniverse.org/   \n",
       "4   https://www.pocket.science/products/ispex/   \n",
       "5                 https://www.ispotnature.org/   \n",
       "6                     https://plantnet.org/en/   \n",
       "7                     https://smartcitizen.me/   \n",
       "8                      https://artportalen.se/   \n",
       "9                       https://minka-sdg.org/   \n",
       "10                https://sensor.community/en/   \n",
       "11                   https://www.spotteron.com   \n",
       "12                    https://smartcitizen.me/   \n",
       "\n",
       "                                 api                         api_fixed  \\\n",
       "0   https://observation.org/api-docs       https://api.observation.org   \n",
       "1                               None       https://api.ornitologia.org   \n",
       "2                               None                              None   \n",
       "3                               None  https://developer.zooniverse.org   \n",
       "4                               None                              None   \n",
       "5                               None                              None   \n",
       "6            https://my.plantnet.org         https://docs.plantnet.org   \n",
       "7                               None       https://api.smartcitizen.me   \n",
       "8                               None                              None   \n",
       "9                               None         https://api.minka-sdg.org   \n",
       "10     https://api.sensor.community/      https://api.sensor.community   \n",
       "11                              None                              None   \n",
       "12                              None       https://api.smartcitizen.me   \n",
       "\n",
       "                     api_improved  \n",
       "0     https://api.observation.org  \n",
       "1                            None  \n",
       "2                            None  \n",
       "3                            None  \n",
       "4                            None  \n",
       "5                            None  \n",
       "6         https://my.plantnet.org  \n",
       "7     https://api.smartcitizen.me  \n",
       "8                            None  \n",
       "9                            None  \n",
       "10  https://api.sensor.community/  \n",
       "11                           None  \n",
       "12    https://api.smartcitizen.me  "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_platforms[['platform_url', 'api', 'api_fixed', 'api_improved']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "a31811b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_apis = {\n",
    "    \"https://observation.org/\": None,\n",
    "    \"https://ornitologia.org/\": \"https://api.ornitologia.org\",\n",
    "    \"https://www.zooniverse.org/\": \"https://developer.zooniverse.org\",\n",
    "    \"https://plantnet.org/en/\": \"https://my.plantnet.org\",\n",
    "    \"https://smartcitizen.me/\": \"https://developer.smartcitizen.me\",\n",
    "    \"https://minka-sdg.org/\": \"https://api.minka-sdg.org\",\n",
    "    \"https://sensor.community/en/\": \"https://api.sensor.community\",\n",
    "}\n",
    "\n",
    "for k,v in final_apis.items():\n",
    "    df_platforms.loc[df_platforms.platform_url == k, \"api\"] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "cadab253",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_platforms.drop(columns=['api_fixed', \"api_improved\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "b0bdaca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_platforms.to_csv(\"../data/df_platforms_20251210.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfd8945",
   "metadata": {},
   "source": [
    "# organization_of_managers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3168eda",
   "metadata": {},
   "source": [
    "The strategy of searching in whois data is not ideal, because this field can be private."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "0ff7fb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_organization_from_whois(url):\n",
    "    \"\"\"\n",
    "    Extracts the organization name from WHOIS data of the domain.\n",
    "    This is more reliable than parsing website content.\n",
    "    \n",
    "    Args:\n",
    "        url (str): Platform URL\n",
    "        \n",
    "    Returns:\n",
    "        str: Organization name from WHOIS data if found, None otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import whois\n",
    "        \n",
    "        # Ensure URL has protocol and extract domain\n",
    "        if not url.startswith(('http://', 'https://')):\n",
    "            url = 'https://' + url\n",
    "        \n",
    "        # Parse domain from URL\n",
    "        parsed_url = urlparse(url)\n",
    "        domain = parsed_url.netloc\n",
    "        \n",
    "        # Remove www prefix if present\n",
    "        if domain.startswith('www.'):\n",
    "            domain = domain[4:]\n",
    "        \n",
    "        # Get WHOIS information\n",
    "        domain_info = whois.whois(domain)\n",
    "        \n",
    "        # Try different fields that might contain organization info\n",
    "        org_fields = ['org', 'organization', 'registrant_organization', 'registrant', 'admin_organization']\n",
    "        \n",
    "        for field in org_fields:\n",
    "            if hasattr(domain_info, field):\n",
    "                org_value = getattr(domain_info, field)\n",
    "                if org_value:\n",
    "                    # Handle case where value might be a list\n",
    "                    if isinstance(org_value, list):\n",
    "                        org_value = org_value[0] if org_value else None\n",
    "                    \n",
    "                    if org_value and isinstance(org_value, str):\n",
    "                        # Clean the organization name\n",
    "                        org_clean = org_value.strip()\n",
    "                        \n",
    "                        # Skip if it's just privacy protection or empty\n",
    "                        privacy_indicators = [\n",
    "                            'privacy', 'protection', 'private', 'whoisguard', 'proxy',\n",
    "                            'redacted', 'data protected', 'contact privacy'\n",
    "                        ]\n",
    "                        \n",
    "                        if (org_clean and \n",
    "                            len(org_clean) > 2 and \n",
    "                            not any(indicator in org_clean.lower() for indicator in privacy_indicators)):\n",
    "                            return org_clean\n",
    "        \n",
    "        # If no organization found in standard fields, try registrant name\n",
    "        if hasattr(domain_info, 'registrant_name') and domain_info.registrant_name:\n",
    "            registrant = domain_info.registrant_name\n",
    "            if isinstance(registrant, list):\n",
    "                registrant = registrant[0] if registrant else None\n",
    "            \n",
    "            if registrant and isinstance(registrant, str):\n",
    "                registrant_clean = registrant.strip()\n",
    "                privacy_indicators = [\n",
    "                    'privacy', 'protection', 'private', 'whoisguard', 'proxy',\n",
    "                    'redacted', 'data protected', 'contact privacy'\n",
    "                ]\n",
    "                \n",
    "                if (registrant_clean and \n",
    "                    len(registrant_clean) > 2 and \n",
    "                    not any(indicator in registrant_clean.lower() for indicator in privacy_indicators)):\n",
    "                    return registrant_clean\n",
    "        \n",
    "        return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting organization from WHOIS for {url}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "2cc0aabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-11 18:59:00,830 - whois.whois - ERROR - Error trying to connect to socket: closing socket - [Errno -2] Nombre o servicio desconocido\n",
      "2025-12-11 18:59:33,661 - whois.whois - ERROR - Error trying to connect to socket: closing socket - [Errno -2] Nombre o servicio desconocido\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "organization_of_managers",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "5a63df1e-8dce-4192-add8-af34416aa6d5",
       "rows": [
        [
         "0",
         null
        ],
        [
         "1",
         null
        ],
        [
         "2",
         null
        ],
        [
         "3",
         null
        ],
        [
         "4",
         "DDQ B.V."
        ],
        [
         "5",
         null
        ],
        [
         "6",
         null
        ],
        [
         "7",
         null
        ],
        [
         "8",
         "artdat1805-00001"
        ],
        [
         "9",
         null
        ],
        [
         "10",
         null
        ],
        [
         "11",
         "Not Disclosed"
        ],
        [
         "12",
         null
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 13
       }
      },
      "text/plain": [
       "0                 None\n",
       "1                 None\n",
       "2                 None\n",
       "3                 None\n",
       "4             DDQ B.V.\n",
       "5                 None\n",
       "6                 None\n",
       "7                 None\n",
       "8     artdat1805-00001\n",
       "9                 None\n",
       "10                None\n",
       "11       Not Disclosed\n",
       "12                None\n",
       "Name: organization_of_managers, dtype: object"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the WHOIS-based organization extraction function to all platforms\n",
    "df_platforms['organization_of_managers'] = df_platforms['platform_url'].apply(extract_organization_from_whois)\n",
    "df_platforms['organization_of_managers']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94dc87b",
   "metadata": {},
   "source": [
    "* Extract Organization from Website Footer\n",
    "\n",
    "This function searches for organization information in website footers by looking for common patterns like copyright notices, company names, and organizational information typically found in footer sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "76cba835",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "def clean_organization_name(org_name):\n",
    "    \"\"\"\n",
    "    Clean and normalize organization name.\n",
    "    \"\"\"\n",
    "    if not org_name:\n",
    "        return None\n",
    "    \n",
    "    # Remove common noise words and characters\n",
    "    noise_patterns = [\n",
    "        r'^(?:by|de|von|par|da|di)\\s+',  # Remove leading prepositions\n",
    "        r'\\s*(?:all rights reserved|todos los derechos reservados|tous droits réservés).*$',\n",
    "        r'\\s*(?:\\d{4}(?:-\\d{4})?)\\s*$',  # Remove trailing years\n",
    "        r'^\\s*[\\-•·]+\\s*',  # Remove leading bullets\n",
    "        r'\\s*[\\-•·]+\\s*$',  # Remove trailing bullets\n",
    "    ]\n",
    "    \n",
    "    cleaned = org_name.strip()\n",
    "    \n",
    "    for pattern in noise_patterns:\n",
    "        cleaned = re.sub(pattern, '', cleaned, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    cleaned = re.sub(r'\\s+', ' ', cleaned).strip()\n",
    "    \n",
    "    # Filter out very generic terms\n",
    "    generic_terms = [\n",
    "        'all rights reserved', 'copyright', 'terms', 'privacy', 'policy',\n",
    "        'contact', 'about', 'home', 'menu', 'navigation', 'footer',\n",
    "        'cookies', 'legal', 'disclaimer', 'sitemap'\n",
    "    ]\n",
    "    \n",
    "    if cleaned.lower() in generic_terms:\n",
    "        return None\n",
    "    \n",
    "    # Title case for better presentation\n",
    "    return cleaned.title() if cleaned else None\n",
    "\n",
    "def extract_organization_from_footer(url):\n",
    "    \"\"\"\n",
    "    Extracts organization information from website footer.\n",
    "    Searches for copyright notices, company names, and organizational information\n",
    "    typically found in footer sections.\n",
    "    \n",
    "    Args:\n",
    "        url (str): Website URL to analyze\n",
    "        verbose (bool): Print detailed information during processing\n",
    "        \n",
    "    Returns:\n",
    "        str: Organization name if found, None otherwise\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Ensure URL has protocol\n",
    "        if not url.startswith(('http://', 'https://')):\n",
    "            url = 'https://' + url\n",
    "        \n",
    "        # Configure headers to avoid blocking\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "            'Accept-Language': 'en-US,en;q=0.5',\n",
    "            'Accept-Encoding': 'gzip, deflate',\n",
    "            'Connection': 'keep-alive',\n",
    "        }\n",
    "        \n",
    "        # Make HTTP request\n",
    "        response = requests.get(url, headers=headers, timeout=15)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        \n",
    "        # Parse HTML\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        found_organizations = []\n",
    "        \n",
    "        # 1. Search in footer elements\n",
    "            \n",
    "        footer_selectors = [\n",
    "            'footer',\n",
    "            '.footer',\n",
    "            '#footer',\n",
    "            '.site-footer',\n",
    "            '.page-footer',\n",
    "            '.main-footer',\n",
    "            'div[role=\"contentinfo\"]',\n",
    "            '.copyright',\n",
    "            '.credits'\n",
    "        ]\n",
    "        \n",
    "        footer_texts = []\n",
    "        for selector in footer_selectors:\n",
    "            elements = soup.select(selector)\n",
    "            for element in elements:\n",
    "                text = element.get_text(separator=' ', strip=True)\n",
    "                if text and len(text) > 10:  # Filter very short texts\n",
    "                    footer_texts.append(text)\n",
    "\n",
    "            \n",
    "        # Copyright patterns in multiple languages\n",
    "        copyright_patterns = [\n",
    "            # English patterns\n",
    "            r'©\\s*(?:copyright\\s*)?(?:\\d{4}(?:-\\d{4})?\\s*)?([^\\n\\r.,;]+?)(?:\\.|,|;|$|\\n|\\r)',\n",
    "            r'copyright\\s*(?:\\d{4}(?:-\\d{4})?\\s*)?(?:by\\s*)?([^\\n\\r.,;]+?)(?:\\.|,|;|$|\\n|\\r)',\n",
    "            r'\\(c\\)\\s*(?:\\d{4}(?:-\\d{4})?\\s*)?([^\\n\\r.,;]+?)(?:\\.|,|;|$|\\n|\\r)',\n",
    "            \n",
    "            # Organization patterns\n",
    "            r'owned\\s*by\\s*([^\\n\\r.,;]+?)(?:\\.|,|;|$|\\n|\\r)',\n",
    "            r'operated\\s*by\\s*([^\\n\\r.,;]+?)(?:\\.|,|;|$|\\n|\\r)',\n",
    "            r'managed\\s*by\\s*([^\\n\\r.,;]+?)(?:\\.|,|;|$|\\n|\\r)',\n",
    "            r'developed\\s*by\\s*([^\\n\\r.,;]+?)(?:\\.|,|;|$|\\n|\\r)',\n",
    "            \n",
    "            # Spanish patterns\n",
    "            r'propiedad\\s*de\\s*([^\\n\\r.,;]+?)(?:\\.|,|;|$|\\n|\\r)',\n",
    "            r'gestionado\\s*por\\s*([^\\n\\r.,;]+?)(?:\\.|,|;|$|\\n|\\r)',\n",
    "            r'desarrollado\\s*por\\s*([^\\n\\r.,;]+?)(?:\\.|,|;|$|\\n|\\r)',\n",
    "        ]\n",
    "        \n",
    "        # Search footer texts for patterns\n",
    "        for text in footer_texts:\n",
    "            text_lower = text.lower()\n",
    "            for pattern in copyright_patterns:\n",
    "                matches = re.finditer(pattern, text_lower, re.IGNORECASE | re.MULTILINE)\n",
    "                for match in matches:\n",
    "                    org_name = match.group(1).strip()\n",
    "                    \n",
    "                    # Clean and validate organization name\n",
    "                    org_name = clean_organization_name(org_name)\n",
    "                    \n",
    "                    if org_name and len(org_name) > 2:\n",
    "                        found_organizations.append((org_name, 'copyright_pattern'))\n",
    "\n",
    "        # 3. Search for common organizational indicators in footer\n",
    "        org_indicators = [\n",
    "            r'([^\\n\\r.,;]+?)\\s*(?:university|universidad|université|universität|uni)',\n",
    "            r'([^\\n\\r.,;]+?)\\s*(?:institute|instituto|institut)',\n",
    "            r'([^\\n\\r.,;]+?)\\s*(?:foundation|fundación|fondation|stiftung)',\n",
    "            r'([^\\n\\r.,;]+?)\\s*(?:organization|organización|organisation)',\n",
    "            r'([^\\n\\r.,;]+?)\\s*(?:association|asociación|verein)',\n",
    "            r'([^\\n\\r.,;]+?)\\s*(?:company|empresa|société|unternehmen|corp|ltd|inc|gmbh|bv)',\n",
    "            r'([^\\n\\r.,;]+?)\\s*(?:government|gobierno|gouvernement|regierung)',\n",
    "            r'([^\\n\\r.,;]+?)\\s*(?:ministry|ministerio|ministère|ministerium)',\n",
    "        ]\n",
    "        \n",
    "        for text in footer_texts:\n",
    "            text_lower = text.lower()\n",
    "            for pattern in org_indicators:\n",
    "                matches = re.finditer(pattern, text_lower, re.IGNORECASE)\n",
    "                for match in matches:\n",
    "                    org_name = match.group(0).strip()\n",
    "                    \n",
    "                    # Clean organization name\n",
    "                    org_name = clean_organization_name(org_name)\n",
    "                    \n",
    "                    if org_name and len(org_name) > 5:\n",
    "                        found_organizations.append((org_name, 'org_indicator'))\n",
    "\n",
    "        # 4. Process and prioritize results\n",
    "        if found_organizations:\n",
    "\n",
    "            # Remove duplicates and prioritize\n",
    "            unique_orgs = {}\n",
    "            for org_name, source in found_organizations:\n",
    "                # Priority: copyright patterns > org indicators\n",
    "                priority = 2 if source == 'copyright_pattern' else 1\n",
    "                \n",
    "                if org_name not in unique_orgs or unique_orgs[org_name][1] < priority:\n",
    "                    unique_orgs[org_name] = (source, priority)\n",
    "            \n",
    "\n",
    "            # Return the highest priority organization\n",
    "            best_org = max(unique_orgs.items(), key=lambda x: x[1][1])[0]\n",
    "            \n",
    "            return best_org\n",
    "        \n",
    "        return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ ERROR: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "8fa4e305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ https://observation.org/ -> No encontrada\n",
      "❌ https://ornitologia.org/ -> No encontrada\n",
      "✅ https://mics.tools/ -> This Project Has Received Funding From The European Uni\n",
      "❌ https://www.zooniverse.org/ -> No encontrada\n",
      "✅ https://www.pocket.science/products/ispex/ -> Pocket\n",
      "❌ https://www.ispotnature.org/ -> No encontrada\n",
      "✅ https://plantnet.org/en/ -> Pl@Ntnet™\n",
      "❌ https://smartcitizen.me/ -> No encontrada\n",
      "❌ https://artportalen.se/ -> No encontrada\n",
      "✅ https://minka-sdg.org/ -> About Us Contact Us Communi\n",
      "❌ https://sensor.community/en/ -> No encontrada\n",
      "✅ https://www.spotteron.com -> Net Phone: +43-676-598-2272 Skype: Spotteron Spotteron Gmbh\n",
      "❌ https://smartcitizen.me/ -> No encontrada\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "platform_url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "organization_of_managers",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "footer_organization",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "f1590272-d643-4f81-a9f8-d495fc4fe29b",
       "rows": [
        [
         "0",
         "https://observation.org/",
         null,
         null
        ],
        [
         "1",
         "https://ornitologia.org/",
         null,
         null
        ],
        [
         "2",
         "https://mics.tools/",
         null,
         "This Project Has Received Funding From The European Uni"
        ],
        [
         "3",
         "https://www.zooniverse.org/",
         null,
         null
        ],
        [
         "4",
         "https://www.pocket.science/products/ispex/",
         "DDQ B.V.",
         "Pocket"
        ],
        [
         "5",
         "https://www.ispotnature.org/",
         null,
         null
        ],
        [
         "6",
         "https://plantnet.org/en/",
         null,
         "Pl@Ntnet™"
        ],
        [
         "7",
         "https://smartcitizen.me/",
         null,
         null
        ],
        [
         "8",
         "https://artportalen.se/",
         "artdat1805-00001",
         null
        ],
        [
         "9",
         "https://minka-sdg.org/",
         null,
         "About Us Contact Us Communi"
        ],
        [
         "10",
         "https://sensor.community/en/",
         null,
         null
        ],
        [
         "11",
         "https://www.spotteron.com",
         "Not Disclosed",
         "Net Phone: +43-676-598-2272 Skype: Spotteron Spotteron Gmbh"
        ],
        [
         "12",
         "https://smartcitizen.me/",
         null,
         null
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 13
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>platform_url</th>\n",
       "      <th>organization_of_managers</th>\n",
       "      <th>footer_organization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://observation.org/</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://ornitologia.org/</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://mics.tools/</td>\n",
       "      <td>None</td>\n",
       "      <td>This Project Has Received Funding From The Eur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.zooniverse.org/</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.pocket.science/products/ispex/</td>\n",
       "      <td>DDQ B.V.</td>\n",
       "      <td>Pocket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://www.ispotnature.org/</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://plantnet.org/en/</td>\n",
       "      <td>None</td>\n",
       "      <td>Pl@Ntnet™</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://smartcitizen.me/</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://artportalen.se/</td>\n",
       "      <td>artdat1805-00001</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://minka-sdg.org/</td>\n",
       "      <td>None</td>\n",
       "      <td>About Us Contact Us Communi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>https://sensor.community/en/</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>https://www.spotteron.com</td>\n",
       "      <td>Not Disclosed</td>\n",
       "      <td>Net Phone: +43-676-598-2272 Skype: Spotteron S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>https://smartcitizen.me/</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  platform_url organization_of_managers  \\\n",
       "0                     https://observation.org/                     None   \n",
       "1                     https://ornitologia.org/                     None   \n",
       "2                          https://mics.tools/                     None   \n",
       "3                  https://www.zooniverse.org/                     None   \n",
       "4   https://www.pocket.science/products/ispex/                 DDQ B.V.   \n",
       "5                 https://www.ispotnature.org/                     None   \n",
       "6                     https://plantnet.org/en/                     None   \n",
       "7                     https://smartcitizen.me/                     None   \n",
       "8                      https://artportalen.se/         artdat1805-00001   \n",
       "9                       https://minka-sdg.org/                     None   \n",
       "10                https://sensor.community/en/                     None   \n",
       "11                   https://www.spotteron.com            Not Disclosed   \n",
       "12                    https://smartcitizen.me/                     None   \n",
       "\n",
       "                                  footer_organization  \n",
       "0                                                None  \n",
       "1                                                None  \n",
       "2   This Project Has Received Funding From The Eur...  \n",
       "3                                                None  \n",
       "4                                              Pocket  \n",
       "5                                                None  \n",
       "6                                           Pl@Ntnet™  \n",
       "7                                                None  \n",
       "8                                                None  \n",
       "9                         About Us Contact Us Communi  \n",
       "10                                               None  \n",
       "11  Net Phone: +43-676-598-2272 Skype: Spotteron S...  \n",
       "12                                               None  "
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the footer organization extraction function to all platforms\n",
    "def extract_organization_summary(url):\n",
    "    \"\"\"Wrapper function for applying to DataFrame\"\"\"\n",
    "    try:\n",
    "        result = extract_organization_from_footer(url)\n",
    "        if result:\n",
    "            print(f\"✅ {url} -> {result}\")\n",
    "        else:\n",
    "            print(f\"❌ {url} -> No encontrada\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"💥 {url} -> Error: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Apply to the dataframe\n",
    "df_platforms['footer_organization'] = df_platforms['platform_url'].apply(extract_organization_summary)\n",
    "\n",
    "df_platforms[['platform_url','organization_of_managers', 'footer_organization']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eee1c62",
   "metadata": {},
   "source": [
    "# Additional Organization Extraction Strategies\n",
    "\n",
    "This section implements various strategies to extract organization information from websites beyond WHOIS data and footer analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "46807ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_organization_from_about_page(url):\n",
    "    \"\"\"\n",
    "    Extract organization information from About/About Us pages.\n",
    "    These pages typically contain detailed organizational information.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not url.startswith(('http://', 'https://')):\n",
    "            url = 'https://' + url\n",
    "        \n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "        }\n",
    "        \n",
    "        # Find about page URL first\n",
    "        response = requests.get(url, headers=headers, timeout=15)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Look for about page links\n",
    "        about_patterns = ['about', 'about us', 'about-us', 'who we are', 'organization', 'company']\n",
    "        about_url = None\n",
    "        \n",
    "        for link in soup.find_all('a', href=True):\n",
    "            link_text = link.get_text(strip=True).lower()\n",
    "            href = link.get('href')\n",
    "            \n",
    "            if any(pattern in link_text for pattern in about_patterns):\n",
    "                if href.startswith('/'):\n",
    "                    about_url = urljoin(url, href)\n",
    "                elif href.startswith('http'):\n",
    "                    about_url = href\n",
    "                break\n",
    "        \n",
    "        if not about_url:\n",
    "            # Try common about page paths\n",
    "            for path in ['/about', '/about-us', '/about.html', '/company', '/organization']:\n",
    "                test_url = urljoin(url, path)\n",
    "                try:\n",
    "                    test_response = requests.head(test_url, headers=headers, timeout=5)\n",
    "                    if test_response.status_code == 200:\n",
    "                        about_url = test_url\n",
    "                        break\n",
    "                except:\n",
    "                    continue\n",
    "        \n",
    "        if about_url:\n",
    "            # Parse about page\n",
    "            about_response = requests.get(about_url, headers=headers, timeout=15)\n",
    "            about_soup = BeautifulSoup(about_response.text, 'html.parser')\n",
    "            \n",
    "            # Extract organization name from title, headings, and first paragraphs\n",
    "            text_content = about_soup.get_text(separator=' ', strip=True)\n",
    "            \n",
    "            # Look for organizational patterns in about page content\n",
    "            org_patterns = [\n",
    "                r'(?:we are|somos|nous sommes)\\s+([^.!?]+?)(?:\\.|!|\\?)',\n",
    "                r'([^.!?\\n]+?)\\s+(?:is|es|est)\\s+(?:a|an|una?)\\s+(?:non-profit|nonprofit|organization|fundación|organización)',\n",
    "                r'(?:founded by|fundada por|fondée par)\\s+([^.!?\\n]+?)(?:\\.|!|\\?)',\n",
    "                r'(?:established|establecida|établie)\\s+(?:by|por|par)\\s+([^.!?\\n]+?)(?:\\.|!|\\?)',\n",
    "            ]\n",
    "            \n",
    "            for pattern in org_patterns:\n",
    "                matches = re.finditer(pattern, text_content, re.IGNORECASE)\n",
    "                for match in matches:\n",
    "                    org_name = match.group(1).strip()\n",
    "                    org_name = clean_organization_name(org_name)\n",
    "                    if org_name and len(org_name) > 3:\n",
    "                        return org_name\n",
    "        \n",
    "        return None\n",
    "        \n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def extract_organization_from_metadata(url):\n",
    "    \"\"\"\n",
    "    Extract organization information from HTML metadata tags.\n",
    "    Includes Open Graph, Twitter Cards, and other meta tags.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not url.startswith(('http://', 'https://')):\n",
    "            url = 'https://' + url\n",
    "        \n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "        }\n",
    "        \n",
    "        response = requests.get(url, headers=headers, timeout=15)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Check various meta tags that might contain organization info\n",
    "        meta_selectors = [\n",
    "            'meta[property=\"og:site_name\"]',\n",
    "            'meta[name=\"author\"]',\n",
    "            'meta[name=\"publisher\"]',\n",
    "            'meta[name=\"copyright\"]',\n",
    "            'meta[property=\"article:publisher\"]',\n",
    "            'meta[name=\"twitter:site\"]',\n",
    "            'meta[name=\"application-name\"]',\n",
    "            'meta[name=\"organization\"]',\n",
    "            'meta[name=\"company\"]'\n",
    "        ]\n",
    "        \n",
    "        for selector in meta_selectors:\n",
    "            meta_tag = soup.select_one(selector)\n",
    "            if meta_tag:\n",
    "                content = meta_tag.get('content', '').strip()\n",
    "                if content and len(content) > 2:\n",
    "                    # Clean Twitter handles\n",
    "                    if content.startswith('@'):\n",
    "                        content = content[1:]\n",
    "                    \n",
    "                    org_name = clean_organization_name(content)\n",
    "                    if org_name:\n",
    "                        return org_name\n",
    "        \n",
    "        # Check JSON-LD structured data\n",
    "        json_scripts = soup.find_all('script', type='application/ld+json')\n",
    "        for script in json_scripts:\n",
    "            try:\n",
    "                data = json.loads(script.string)\n",
    "                if isinstance(data, dict):\n",
    "                    # Look for organization information in structured data\n",
    "                    org_fields = ['name', 'legalName', 'alternateName', 'publisher']\n",
    "                    for field in org_fields:\n",
    "                        if field in data and isinstance(data[field], str):\n",
    "                            org_name = clean_organization_name(data[field])\n",
    "                            if org_name:\n",
    "                                return org_name\n",
    "                    \n",
    "                    # Check nested organization objects\n",
    "                    if 'publisher' in data and isinstance(data['publisher'], dict):\n",
    "                        if 'name' in data['publisher']:\n",
    "                            org_name = clean_organization_name(data['publisher']['name'])\n",
    "                            if org_name:\n",
    "                                return org_name\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        return None\n",
    "        \n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def extract_organization_from_contact_page(url):\n",
    "    \"\"\"\n",
    "    Extract organization information from contact pages.\n",
    "    Contact pages often contain formal organization names and addresses.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not url.startswith(('http://', 'https://')):\n",
    "            url = 'https://' + url\n",
    "        \n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "        }\n",
    "        \n",
    "        # Find contact page URL\n",
    "        response = requests.get(url, headers=headers, timeout=15)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        contact_patterns = ['contact', 'contact us', 'contacto', 'kontakt']\n",
    "        contact_url = None\n",
    "        \n",
    "        for link in soup.find_all('a', href=True):\n",
    "            link_text = link.get_text(strip=True).lower()\n",
    "            href = link.get('href')\n",
    "            \n",
    "            if any(pattern in link_text for pattern in contact_patterns):\n",
    "                if href.startswith('/'):\n",
    "                    contact_url = urljoin(url, href)\n",
    "                elif href.startswith('http'):\n",
    "                    contact_url = href\n",
    "                break\n",
    "        \n",
    "        if not contact_url:\n",
    "            # Try common contact page paths\n",
    "            for path in ['/contact', '/contact-us', '/contact.html', '/contacto']:\n",
    "                test_url = urljoin(url, path)\n",
    "                try:\n",
    "                    test_response = requests.head(test_url, headers=headers, timeout=5)\n",
    "                    if test_response.status_code == 200:\n",
    "                        contact_url = test_url\n",
    "                        break\n",
    "                except:\n",
    "                    continue\n",
    "        \n",
    "        if contact_url:\n",
    "            # Parse contact page\n",
    "            contact_response = requests.get(contact_url, headers=headers, timeout=15)\n",
    "            contact_soup = BeautifulSoup(contact_response.text, 'html.parser')\n",
    "            \n",
    "            text_content = contact_soup.get_text(separator=' ', strip=True)\n",
    "            \n",
    "            # Look for address patterns that include organization names\n",
    "            address_patterns = [\n",
    "                r'([A-Z][A-Za-z\\s]+(?:University|Institute|Foundation|Organization|Company|Corp|Ltd|Inc|GmbH|BV))',\n",
    "                r'([A-Z][A-Za-z\\s]+)[\\s\\n]+\\d+\\s+[A-Z]',  # Organization name before address\n",
    "                r'(?:Registered|Legal)\\s+(?:name|entity):\\s*([^.\\n]+)',\n",
    "            ]\n",
    "            \n",
    "            for pattern in address_patterns:\n",
    "                matches = re.finditer(pattern, text_content, re.MULTILINE)\n",
    "                for match in matches:\n",
    "                    org_name = match.group(1).strip()\n",
    "                    org_name = clean_organization_name(org_name)\n",
    "                    if org_name and len(org_name) > 5:\n",
    "                        return org_name\n",
    "        \n",
    "        return None\n",
    "        \n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def extract_organization_from_title_and_headers(url):\n",
    "    \"\"\"\n",
    "    Extract organization information from page title, main headings, and logo alt text.\n",
    "    The main page often contains the organization name prominently.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not url.startswith(('http://', 'https://')):\n",
    "            url = 'https://' + url\n",
    "        \n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "        }\n",
    "        \n",
    "        response = requests.get(url, headers=headers, timeout=15)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        candidates = []\n",
    "        \n",
    "        # Extract from page title\n",
    "        title_tag = soup.find('title')\n",
    "        if title_tag:\n",
    "            title = title_tag.get_text(strip=True)\n",
    "            # Remove common suffixes\n",
    "            title = re.sub(r'\\s*[-|:]\\s*(?:Home|Welcome|Official Site|Website).*$', '', title, flags=re.IGNORECASE)\n",
    "            if title and len(title) > 3:\n",
    "                candidates.append((title, 3))\n",
    "        \n",
    "        # Extract from main headings (h1, h2)\n",
    "        for tag in ['h1', 'h2']:\n",
    "            headings = soup.find_all(tag)\n",
    "            for heading in headings[:3]:  # Only check first few headings\n",
    "                text = heading.get_text(strip=True)\n",
    "                if text and len(text) > 3 and len(text) < 100:\n",
    "                    candidates.append((text, 2))\n",
    "        \n",
    "        # Extract from logo alt text and site branding\n",
    "        logo_selectors = [\n",
    "            'img[alt*=\"logo\"]',\n",
    "            'img[class*=\"logo\"]',\n",
    "            'img[id*=\"logo\"]',\n",
    "            '.logo img',\n",
    "            '.brand img',\n",
    "            '.header img[alt]'\n",
    "        ]\n",
    "        \n",
    "        for selector in logo_selectors:\n",
    "            imgs = soup.select(selector)\n",
    "            for img in imgs:\n",
    "                alt_text = img.get('alt', '').strip()\n",
    "                if alt_text and len(alt_text) > 3:\n",
    "                    # Clean common logo text\n",
    "                    alt_text = re.sub(r'\\s*(?:logo|brand|image)$', '', alt_text, flags=re.IGNORECASE)\n",
    "                    if alt_text:\n",
    "                        candidates.append((alt_text, 1))\n",
    "        \n",
    "        # Process candidates - prioritize and clean\n",
    "        if candidates:\n",
    "            # Sort by priority (higher number = higher priority)\n",
    "            candidates.sort(key=lambda x: x[1], reverse=True)\n",
    "            \n",
    "            for candidate, priority in candidates:\n",
    "                org_name = clean_organization_name(candidate)\n",
    "                if org_name and len(org_name) > 2:\n",
    "                    return org_name\n",
    "        \n",
    "        return None\n",
    "        \n",
    "    except Exception:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "b2489ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_platforms['about_organization'] = df_platforms['platform_url'].apply(extract_organization_from_about_page)\n",
    "df_platforms['metadata_organization'] = df_platforms['platform_url'].apply(extract_organization_from_metadata)\n",
    "df_platforms['contact_organization'] = df_platforms['platform_url'].apply(extract_organization_from_contact_page)\n",
    "df_platforms['headers_organization'] = df_platforms['platform_url'].apply(extract_organization_from_title_and_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "421b2497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "platform_url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "organization_of_managers",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "footer_organization",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "about_organization",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "metadata_organization",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "contact_organization",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "headers_organization",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "e7b96d69-453a-4630-901a-9b9e535a9eab",
       "rows": [
        [
         "0",
         "https://observation.org/",
         null,
         null,
         null,
         null,
         null,
         "Checking If You Are Not A Bot"
        ],
        [
         "1",
         "https://ornitologia.org/",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "2",
         "https://mics.tools/",
         null,
         "This Project Has Received Funding From The European Uni",
         null,
         "Mics.Tools",
         null,
         "Mics.Tools"
        ],
        [
         "3",
         "https://www.zooniverse.org/",
         null,
         null,
         "To Make An Error",
         null,
         null,
         "Zooniverse"
        ],
        [
         "4",
         "https://www.pocket.science/products/ispex/",
         "DDQ B.V.",
         "Pocket",
         null,
         null,
         null,
         "Ispex - Validated Smartphone Spectropolarimeter For Air & Water Quality Monitoring | Pocket Science"
        ],
        [
         "5",
         "https://www.ispotnature.org/",
         null,
         null,
         null,
         null,
         null,
         "Home | Ispot Nature"
        ],
        [
         "6",
         "https://plantnet.org/en/",
         null,
         "Pl@Ntnet™",
         null,
         "Pl@Ntnet",
         "Weedelec Project Cactus Deepsdm",
         "Home - Pl@Ntnet"
        ],
        [
         "7",
         "https://smartcitizen.me/",
         null,
         null,
         null,
         null,
         null,
         "Smart Citizen"
        ],
        [
         "8",
         "https://artportalen.se/",
         "artdat1805-00001",
         null,
         null,
         null,
         "Landskapsligan",
         "Välkommen Till Artportalen"
        ],
        [
         "9",
         "https://minka-sdg.org/",
         null,
         "About Us Contact Us Communi",
         null,
         "Minka",
         null,
         "A Community To Get The Sdg · Minka"
        ],
        [
         "10",
         "https://sensor.community/en/",
         null,
         null,
         null,
         null,
         null,
         "Sensor Community"
        ],
        [
         "11",
         "https://www.spotteron.com",
         "Not Disclosed",
         "Net Phone: +43-676-598-2272 Skype: Spotteron Spotteron Gmbh",
         null,
         null,
         null,
         "Home - Spotteron Citizen Science"
        ],
        [
         "12",
         "https://smartcitizen.me/",
         null,
         null,
         null,
         null,
         null,
         "Smart Citizen"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 13
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>platform_url</th>\n",
       "      <th>organization_of_managers</th>\n",
       "      <th>footer_organization</th>\n",
       "      <th>about_organization</th>\n",
       "      <th>metadata_organization</th>\n",
       "      <th>contact_organization</th>\n",
       "      <th>headers_organization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://observation.org/</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Checking If You Are Not A Bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://ornitologia.org/</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://mics.tools/</td>\n",
       "      <td>None</td>\n",
       "      <td>This Project Has Received Funding From The Eur...</td>\n",
       "      <td>None</td>\n",
       "      <td>Mics.Tools</td>\n",
       "      <td>None</td>\n",
       "      <td>Mics.Tools</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.zooniverse.org/</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>To Make An Error</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Zooniverse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.pocket.science/products/ispex/</td>\n",
       "      <td>DDQ B.V.</td>\n",
       "      <td>Pocket</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Ispex - Validated Smartphone Spectropolarimete...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://www.ispotnature.org/</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Home | Ispot Nature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://plantnet.org/en/</td>\n",
       "      <td>None</td>\n",
       "      <td>Pl@Ntnet™</td>\n",
       "      <td>None</td>\n",
       "      <td>Pl@Ntnet</td>\n",
       "      <td>Weedelec Project Cactus Deepsdm</td>\n",
       "      <td>Home - Pl@Ntnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://smartcitizen.me/</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Smart Citizen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://artportalen.se/</td>\n",
       "      <td>artdat1805-00001</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Landskapsligan</td>\n",
       "      <td>Välkommen Till Artportalen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://minka-sdg.org/</td>\n",
       "      <td>None</td>\n",
       "      <td>About Us Contact Us Communi</td>\n",
       "      <td>None</td>\n",
       "      <td>Minka</td>\n",
       "      <td>None</td>\n",
       "      <td>A Community To Get The Sdg · Minka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>https://sensor.community/en/</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Sensor Community</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>https://www.spotteron.com</td>\n",
       "      <td>Not Disclosed</td>\n",
       "      <td>Net Phone: +43-676-598-2272 Skype: Spotteron S...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Home - Spotteron Citizen Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>https://smartcitizen.me/</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Smart Citizen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  platform_url organization_of_managers  \\\n",
       "0                     https://observation.org/                     None   \n",
       "1                     https://ornitologia.org/                     None   \n",
       "2                          https://mics.tools/                     None   \n",
       "3                  https://www.zooniverse.org/                     None   \n",
       "4   https://www.pocket.science/products/ispex/                 DDQ B.V.   \n",
       "5                 https://www.ispotnature.org/                     None   \n",
       "6                     https://plantnet.org/en/                     None   \n",
       "7                     https://smartcitizen.me/                     None   \n",
       "8                      https://artportalen.se/         artdat1805-00001   \n",
       "9                       https://minka-sdg.org/                     None   \n",
       "10                https://sensor.community/en/                     None   \n",
       "11                   https://www.spotteron.com            Not Disclosed   \n",
       "12                    https://smartcitizen.me/                     None   \n",
       "\n",
       "                                  footer_organization about_organization  \\\n",
       "0                                                None               None   \n",
       "1                                                None               None   \n",
       "2   This Project Has Received Funding From The Eur...               None   \n",
       "3                                                None   To Make An Error   \n",
       "4                                              Pocket               None   \n",
       "5                                                None               None   \n",
       "6                                           Pl@Ntnet™               None   \n",
       "7                                                None               None   \n",
       "8                                                None               None   \n",
       "9                         About Us Contact Us Communi               None   \n",
       "10                                               None               None   \n",
       "11  Net Phone: +43-676-598-2272 Skype: Spotteron S...               None   \n",
       "12                                               None               None   \n",
       "\n",
       "   metadata_organization             contact_organization  \\\n",
       "0                   None                             None   \n",
       "1                   None                             None   \n",
       "2             Mics.Tools                             None   \n",
       "3                   None                             None   \n",
       "4                   None                             None   \n",
       "5                   None                             None   \n",
       "6               Pl@Ntnet  Weedelec Project Cactus Deepsdm   \n",
       "7                   None                             None   \n",
       "8                   None                   Landskapsligan   \n",
       "9                  Minka                             None   \n",
       "10                  None                             None   \n",
       "11                  None                             None   \n",
       "12                  None                             None   \n",
       "\n",
       "                                 headers_organization  \n",
       "0                       Checking If You Are Not A Bot  \n",
       "1                                                None  \n",
       "2                                          Mics.Tools  \n",
       "3                                          Zooniverse  \n",
       "4   Ispex - Validated Smartphone Spectropolarimete...  \n",
       "5                                 Home | Ispot Nature  \n",
       "6                                     Home - Pl@Ntnet  \n",
       "7                                       Smart Citizen  \n",
       "8                          Välkommen Till Artportalen  \n",
       "9                  A Community To Get The Sdg · Minka  \n",
       "10                                   Sensor Community  \n",
       "11                   Home - Spotteron Citizen Science  \n",
       "12                                      Smart Citizen  "
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_platforms[[\n",
    "    'platform_url',\n",
    "    'organization_of_managers', \n",
    "    'footer_organization', \n",
    "    'about_organization', \n",
    "    'metadata_organization',\n",
    "    'contact_organization',\n",
    "    'headers_organization',\n",
    "    ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe1d238",
   "metadata": {},
   "source": [
    "No conclusive results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d93ab4c",
   "metadata": {},
   "source": [
    "# platform_license"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "13763dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def detect_license(text):\n",
    "    text = text.replace('\\n', ' ').replace('\\r', ' ').lower()\n",
    "\n",
    "    patterns = [\n",
    "        # Common copyright (symbol or world)\n",
    "        r'©\\s*\\d{4}[^\\.\\n]*',\n",
    "        r'copyright\\s*©?\\s*\\d{4}[^\\.\\n]*',\n",
    "        r'copyright\\s+[\\w\\s\\.\\-&,]*\\d{4}[^\\.\\n]*',\n",
    "        r'[^\\.]*©\\s*\\d{4}',  # Match text before and after © symbol   \n",
    "        r'powered by.*?©\\s*\\d{4}',\n",
    "        r'todos los derechos reservados',\n",
    "        r'all rights reserved',\n",
    "        r'tous droits réservés',\n",
    "        r'alle rechte vorbehalten',\n",
    "        r'tutti i diritti riservati',\n",
    "\n",
    "        # Creative Commons\n",
    "        r'creative commons[^<\\n]{0,100}',\n",
    "        r'cc\\s*(by|by-sa|by-nc|by-nd|0)[\\s\\-0-9\\.]*',\n",
    "\n",
    "        # Other licenses\n",
    "        r'mit license',\n",
    "        r'licensed under the mit license',\n",
    "        r'gpl license',\n",
    "        r'licensed under the gpl',\n",
    "        r'bsd license',\n",
    "        r'apache license',\n",
    "        r'european union public licence',\n",
    "        r'licencia.*mit',\n",
    "        r'licencia.*gpl',\n",
    "        r'licencia.*apache',\n",
    "        r'licencia.*bsd',\n",
    "        r'licenza.*',\n",
    "        r'lizenz.*',\n",
    "        r'licence.*'\n",
    "    ]\n",
    "\n",
    "    for pat in patterns:\n",
    "        match = re.search(pat, text, re.IGNORECASE)\n",
    "        if match:\n",
    "            return match.group(0).strip()\n",
    "\n",
    "    return None\n",
    "\n",
    "def extract_license(url):\n",
    "    try:\n",
    "        # Ensure URL has protocol\n",
    "        if not url.startswith(('http://', 'https://')):\n",
    "            url = 'https://' + url\n",
    "        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}\n",
    "        resp = requests.get(url, timeout=10, headers=headers)\n",
    "        soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "        texto = soup.get_text(separator=' ', strip=True)\n",
    "        return detect_license(texto)\n",
    "    except Exception as e:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "fd09194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_platforms['platform_license'] = df_platforms['platform_url'].apply(extract_license)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "c465048e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "platform_url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "platform_license",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "a9398a3a-1167-45a8-8a8a-ec204583d338",
       "rows": [
        [
         "0",
         "https://observation.org/",
         null
        ],
        [
         "1",
         "https://ornitologia.org/",
         "copyright 2025 institut català d'ornitologia | avís legal i política de privadesa"
        ],
        [
         "2",
         "https://mics.tools/",
         "creative commons attribution-sharealike 4.0 international license."
        ],
        [
         "3",
         "https://www.zooniverse.org/",
         null
        ],
        [
         "4",
         "https://www.pocket.science/products/ispex/",
         "© 2025 pocket"
        ],
        [
         "5",
         "https://www.ispotnature.org/",
         null
        ],
        [
         "6",
         "https://plantnet.org/en/",
         "© 2025 pl@ntnet™  the pl@ntnet trademark is a protected trademark owned by cirad, inrae, inria and ird"
        ],
        [
         "7",
         "https://smartcitizen.me/",
         null
        ],
        [
         "8",
         "https://artportalen.se/",
         null
        ],
        [
         "9",
         "https://minka-sdg.org/",
         "creative commons attribution 4.0 license. minka incorporates consent commons icons, allowing for easy visual compreh"
        ],
        [
         "10",
         "https://sensor.community/en/",
         null
        ],
        [
         "11",
         "https://www.spotteron.com",
         null
        ],
        [
         "12",
         "https://smartcitizen.me/",
         null
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 13
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>platform_url</th>\n",
       "      <th>platform_license</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://observation.org/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://ornitologia.org/</td>\n",
       "      <td>copyright 2025 institut català d'ornitologia |...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://mics.tools/</td>\n",
       "      <td>creative commons attribution-sharealike 4.0 in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.zooniverse.org/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.pocket.science/products/ispex/</td>\n",
       "      <td>© 2025 pocket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://www.ispotnature.org/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://plantnet.org/en/</td>\n",
       "      <td>© 2025 pl@ntnet™  the pl@ntnet trademark is a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://smartcitizen.me/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://artportalen.se/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://minka-sdg.org/</td>\n",
       "      <td>creative commons attribution 4.0 license. mink...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>https://sensor.community/en/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>https://www.spotteron.com</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>https://smartcitizen.me/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  platform_url  \\\n",
       "0                     https://observation.org/   \n",
       "1                     https://ornitologia.org/   \n",
       "2                          https://mics.tools/   \n",
       "3                  https://www.zooniverse.org/   \n",
       "4   https://www.pocket.science/products/ispex/   \n",
       "5                 https://www.ispotnature.org/   \n",
       "6                     https://plantnet.org/en/   \n",
       "7                     https://smartcitizen.me/   \n",
       "8                      https://artportalen.se/   \n",
       "9                       https://minka-sdg.org/   \n",
       "10                https://sensor.community/en/   \n",
       "11                   https://www.spotteron.com   \n",
       "12                    https://smartcitizen.me/   \n",
       "\n",
       "                                     platform_license  \n",
       "0                                                None  \n",
       "1   copyright 2025 institut català d'ornitologia |...  \n",
       "2   creative commons attribution-sharealike 4.0 in...  \n",
       "3                                                None  \n",
       "4                                       © 2025 pocket  \n",
       "5                                                None  \n",
       "6   © 2025 pl@ntnet™  the pl@ntnet trademark is a ...  \n",
       "7                                                None  \n",
       "8                                                None  \n",
       "9   creative commons attribution 4.0 license. mink...  \n",
       "10                                               None  \n",
       "11                                               None  \n",
       "12                                               None  "
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_platforms[[\"platform_url\", 'platform_license']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95b0d6a",
   "metadata": {},
   "source": [
    "observation.org is working with anti-bot technology that deny capturing information using requests. Selenium or playwright would be necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "0537d4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_platforms.to_csv(\"../data/df_platforms.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f846be",
   "metadata": {},
   "source": [
    "# platform_email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "34a362e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search email text in home\n",
    "def get_email(url):\n",
    "    try:\n",
    "        # Ensure URL has protocol\n",
    "        if not url.startswith(('http://', 'https://')):\n",
    "            url = 'https://' + url\n",
    "        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}\n",
    "        response = requests.get(url, timeout=10, headers=headers)\n",
    "        if response.status_code != 200:\n",
    "            return None\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        text = soup.get_text()\n",
    "        emails = re.findall(r\"[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+\", text)\n",
    "        return emails[0] if emails else None\n",
    "    except Exception as e:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "743d821e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "platform_email",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "ce054d1a-e465-4266-acf8-58813ba61604",
       "rows": [
        [
         "0",
         null
        ],
        [
         "1",
         "ico@ornitologia.org"
        ],
        [
         "2",
         null
        ],
        [
         "3",
         null
        ],
        [
         "4",
         null
        ],
        [
         "5",
         null
        ],
        [
         "6",
         null
        ],
        [
         "7",
         null
        ],
        [
         "8",
         null
        ],
        [
         "9",
         null
        ],
        [
         "10",
         null
        ],
        [
         "11",
         "office@spotteron.netphone"
        ],
        [
         "12",
         null
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 13
       }
      },
      "text/plain": [
       "0                          None\n",
       "1           ico@ornitologia.org\n",
       "2                          None\n",
       "3                          None\n",
       "4                          None\n",
       "5                          None\n",
       "6                          None\n",
       "7                          None\n",
       "8                          None\n",
       "9                          None\n",
       "10                         None\n",
       "11    office@spotteron.netphone\n",
       "12                         None\n",
       "Name: platform_email, dtype: object"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_platforms['platform_email'] = df_platforms['platform_url'].apply(get_email)\n",
    "df_platforms.platform_email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "6abbc0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_email_from_possible_pages(base_url):\n",
    "    contact_paths = [\n",
    "        '', '/contact', '/contact-us', '/contacto', '/a-propos', '/kontakt',\n",
    "        '/contatti', '/contato', '/assistance', '/chi-siamo', '/uber-uns',\n",
    "        '/soporte', '/support', '/supporto', '/ajuda', '/acerca-de', '/sobre',\n",
    "        '/hilfe', '/steun', '/over-ons'\n",
    "    ]\n",
    "    for path in contact_paths:\n",
    "        email = get_email(base_url.rstrip('/') + path)\n",
    "        if email:\n",
    "            return email\n",
    "    return None\n",
    "\n",
    "df_platforms['platform_email'] = df_platforms['platform_url'].apply(get_email_from_possible_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "32afc046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "platform_email",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "a6d39ee9-067a-40b5-8d03-1d2552235103",
       "rows": [
        [
         "0",
         null
        ],
        [
         "1",
         "ico@ornitologia.org"
        ],
        [
         "2",
         null
        ],
        [
         "3",
         "contact@zooniverse.org."
        ],
        [
         "4",
         null
        ],
        [
         "5",
         null
        ],
        [
         "6",
         null
        ],
        [
         "7",
         null
        ],
        [
         "8",
         null
        ],
        [
         "9",
         null
        ],
        [
         "10",
         null
        ],
        [
         "11",
         "office@spotteron.netphone"
        ],
        [
         "12",
         null
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 13
       }
      },
      "text/plain": [
       "0                          None\n",
       "1           ico@ornitologia.org\n",
       "2                          None\n",
       "3       contact@zooniverse.org.\n",
       "4                          None\n",
       "5                          None\n",
       "6                          None\n",
       "7                          None\n",
       "8                          None\n",
       "9                          None\n",
       "10                         None\n",
       "11    office@spotteron.netphone\n",
       "12                         None\n",
       "Name: platform_email, dtype: object"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_platforms.platform_email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "d431bea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_platforms.to_csv(\"../data/df_platforms_20251210.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb81f28c",
   "metadata": {},
   "source": [
    "# country_of_managers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "e81a1bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-11 19:01:51,737 - whois.whois - ERROR - Error trying to connect to socket: closing socket - [Errno -2] Nombre o servicio desconocido\n",
      "2025-12-11 19:02:35,544 - whois.whois - ERROR - Error trying to connect to socket: closing socket - [Errno -2] Nombre o servicio desconocido\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "platform_url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "country_from_whois",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "df60ed76-e0f6-4666-a607-a084ec1cdfe3",
       "rows": [
        [
         "0",
         "https://observation.org/",
         "GB"
        ],
        [
         "1",
         "https://ornitologia.org/",
         null
        ],
        [
         "2",
         "https://mics.tools/",
         null
        ],
        [
         "3",
         "https://www.zooniverse.org/",
         null
        ],
        [
         "4",
         "https://www.pocket.science/products/ispex/",
         "NL"
        ],
        [
         "5",
         "https://www.ispotnature.org/",
         null
        ],
        [
         "6",
         "https://plantnet.org/en/",
         null
        ],
        [
         "7",
         "https://smartcitizen.me/",
         null
        ],
        [
         "8",
         "https://artportalen.se/",
         null
        ],
        [
         "9",
         "https://minka-sdg.org/",
         null
        ],
        [
         "10",
         "https://sensor.community/en/",
         null
        ],
        [
         "11",
         "https://www.spotteron.com",
         "AT"
        ],
        [
         "12",
         "https://smartcitizen.me/",
         null
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 13
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>platform_url</th>\n",
       "      <th>country_from_whois</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://observation.org/</td>\n",
       "      <td>GB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://ornitologia.org/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://mics.tools/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.zooniverse.org/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.pocket.science/products/ispex/</td>\n",
       "      <td>NL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://www.ispotnature.org/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://plantnet.org/en/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://smartcitizen.me/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://artportalen.se/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://minka-sdg.org/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>https://sensor.community/en/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>https://www.spotteron.com</td>\n",
       "      <td>AT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>https://smartcitizen.me/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  platform_url country_from_whois\n",
       "0                     https://observation.org/                 GB\n",
       "1                     https://ornitologia.org/               None\n",
       "2                          https://mics.tools/               None\n",
       "3                  https://www.zooniverse.org/               None\n",
       "4   https://www.pocket.science/products/ispex/                 NL\n",
       "5                 https://www.ispotnature.org/               None\n",
       "6                     https://plantnet.org/en/               None\n",
       "7                     https://smartcitizen.me/               None\n",
       "8                      https://artportalen.se/               None\n",
       "9                       https://minka-sdg.org/               None\n",
       "10                https://sensor.community/en/               None\n",
       "11                   https://www.spotteron.com                 AT\n",
       "12                    https://smartcitizen.me/               None"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import whois\n",
    "\n",
    "def get_country_from_whois(domain):\n",
    "    try:\n",
    "        w = whois.whois(domain)\n",
    "        return w.get('country')\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "df_platforms['country_from_whois'] = df_platforms['platform_url'].apply(get_country_from_whois)\n",
    "df_platforms[['platform_url', 'country_from_whois']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "82ebae10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "platform_url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "country_servers",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "3a0a422d-e329-41ff-8ec1-fba25486df81",
       "rows": [
        [
         "0",
         "https://observation.org/",
         "The Netherlands"
        ],
        [
         "1",
         "https://ornitologia.org/",
         "Ireland"
        ],
        [
         "2",
         "https://mics.tools/",
         "United Kingdom"
        ],
        [
         "3",
         "https://www.zooniverse.org/",
         "United States"
        ],
        [
         "4",
         "https://www.pocket.science/products/ispex/",
         "United States"
        ],
        [
         "5",
         "https://www.ispotnature.org/",
         "Canada"
        ],
        [
         "6",
         "https://plantnet.org/en/",
         "France"
        ],
        [
         "7",
         "https://smartcitizen.me/",
         "United States"
        ],
        [
         "8",
         "https://artportalen.se/",
         "Sweden"
        ],
        [
         "9",
         "https://minka-sdg.org/",
         "Spain"
        ],
        [
         "10",
         "https://sensor.community/en/",
         "Germany"
        ],
        [
         "11",
         "https://www.spotteron.com",
         "Ireland"
        ],
        [
         "12",
         "https://smartcitizen.me/",
         "United States"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 13
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>platform_url</th>\n",
       "      <th>country_servers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://observation.org/</td>\n",
       "      <td>The Netherlands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://ornitologia.org/</td>\n",
       "      <td>Ireland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://mics.tools/</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.zooniverse.org/</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.pocket.science/products/ispex/</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://www.ispotnature.org/</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://plantnet.org/en/</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://smartcitizen.me/</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://artportalen.se/</td>\n",
       "      <td>Sweden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://minka-sdg.org/</td>\n",
       "      <td>Spain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>https://sensor.community/en/</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>https://www.spotteron.com</td>\n",
       "      <td>Ireland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>https://smartcitizen.me/</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  platform_url  country_servers\n",
       "0                     https://observation.org/  The Netherlands\n",
       "1                     https://ornitologia.org/          Ireland\n",
       "2                          https://mics.tools/   United Kingdom\n",
       "3                  https://www.zooniverse.org/    United States\n",
       "4   https://www.pocket.science/products/ispex/    United States\n",
       "5                 https://www.ispotnature.org/           Canada\n",
       "6                     https://plantnet.org/en/           France\n",
       "7                     https://smartcitizen.me/    United States\n",
       "8                      https://artportalen.se/           Sweden\n",
       "9                       https://minka-sdg.org/            Spain\n",
       "10                https://sensor.community/en/          Germany\n",
       "11                   https://www.spotteron.com          Ireland\n",
       "12                    https://smartcitizen.me/    United States"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example with ip-api.com\n",
    "from urllib.parse import urlparse\n",
    "import socket\n",
    "import requests\n",
    "\n",
    "def country_from_ip(url):\n",
    "    try:\n",
    "        # Extract domain (without http/https or routes)\n",
    "        parsed = urlparse(url)\n",
    "        domain = parsed.netloc or parsed.path  # in case the URL doesn't have a scheme\n",
    "\n",
    "        # Remove www if necessary\n",
    "        if domain.startswith('www.'):\n",
    "            domain = domain[4:]\n",
    "\n",
    "        # Resolve IP\n",
    "        ip = socket.gethostbyname(domain)\n",
    "\n",
    "        # Query geolocalization API\n",
    "        r = requests.get(f\"http://ip-api.com/json/{ip}\", timeout=10)\n",
    "        if r.status_code == 200:\n",
    "            time.sleep(1.4) # limit of 45 requests per minute\n",
    "            return r.json().get(\"country\")\n",
    "    except Exception as e:\n",
    "        return None\n",
    "    \n",
    "df_platforms['country_servers'] = df_platforms['platform_url'].apply(country_from_ip)\n",
    "df_platforms[['platform_url', 'country_servers']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "760bac2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_platforms.to_csv(\"../data/df_platforms20251210.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf63a2a",
   "metadata": {},
   "source": [
    "# data_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "5817e7e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "platform_url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "data_download_options",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "d3cc9319-bb04-4b7d-ba45-1c2f20613e12",
       "rows": [
        [
         "0",
         "https://observation.org/",
         "Protected by anti-bot"
        ],
        [
         "1",
         "https://ornitologia.org/",
         null
        ],
        [
         "2",
         "https://mics.tools/",
         null
        ],
        [
         "3",
         "https://www.zooniverse.org/",
         null
        ],
        [
         "4",
         "https://www.pocket.science/products/ispex/",
         null
        ],
        [
         "5",
         "https://www.ispotnature.org/",
         null
        ],
        [
         "6",
         "https://plantnet.org/en/",
         "https://plantnet.org/en/#download"
        ],
        [
         "7",
         "https://smartcitizen.me/",
         null
        ],
        [
         "8",
         "https://artportalen.se/",
         null
        ],
        [
         "9",
         "https://minka-sdg.org/",
         null
        ],
        [
         "10",
         "https://sensor.community/en/",
         null
        ],
        [
         "11",
         "https://www.spotteron.com",
         null
        ],
        [
         "12",
         "https://smartcitizen.me/",
         null
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 13
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>platform_url</th>\n",
       "      <th>data_download_options</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://observation.org/</td>\n",
       "      <td>Protected by anti-bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://ornitologia.org/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://mics.tools/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.zooniverse.org/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.pocket.science/products/ispex/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://www.ispotnature.org/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://plantnet.org/en/</td>\n",
       "      <td>https://plantnet.org/en/#download</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://smartcitizen.me/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://artportalen.se/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://minka-sdg.org/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>https://sensor.community/en/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>https://www.spotteron.com</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>https://smartcitizen.me/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  platform_url  \\\n",
       "0                     https://observation.org/   \n",
       "1                     https://ornitologia.org/   \n",
       "2                          https://mics.tools/   \n",
       "3                  https://www.zooniverse.org/   \n",
       "4   https://www.pocket.science/products/ispex/   \n",
       "5                 https://www.ispotnature.org/   \n",
       "6                     https://plantnet.org/en/   \n",
       "7                     https://smartcitizen.me/   \n",
       "8                      https://artportalen.se/   \n",
       "9                       https://minka-sdg.org/   \n",
       "10                https://sensor.community/en/   \n",
       "11                   https://www.spotteron.com   \n",
       "12                    https://smartcitizen.me/   \n",
       "\n",
       "                data_download_options  \n",
       "0               Protected by anti-bot  \n",
       "1                                None  \n",
       "2                                None  \n",
       "3                                None  \n",
       "4                                None  \n",
       "5                                None  \n",
       "6   https://plantnet.org/en/#download  \n",
       "7                                None  \n",
       "8                                None  \n",
       "9                                None  \n",
       "10                               None  \n",
       "11                               None  \n",
       "12                               None  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_data_download_options(url):\n",
    "    \"\"\"\n",
    "    Detects if a platform offers data download options.\n",
    "    Searches for download links, export options, and data access features.\n",
    "    \n",
    "    Args:\n",
    "        url (str): Platform URL\n",
    "        \n",
    "    Returns:\n",
    "        str: Description of download options if found, None otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Ensure URL has protocol\n",
    "        if not url.startswith(('http://', 'https://')):\n",
    "            url = 'https://' + url\n",
    "        \n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
    "        }\n",
    "        \n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        page_text = soup.get_text().lower()\n",
    "        \n",
    "        # Check for anti-bot protection\n",
    "        if 'botstopper' in page_text or 'checking if you are not a bot' in page_text:\n",
    "            return \"Protected by anti-bot\"\n",
    "        \n",
    "        download_options = []\n",
    "        \n",
    "        # Terms related to data download/export\n",
    "        download_terms = [\n",
    "            # English\n",
    "            'download data', 'export data', 'data download', 'data export',\n",
    "            'download dataset', 'export dataset', 'bulk download', 'batch download',\n",
    "            'csv download', 'excel download', 'json download', 'xml download',\n",
    "            'download observations', 'export observations', 'data access',\n",
    "            'download records', 'export records', 'get data', 'api download',\n",
    "            \n",
    "            # Spanish\n",
    "            'descargar datos', 'exportar datos', 'descarga de datos',\n",
    "            'descargar registros', 'exportar registros',\n",
    "            \n",
    "            # French\n",
    "            'télécharger données', 'exporter données', 'téléchargement données',\n",
    "            \n",
    "            # German\n",
    "            'daten herunterladen', 'daten exportieren', 'datendownload',\n",
    "            \n",
    "            # Dutch\n",
    "            'data downloaden', 'gegevens downloaden', 'data exporteren'\n",
    "        ]\n",
    "        \n",
    "        # Search for download terms in text\n",
    "        found_terms = []\n",
    "        for term in download_terms:\n",
    "            if term in page_text:\n",
    "                found_terms.append(term)\n",
    "        \n",
    "        # Search for download links\n",
    "        download_links = []\n",
    "        for link in soup.find_all('a', href=True):\n",
    "            href = link.get('href')\n",
    "            href_lower = href.lower()\n",
    "            link_text = link.get_text(strip=True).lower()\n",
    "            \n",
    "            # Check for download-related URLs\n",
    "            download_patterns = [\n",
    "                'download', 'export', 'csv', 'excel', 'json', 'xml', \n",
    "                'data.csv', 'data.json', 'data.xml', '.zip', 'bulk'\n",
    "            ]\n",
    "            \n",
    "            if any(pattern in href_lower for pattern in download_patterns):\n",
    "                # Convert to absolute URL if relative\n",
    "                if href.startswith('/'):\n",
    "                    absolute_url = urljoin(url, href)\n",
    "                elif href.startswith('http'):\n",
    "                    absolute_url = href\n",
    "                else:\n",
    "                    absolute_url = urljoin(url, '/' + href)\n",
    "                download_links.append(f\"{absolute_url}\")\n",
    "            elif any(pattern in link_text for pattern in download_patterns):\n",
    "                # Convert to absolute URL if relative\n",
    "                if href.startswith('/'):\n",
    "                    absolute_url = urljoin(url, href)\n",
    "                elif href.startswith('http'):\n",
    "                    absolute_url = href\n",
    "                else:\n",
    "                    absolute_url = urljoin(url, '/' + href)\n",
    "                download_links.append(f\"{absolute_url}\")\n",
    "        \n",
    "        # Search for file format mentions\n",
    "        file_formats = []\n",
    "        format_patterns = [\n",
    "            r'csv\\s+format', r'excel\\s+format', r'json\\s+format', \n",
    "            r'xml\\s+format', r'\\.csv', r'\\.xlsx?', r'\\.json', r'\\.xml'\n",
    "        ]\n",
    "        \n",
    "        for pattern in format_patterns:\n",
    "            matches = re.findall(pattern, page_text)\n",
    "            if matches:\n",
    "                file_formats.extend(matches)\n",
    "        \n",
    "        # Search for API endpoints that might provide data\n",
    "        api_endpoints = []\n",
    "        if '/api' in page_text or 'rest api' in page_text or 'graphql' in page_text:\n",
    "            api_endpoints.append(\"API available\")\n",
    "        \n",
    "        # Compile results\n",
    "        if found_terms or download_links or file_formats or api_endpoints:\n",
    "            result_parts = []\n",
    "            \n",
    "            if found_terms:\n",
    "                result_parts.append(f\"{', '.join(set(found_terms[:3]))}\")  # Limit to 3\n",
    "            \n",
    "            if download_links:\n",
    "                result_parts.append(f\"{', '.join(download_links[:2])}\")  # Limit to 2\n",
    "            \n",
    "            if file_formats:\n",
    "                result_parts.append(f\"{', '.join(set(file_formats[:3]))}\")  # Limit to 3\n",
    "            \n",
    "            if api_endpoints:\n",
    "                result_parts.append(\"API: Available\")\n",
    "            \n",
    "            return \" | \".join(result_parts)\n",
    "        \n",
    "        return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error checking download options for {url}: {e}\")\n",
    "        return None\n",
    "    \n",
    "df_platforms['data_download_options'] = df_platforms['platform_url'].apply(extract_data_download_options)\n",
    "df_platforms[['platform_url', 'data_download_options']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08bb110",
   "metadata": {},
   "source": [
    "# data_standards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "dd0a11ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "platform_url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "terms_link",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "data_standards",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "6650bef7-5ad1-4f84-9e65-371fe4b3f20f",
       "rows": [
        [
         "0",
         "https://observation.org/",
         "https://observation.org/terms",
         "Protected by anti-bot"
        ],
        [
         "1",
         "https://ornitologia.org/",
         "https://ornitologia.org/ca/quisom/associacio/avis-legal.html",
         null
        ],
        [
         "2",
         "https://mics.tools/",
         null,
         null
        ],
        [
         "3",
         "https://www.zooniverse.org/",
         "https://www.zooniverse.org/privacy-policy",
         null
        ],
        [
         "4",
         "https://www.pocket.science/products/ispex/",
         null,
         null
        ],
        [
         "5",
         "https://www.ispotnature.org/",
         null,
         null
        ],
        [
         "6",
         "https://plantnet.org/en/",
         "https://identify.plantnet.org/en/terms_of_use",
         "JSON-LD"
        ],
        [
         "7",
         "https://smartcitizen.me/",
         null,
         null
        ],
        [
         "8",
         "https://artportalen.se/",
         "https://artportalen.se/FieldDiary",
         null
        ],
        [
         "9",
         "https://minka-sdg.org/",
         "https://minka-sdg.org/pages/terms_and_agreements",
         "DOI, Zenodo"
        ],
        [
         "10",
         "https://sensor.community/en/",
         "https://sensor.community/en/privacy-terms/",
         null
        ],
        [
         "11",
         "https://www.spotteron.com",
         "https://www.spotteron.com/#identifier_8031",
         "Microdata"
        ],
        [
         "12",
         "https://smartcitizen.me/",
         null,
         null
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 13
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>platform_url</th>\n",
       "      <th>terms_link</th>\n",
       "      <th>data_standards</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://observation.org/</td>\n",
       "      <td>https://observation.org/terms</td>\n",
       "      <td>Protected by anti-bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://ornitologia.org/</td>\n",
       "      <td>https://ornitologia.org/ca/quisom/associacio/a...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://mics.tools/</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.zooniverse.org/</td>\n",
       "      <td>https://www.zooniverse.org/privacy-policy</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.pocket.science/products/ispex/</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://www.ispotnature.org/</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://plantnet.org/en/</td>\n",
       "      <td>https://identify.plantnet.org/en/terms_of_use</td>\n",
       "      <td>JSON-LD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://smartcitizen.me/</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://artportalen.se/</td>\n",
       "      <td>https://artportalen.se/FieldDiary</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://minka-sdg.org/</td>\n",
       "      <td>https://minka-sdg.org/pages/terms_and_agreements</td>\n",
       "      <td>DOI, Zenodo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>https://sensor.community/en/</td>\n",
       "      <td>https://sensor.community/en/privacy-terms/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>https://www.spotteron.com</td>\n",
       "      <td>https://www.spotteron.com/#identifier_8031</td>\n",
       "      <td>Microdata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>https://smartcitizen.me/</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  platform_url  \\\n",
       "0                     https://observation.org/   \n",
       "1                     https://ornitologia.org/   \n",
       "2                          https://mics.tools/   \n",
       "3                  https://www.zooniverse.org/   \n",
       "4   https://www.pocket.science/products/ispex/   \n",
       "5                 https://www.ispotnature.org/   \n",
       "6                     https://plantnet.org/en/   \n",
       "7                     https://smartcitizen.me/   \n",
       "8                      https://artportalen.se/   \n",
       "9                       https://minka-sdg.org/   \n",
       "10                https://sensor.community/en/   \n",
       "11                   https://www.spotteron.com   \n",
       "12                    https://smartcitizen.me/   \n",
       "\n",
       "                                           terms_link         data_standards  \n",
       "0                       https://observation.org/terms  Protected by anti-bot  \n",
       "1   https://ornitologia.org/ca/quisom/associacio/a...                   None  \n",
       "2                                                None                   None  \n",
       "3           https://www.zooniverse.org/privacy-policy                   None  \n",
       "4                                                None                   None  \n",
       "5                                                None                   None  \n",
       "6       https://identify.plantnet.org/en/terms_of_use                JSON-LD  \n",
       "7                                                None                   None  \n",
       "8                   https://artportalen.se/FieldDiary                   None  \n",
       "9    https://minka-sdg.org/pages/terms_and_agreements            DOI, Zenodo  \n",
       "10         https://sensor.community/en/privacy-terms/                   None  \n",
       "11         https://www.spotteron.com/#identifier_8031              Microdata  \n",
       "12                                               None                   None  "
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def detect_data_standards(url):\n",
    "    \"\"\"\n",
    "    Detects data standards mentioned on a platform.\n",
    "    Searches for common data standards like Darwin Core, Dublin Core, etc. in terms page.\n",
    "    \n",
    "    Args:\n",
    "        url (str): Platform URL\n",
    "        \n",
    "    Returns:\n",
    "        str: List of detected data standards, None if none found\n",
    "    \"\"\"\n",
    "    if url != None:\n",
    "        try:\n",
    "            # Ensure URL has protocol\n",
    "            if not url.startswith(('http://', 'https://')):\n",
    "                url = 'https://' + url\n",
    "            \n",
    "            headers = {\n",
    "                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
    "            }\n",
    "            \n",
    "            response = requests.get(url, headers=headers, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            page_text = soup.get_text().lower()\n",
    "            \n",
    "            # Check for anti-bot protection\n",
    "            if 'botstopper' in page_text or 'checking if you are not a bot' in page_text:\n",
    "                return \"Protected by anti-bot\"\n",
    "            \n",
    "            # Common data standards to search for\n",
    "            data_standards = {\n",
    "                # Biodiversity standards\n",
    "                'Darwin Core': ['darwin core', 'darwincore', 'dwc', 'darwin'],\n",
    "                'ABCD': ['abcd', 'access to biological collection data'],\n",
    "                'EML': ['eml', 'ecological metadata language'],\n",
    "                'GBIF': ['gbif', 'global biodiversity information facility'],\n",
    "                \n",
    "                # General metadata standards\n",
    "                'Dublin Core': ['dublin core', 'dublincore', 'dc metadata'],\n",
    "                'ISO 19115': ['iso 19115', 'iso19115', 'geographic information metadata'],\n",
    "                'DCAT': ['dcat', 'data catalog vocabulary'],\n",
    "                'Schema.org': ['schema.org', 'schema org', 'structured data'],\n",
    "                \n",
    "                # Scientific data standards\n",
    "                'FAIR': ['fair data', 'fair principles', 'findable accessible interoperable reusable'],\n",
    "                'DataCite': ['datacite', 'data cite', 'doi metadata'],\n",
    "                'ORCID': ['orcid', 'open researcher and contributor id'],\n",
    "                'DOI': ['digital object identifier', 'doi'],\n",
    "                \n",
    "                # Environmental/Earth sciences\n",
    "                'CF Conventions': ['cf conventions', 'climate and forecast', 'netcdf'],\n",
    "                'ISO 19139': ['iso 19139', 'iso19139'],\n",
    "                'OGC': ['ogc', 'open geospatial consortium'],\n",
    "                'WMS': ['web map service', 'wms'],\n",
    "                'WFS': ['web feature service', 'wfs'],\n",
    "                \n",
    "                # Data exchange formats\n",
    "                'JSON-LD': ['json-ld', 'json linked data'],\n",
    "                'RDF': ['rdf', 'resource description framework'],\n",
    "                'OWL': [r'^owl$', 'web ontology language'],\n",
    "                'SKOS': ['skos', 'simple knowledge organization system'],\n",
    "                \n",
    "                # Marine/Ocean standards\n",
    "                'OBIS': ['obis', 'ocean biogeographic information system'],\n",
    "                'ICES': [r'^ices$', 'international council for the exploration of the sea'],\n",
    "                'SeaDataNet': ['seadatanet', 'sea data net'],\n",
    "                \n",
    "                # Research data standards\n",
    "                'CEDARS': ['cedars', 'comprehensive extensible data archival and retrieval system'],\n",
    "                'DataVerse': ['dataverse', 'data verse'],\n",
    "                'Zenodo': ['zenodo'],\n",
    "                'Figshare': ['figshare'],\n",
    "            }\n",
    "            \n",
    "            found_standards = []\n",
    "            \n",
    "            # Search for each standard\n",
    "            for standard_name, terms in data_standards.items():\n",
    "                for term in terms:\n",
    "                    if term in page_text:\n",
    "                        found_standards.append(standard_name)\n",
    "                        break  # Found this standard, move to next\n",
    "            \n",
    "            # Also search in meta tags and structured data\n",
    "            meta_standards = []\n",
    "            \n",
    "            # Check meta tags\n",
    "            for meta in soup.find_all('meta'):\n",
    "                content = meta.get('content', '').lower()\n",
    "                name = meta.get('name', '').lower()\n",
    "                \n",
    "                for standard_name, terms in data_standards.items():\n",
    "                    for term in terms:\n",
    "                        if term in content or term in name:\n",
    "                            meta_standards.append(standard_name)\n",
    "                            break\n",
    "            \n",
    "            # Check for structured data (JSON-LD, microdata)\n",
    "            json_ld = soup.find_all('script', type='application/ld+json')\n",
    "            if json_ld:\n",
    "                found_standards.append('JSON-LD')\n",
    "            \n",
    "            # Check for microdata\n",
    "            if soup.find_all(attrs={'itemtype': True}):\n",
    "                found_standards.append('Microdata')\n",
    "            \n",
    "            # Combine and deduplicate\n",
    "            all_standards = list(set(found_standards + meta_standards))\n",
    "            \n",
    "            if all_standards:\n",
    "                return ', '.join(sorted(all_standards))\n",
    "            \n",
    "            return None\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error detecting data standards for {url}: {e}\")\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "df_platforms['data_standards'] = df_platforms['terms_link'].apply(detect_data_standards)\n",
    "df_platforms[['platform_url', 'terms_link', 'data_standards']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d20914f",
   "metadata": {},
   "source": [
    "The ICES (International Council for the Exploration of the Sea) data standard refers to a comprehensive framework for managing, standardizing, and sharing marine data, focusing on quality, consistency, and accessibility for scientific advice, with key components like the ICES Data Dictionary, specific formats (like HAC for acoustics), and policies ensuring public access (Creative Commons) and data quality checks within portals like DATRAS. \n",
    "\n",
    "The OWL data standard refers to the Web Ontology Language, a W3C standard for creating semantic web ontologies, defining classes, properties, and relationships for complex data modeling and reasoning, with OWL 2 being the current iteration, used in domains like health (SNOMED CT), industry (ISO), and digital preservation (PREMIS) for richer data interoperability and machine understanding.\n",
    "\n",
    "GBIF is not a standard, is a global repository that uses Darwin Core Standard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "bbdeb287",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_platforms.to_csv(\"../data/df_platforms_20251210.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5216778a",
   "metadata": {},
   "source": [
    "# data_license"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "1011404e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "platform_url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "data_license",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "6e60b9ee-a06d-40d6-a8e2-096f0df10cbf",
       "rows": [
        [
         "0",
         "https://observation.org/",
         "Protected by anti-bot"
        ],
        [
         "1",
         "https://ornitologia.org/",
         "Copyright Institut Català D'Ornitologia | Avís Legal I Política De Privadesa"
        ],
        [
         "2",
         "https://mics.tools/",
         "CC BY-SA"
        ],
        [
         "3",
         "https://www.zooniverse.org/",
         null
        ],
        [
         "4",
         "https://www.pocket.science/products/ispex/",
         "Research Use, Copyright Pocket"
        ],
        [
         "5",
         "https://www.ispotnature.org/",
         null
        ],
        [
         "6",
         "https://plantnet.org/en/",
         "Copyright Pl@Ntnet™, Copyright © 2025 Pl@Ntnet™"
        ],
        [
         "7",
         "https://smartcitizen.me/",
         null
        ],
        [
         "8",
         "https://artportalen.se/",
         null
        ],
        [
         "9",
         "https://minka-sdg.org/",
         "CC BY"
        ],
        [
         "10",
         "https://sensor.community/en/",
         "Licensed (unspecified)"
        ],
        [
         "11",
         "https://www.spotteron.com",
         null
        ],
        [
         "12",
         "https://smartcitizen.me/",
         null
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 13
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>platform_url</th>\n",
       "      <th>data_license</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://observation.org/</td>\n",
       "      <td>Protected by anti-bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://ornitologia.org/</td>\n",
       "      <td>Copyright Institut Català D'Ornitologia | Avís...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://mics.tools/</td>\n",
       "      <td>CC BY-SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.zooniverse.org/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.pocket.science/products/ispex/</td>\n",
       "      <td>Research Use, Copyright Pocket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://www.ispotnature.org/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://plantnet.org/en/</td>\n",
       "      <td>Copyright Pl@Ntnet™, Copyright © 2025 Pl@Ntnet™</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://smartcitizen.me/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://artportalen.se/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://minka-sdg.org/</td>\n",
       "      <td>CC BY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>https://sensor.community/en/</td>\n",
       "      <td>Licensed (unspecified)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>https://www.spotteron.com</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>https://smartcitizen.me/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  platform_url  \\\n",
       "0                     https://observation.org/   \n",
       "1                     https://ornitologia.org/   \n",
       "2                          https://mics.tools/   \n",
       "3                  https://www.zooniverse.org/   \n",
       "4   https://www.pocket.science/products/ispex/   \n",
       "5                 https://www.ispotnature.org/   \n",
       "6                     https://plantnet.org/en/   \n",
       "7                     https://smartcitizen.me/   \n",
       "8                      https://artportalen.se/   \n",
       "9                       https://minka-sdg.org/   \n",
       "10                https://sensor.community/en/   \n",
       "11                   https://www.spotteron.com   \n",
       "12                    https://smartcitizen.me/   \n",
       "\n",
       "                                         data_license  \n",
       "0                               Protected by anti-bot  \n",
       "1   Copyright Institut Català D'Ornitologia | Avís...  \n",
       "2                                            CC BY-SA  \n",
       "3                                                None  \n",
       "4                      Research Use, Copyright Pocket  \n",
       "5                                                None  \n",
       "6     Copyright Pl@Ntnet™, Copyright © 2025 Pl@Ntnet™  \n",
       "7                                                None  \n",
       "8                                                None  \n",
       "9                                               CC BY  \n",
       "10                             Licensed (unspecified)  \n",
       "11                                               None  \n",
       "12                                               None  "
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def detect_data_license(url):\n",
    "    \"\"\"\n",
    "   Detects licensing information in home page of platforms.\n",
    "    \n",
    "    Args:\n",
    "        url (str): Platform URL\n",
    "        \n",
    "    Returns:\n",
    "        str: License info if found, guidance if not found\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not url.startswith(('http://', 'https://')):\n",
    "            url = 'https://' + url\n",
    "        \n",
    "        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            return \"Page not accessible\"\n",
    "            \n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        text = soup.get_text().lower()\n",
    "        \n",
    "        # Check for anti-bot\n",
    "        if 'botstopper' in text or 'checking if you are not a bot' in text:\n",
    "            return \"Protected by anti-bot\"\n",
    "        \n",
    "        found_licenses = []\n",
    "        \n",
    "        # 1. Creative Commons (broad search)\n",
    "        if 'creative commons' in text:\n",
    "            if 'cc by-sa' in text or 'attribution-sharealike' in text:\n",
    "                found_licenses.append('CC BY-SA')\n",
    "            elif 'cc by-nc-sa' in text:\n",
    "                found_licenses.append('CC BY-NC-SA')\n",
    "            elif 'cc by-nc' in text or 'noncommercial' in text:\n",
    "                found_licenses.append('CC BY-NC')\n",
    "            elif 'cc by' in text or 'attribution' in text:\n",
    "                found_licenses.append('CC BY')\n",
    "            elif 'cc0' in text or 'public domain' in text:\n",
    "                found_licenses.append('CC0')\n",
    "            else:\n",
    "                found_licenses.append('Creative Commons')\n",
    "        \n",
    "        # 2. Other open licenses\n",
    "        if 'open data commons' in text or 'odc' in text:\n",
    "            found_licenses.append('Open Data Commons')\n",
    "        if 'open database license' in text or 'odbl' in text:\n",
    "            found_licenses.append('ODbL')\n",
    "        if 'open government' in text and 'licen' in text:\n",
    "            found_licenses.append('Open Government Licence')\n",
    "        \n",
    "        # 3. General usage terms (very broad)\n",
    "        if 'open access' in text:\n",
    "            found_licenses.append('Open Access')\n",
    "        if 'freely available' in text or 'free to use' in text:\n",
    "            found_licenses.append('Free Use')\n",
    "        if 'public domain' in text and 'creative commons' not in text:\n",
    "            found_licenses.append('Public Domain')\n",
    "        if 'non-commercial' in text or 'noncommercial' in text:\n",
    "            found_licenses.append('Non-Commercial Use')\n",
    "        if 'academic use' in text or 'educational use' in text:\n",
    "            found_licenses.append('Academic Use')\n",
    "        if 'research use' in text or 'research purposes' in text:\n",
    "            found_licenses.append('Research Use')\n",
    "        if 'attribution required' in text:\n",
    "            found_licenses.append('Attribution Required')\n",
    "        if 'all rights reserved' in text:\n",
    "            found_licenses.append('All Rights Reserved')\n",
    "        \n",
    "        # 4. Copyright detection\n",
    "        copyright_patterns = [\n",
    "            r'©\\s*(?:copyright\\s*)?(?:\\d{4}(?:-\\d{4})?\\s*)?([^\\n\\r.,;]+?)(?:\\.|,|;|$|\\n|\\r)',\n",
    "            r'copyright\\s*(?:\\d{4}(?:-\\d{4})?\\s*)?(?:by\\s*)?([^\\n\\r.,;]+?)(?:\\.|,|;|$|\\n|\\r)',\n",
    "            r'\\(c\\)\\s*(?:\\d{4}(?:-\\d{4})?\\s*)?([^\\n\\r.,;]+?)(?:\\.|,|;|$|\\n|\\r)',\n",
    "            r'all rights reserved.*?([^\\n\\r.,;]+?)(?:\\.|,|;|$|\\n|\\r)',\n",
    "            r'proprietary.*?(?:of|by)\\s*([^\\n\\r.,;]+?)(?:\\.|,|;|$|\\n|\\r)',\n",
    "        ]\n",
    "        \n",
    "        for pattern in copyright_patterns:\n",
    "            matches = re.finditer(pattern, text, re.IGNORECASE | re.MULTILINE)\n",
    "            for match in matches:\n",
    "                copyright_holder = match.group(1).strip()\n",
    "                if copyright_holder and len(copyright_holder) > 2:\n",
    "                    # Clean copyright holder name\n",
    "                    copyright_holder = re.sub(r'\\s*(?:all rights reserved|inc|ltd|corp|llc).*$', '', copyright_holder, flags=re.IGNORECASE)\n",
    "                    copyright_holder = re.sub(r'^\\s*(?:by|de|von|par)\\s+', '', copyright_holder, flags=re.IGNORECASE)\n",
    "                    \n",
    "                    # Filter out generic terms\n",
    "                    generic_terms = ['terms', 'privacy', 'policy', 'contact', 'about', 'home', 'site', 'page']\n",
    "                    if copyright_holder.lower() not in generic_terms and len(copyright_holder) > 2:\n",
    "                        found_licenses.append(f'Copyright {copyright_holder.strip().title()}')\n",
    "                        break\n",
    "        \n",
    "        # 5. Look for any mention of \"license\" or \"licence\"\n",
    "        if not found_licenses:\n",
    "            if 'license' in text or 'licence' in text:\n",
    "                found_licenses.append('Licensed (unspecified)')\n",
    "        \n",
    "        # 6. Check for CC images\n",
    "        if not found_licenses:\n",
    "            for img in soup.find_all('img'):\n",
    "                src = img.get('src', '').lower()\n",
    "                alt = img.get('alt', '').lower()\n",
    "                if any(cc in src or cc in alt for cc in ['creativecommons', 'cc-by', 'cc0']):\n",
    "                    found_licenses.append('Creative Commons (Badge)')\n",
    "                    break\n",
    "        \n",
    "        # 7. Check for CC links\n",
    "        if not found_licenses:\n",
    "            for link in soup.find_all('a', href=True):\n",
    "                href = link.get('href').lower()\n",
    "                if 'creativecommons.org' in href:\n",
    "                    found_licenses.append('Creative Commons (Link)')\n",
    "                    break\n",
    "        \n",
    "        # Return results\n",
    "        if found_licenses:\n",
    "            # Remove duplicates while preserving order\n",
    "            unique_licenses = []\n",
    "            seen = set()\n",
    "            for license_name in found_licenses:\n",
    "                if license_name not in seen:\n",
    "                    seen.add(license_name)\n",
    "                    unique_licenses.append(license_name)\n",
    "            \n",
    "            return ', '.join(unique_licenses[:3])  # Limit to top 3 results\n",
    "        \n",
    "        # If no licenses found, check if we can access terms pages\n",
    "        try:\n",
    "            terms_response = requests.head(url + '/terms', headers=headers, timeout=5)\n",
    "            if terms_response.status_code == 200:\n",
    "                return \"Check terms/legal pages\"\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "df_platforms['data_license'] = df_platforms['platform_url'].apply(detect_data_license)\n",
    "\n",
    "df_platforms[['platform_url', 'data_license']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff877f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_platforms.to_csv(\"../data/df_platforms_20251210.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
